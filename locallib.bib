% Encoding: UTF-8
% == BibTeX quality report for chalkAttentionRewardDrivenOptimization2013:
% ? Title looks like it was stored in title-case in Zotero

@Article{chalkNeuralOscillationsSignature2016,
  author   = {Chalk, M. and Gutkin, B. and Deneve, S.},
  title    = {Neural Oscillations as a Signature of Efficient Coding in the Presence of Synaptic Delays},
  doi      = {10.7554/eLife.13824},
  issn     = {2050-084X (Electronic) 2050-084X (Linking)},
  volume   = {5},
  abstract = {Cortical networks exhibit 'global oscillations', in which neural spike times are entrained to an underlying oscillatory rhythm, but where individual neurons fire irregularly, on only a fraction of cycles. While the network dynamics underlying global oscillations have been well characterised, their function is debated. Here, we show that such global oscillations are a direct consequence of optimal efficient coding in spiking networks with synaptic delays and noise. To avoid firing unnecessary spikes, neurons need to share information about the network state. Ideally, membrane potentials should be strongly correlated and reflect a 'prediction error' while the spikes themselves are uncorrelated and occur rarely. We show that the most efficient representation is when: (i) spike times are entrained to a global Gamma rhythm (implying a consistent representation of the error); but (ii) few neurons fire on each cycle (implying high efficiency), while (iii) excitation and inhibition are tightly balanced. This suggests that cortical networks exhibiting such dynamics are tuned to achieve a maximally efficient population code.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/computation/bayesian/bayesianNeuralSystems/implementations/chalk2016neu.pdf;/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neuroprinciples/chalk2016neu.pdf},
  journal  = {eLife},
  keywords = {computational biology,computational neuroscience,neural coding,neural oscillations,none,systems biology princNeuro},
  month    = jul,
  pmcid    = {PMC4959845},
  year     = {2016},
}

@Article{smelandPolygenicArchitectureSchizophrenia2020,
  author     = {Smeland, Olav B. and Frei, Oleksandr and Dale, Anders M. and Andreassen, Ole A.},
  title      = {The Polygenic Architecture of Schizophrenia \textemdash{} Rethinking Pathogenesis and Nosology},
  doi        = {10.1038/s41582-020-0364-0},
  issn       = {1759-4766},
  language   = {en},
  pages      = {1--14},
  abstract   = {Schizophrenia is a severe psychiatric disorder with considerable morbidity and mortality. Although the past two decades have seen limited improvement in the treatment of schizophrenia, research into the genetic causes of this condition has made important advances that offer new insights into the aetiology of schizophrenia. This Review summarizes the evidence for a polygenic architecture of schizophrenia that involves a large number of risk alleles across the whole range of population frequencies. These genetic risk loci implicate biological processes related to neurodevelopment, neuronal excitability, synaptic function and the immune system in the pathogenesis of schizophrenia. Mathematical models also suggest a substantial overlap between schizophrenia and psychiatric, behavioural and cognitive traits, a situation that has implications for understanding its clinical epidemiology, psychiatric nosology and pathobiology. Looking ahead, further genetic discoveries are expected to lead to clinically relevant predictive approaches for identifying high-risk individuals, improved diagnostic accuracy, increased yield from drug development programmes and improved stratification strategies to address the heterogeneous disease course and treatment responses observed among affected patients.},
  copyright  = {2020 Springer Nature Limited},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/psychiatry/schizophrenia/smeland2020the.pdf},
  journal    = {Nature Reviews Neurology},
  keywords   = {r12,read,review},
  month      = jun,
  publisher  = {{Nature Publishing Group}},
  readstatus = {read},
  year       = {2020},
}

@Article{beggsNeuronalAvalanchesNeocortical2003,
  author   = {Beggs, J. M. and Plenz, D.},
  title    = {Neuronal Avalanches in Neocortical Circuits},
  issn     = {1529-2401 (Electronic) 0270-6474 (Linking)},
  pages    = {11167--77},
  volume   = {23},
  abstract = {Networks of living neurons exhibit diverse patterns of activity, including oscillations, synchrony, and waves. Recent work in physics has shown yet another mode of activity in systems composed of many nonlinear units interacting locally. For example, avalanches, earthquakes, and forest fires all propagate in systems organized into a critical state in which event sizes show no characteristic scale and are described by power laws. We hypothesized that a similar mode of activity with complex emergent properties could exist in networks of cortical neurons. We investigated this issue in mature organotypic cultures and acute slices of rat cortex by recording spontaneous local field potentials continuously using a 60 channel multielectrode array. Here, we show that propagation of spontaneous activity in cortical networks is described by equations that govern avalanches. As predicted by theory for a critical branching process, the propagation obeys a power law with an exponent of -3/2 for event sizes, with a branching parameter close to the critical value of 1. Simulations show that a branching parameter at this value optimizes information transmission in feedforward networks, while preventing runaway network excitation. Our findings suggest that "neuronal avalanches" may be a generic property of cortical networks, and represent a mode of activity that differs profoundly from oscillatory, synchronized, or wave-like network states. In the critical state, the network may satisfy the competing demands of information transmission and network stability.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/criticality/beggs2003neu.pdf},
  journal  = {J Neurosci},
  keywords = {Animals,Computer Simulation,Electrodes,Models; Neurological,Neocortex/cytology/*physiology,Nerve Net/*physiology,Neural Networks (Computer),Neurons/*physiology,Rats,Synaptic Transmission/*physiology},
  month    = dec,
  year     = {2003},
}
% == BibTeX quality report for teixeiraDoesPlasticityPromote2014:
% ? Unsure about the formatting of the booktitle

@Book{teixeiraImmunopsychiatryClinicianIntroduction2019,
  author      = {Teixeira, Antonio L. and Bauer, Moises E.},
  title       = {Immunopsychiatry: {{A Clinician}}'s {{Introduction}} to the {{Immune Basis}} of {{Mental Disorders}}},
  isbn        = {978-0-19-088448-2},
  language    = {en},
  publisher   = {{Oxford University Press}},
  abstract    = {In recent years, a dedicated effort has been made to understand the immune dysfunction that is associated with major psychiatric disorders. The expanding knowledge of the immune system as a major homeostatic system has been very helpful in indicating new potential biomarkers and therapeutic targets to reduce the burden of psychiatric disorders. Indeed, immune cells, their secreted molecules, and cell signalling events are highly promising. Yet, the literature on immunology of psychiatric disorders is still dispersed, and only a few attempts have been made to consolidate the current knowledge in this expanding area. This book assembles and presents the available data on the immune/inflammatory dysfunction in psychiatric disorders, indicating the potential of immune mechanisms as either biomarkers or therapeutic targets, as well as discussing the challenges ahead of incorporating this knowledge into clinical practice. An international team of senior experts in the field review all psychiatric disorders in order to provide an integrated, in-depth understanding of the role of immune changes in psychiatric diseases for mental health clinicians as well as for researchers in immunology, psychiatry, neurology, and pharmacology.},
  googlebooks = {cpSBDwAAQBAJ},
  keywords    = {Medical / Psychiatry / General,Science / Life Sciences / Neuroscience},
  month       = jan,
  shorttitle  = {Immunopsychiatry},
  year        = {2019},
}

@Article{pastukhovMultistablePerceptionBalances2013a,
  author     = {Pastukhov, A. and {Garcia-Rodriguez}, P. E. and Haenicke, J. and Guillamon, A. and Deco, G. and Braun, J.},
  title      = {Multi-Stable Perception Balances Stability and Sensitivity},
  doi        = {10.3389/fncom.2013.00017},
  issn       = {1662-5188 (Electronic) 1662-5188 (Linking)},
  language   = {English},
  pages      = {17},
  volume     = {7},
  abstract   = {We report that multi-stable perception operates in a consistent, dynamical regime, balancing the conflicting goals of stability and sensitivity. When a multi-stable visual display is viewed continuously, its phenomenal appearance reverses spontaneously at irregular intervals. We characterized the perceptual dynamics of individual observers in terms of four statistical measures: the distribution of dominance times (mean and variance) and the novel, subtle dependence on prior history (correlation and time-constant). The dynamics of multi-stable perception is known to reflect several stabilizing and destabilizing factors. Phenomenologically, its main aspects are captured by a simplistic computational model with competition, adaptation, and noise. We identified small parameter volumes (\textasciitilde 3\% of the possible volume) in which the model reproduced both dominance distribution and history-dependence of each observer. For 21 of 24 data sets, the identified volumes clustered tightly (\textasciitilde 15\% of the possible volume), revealing a consistent "operating regime" of multi-stable perception. The "operating regime" turned out to be marginally stable or, equivalently, near the brink of an oscillatory instability. The chance probability of the observed clustering was {$<$}0.02. To understand the functional significance of this empirical "operating regime," we compared it to the theoretical "sweet spot" of the model. We computed this "sweet spot" as the intersection of the parameter volumes in which the model produced stable perceptual outcomes and in which it was sensitive to input modulations. Remarkably, the empirical "operating regime" proved to be largely coextensive with the theoretical "sweet spot." This demonstrated that perceptual dynamics was not merely consistent but also functionally optimized (in that it balances stability with sensitivity). Our results imply that multi-stable perception is not a laboratory curiosity, but reflects a functional optimization of perceptual dynamics for visual inference.},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/perception/multiStablePerception_msp/models/pastukhov2013mul.pdf},
  journal    = {Front Comput Neurosci},
  keywords   = {adaptation,Binocular Rivalry,exploitation-exploration dilemma,Model,Multi-stability,r14,read},
  readstatus = {read},
  year       = {2013},
}
% == BibTeX quality report for keithdfarnsworthUnifyingConceptsBiological2017:
% Missing required field 'journal'

@Article{kelirisRolePrimaryVisual2010,
  author   = {Keliris, G. A. and Logothetis, N. K. and Tolias, A. S.},
  title    = {The Role of the Primary Visual Cortex in Perceptual Suppression of Salient Visual Stimuli},
  doi      = {10.1523/JNEUROSCI.0677-10.2010},
  issn     = {1529-2401 (Electronic) 0270-6474 (Linking)},
  language = {en},
  number   = {37},
  pages    = {12353--65},
  volume   = {30},
  abstract = {The role of primary visual cortex (area V1) in subjective perception has intrigued students of vision for decades. Specifically, the extent to which the activity of different types of cells (monocular versus binocular) and electrophysiological signals (i.e., local field potentials versus spiking activity) reflect perception is still debated. To address these questions we recorded from area V1 of the macaque using tetrodes during the paradigm of binocular flash suppression, where incongruent images presented dichoptically compete for perceptual dominance. We found that the activity of a minority (20\%) of neurons reflect the perceived visual stimulus and these cells exhibited perceptual modulations substantially weaker compared with their sensory modulation induced by congruent stimuli. Importantly, perceptual modulations were found equally often for monocular and binocular cells, demonstrating that perceptual competition in V1 involves mechanisms across both types of neurons. The power of the local field potential (LFP) also showed moderate perceptual modulations with similar percentages of sites showing significant effects across frequency bands (18-22\%). The possibility remains that perception may be strongly reflected in more elaborate aspects of activity in V1 circuits (e.g., specific neuronal subtypes) or perceptual states might have a modulatory role on more intricate aspects of V1 firing patterns (e.g., synchronization), not necessarily altering the firing rates of single cells or the LFP power dramatically.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/perception/multiStablePerception_msp/keliris2010the.pdf},
  journal  = {J Neurosci},
  keywords = {Action Potentials/physiology,Animals,Cortical Synchronization,Dominance; Ocular/physiology,Evoked Potentials; Visual/*physiology,Macaca mulatta,Male,Neural Pathways/physiology,Neurons/*physiology,Perceptual Masking/*physiology,Photic Stimulation/*methods,Signal Processing; Computer-Assisted,Vision; Binocular/physiology,Visual Cortex/anatomy \& histology/*physiology,Visual Pathways/physiology,Visual Perception/*physiology},
  month    = sep,
  year     = {2010},
}

@Article{tetzlaffUseHebbianCell2015,
  author    = {Tetzlaff, Christian and Dasgupta, Sakyasingha and Kulvicius, Tomas and W{\"o}rg{\"o}tter, Florentin},
  title     = {The {{Use}} of {{Hebbian Cell Assemblies}} for {{Nonlinear Computation}}},
  doi       = {10.1038/srep12866},
  issn      = {2045-2322},
  language  = {en},
  number    = {1},
  pages     = {12866},
  volume    = {5},
  abstract  = {When learning a complex task our nervous system self-organizes large groups of neurons into coherent dynamic activity patterns. During this, a network with multiple, simultaneously active and computationally powerful cell assemblies is created. How such ordered structures are formed while preserving a rich diversity of neural dynamics needed for computation is still unknown. Here we show that the combination of synaptic plasticity with the slower process of synaptic scaling achieves (i) the formation of cell assemblies and (ii) enhances the diversity of neural dynamics facilitating the learning of complex calculations. Due to synaptic scaling the dynamics of different cell assemblies do not interfere with each other. As a consequence, this type of self-organization allows executing a difficult, six degrees of freedom, manipulation task with a robot where assemblies need to learn computing complex non-linear transforms and \textendash{} for execution \textendash{} must cooperate with each other without interference. This mechanism, thus, permits the self-organization of computationally powerful sub-structures in dynamic networks for behavior control.},
  copyright = {2015 The Author(s)},
  journal   = {Scientific Reports},
  month     = aug,
  publisher = {{Nature Publishing Group}},
  year      = {2015},
}

@Article{hesseNewNoreportParadigm2020,
  author     = {Hesse, Janis Karan and Tsao, Doris Y},
  title      = {A New No-Report Paradigm Reveals That Face Cells Encode Both Consciously Perceived and Suppressed Stimuli},
  doi        = {10.7554/eLife.58360},
  editor     = {Meng, Ming},
  issn       = {2050-084X},
  pages      = {e58360},
  volume     = {9},
  abstract   = {A powerful paradigm to identify neural correlates of consciousness is binocular rivalry, wherein a constant visual stimulus evokes a varying conscious percept. It has recently been suggested that activity modulations observed during rivalry may represent the act of report rather than the conscious percept itself. Here, we performed single-unit recordings from face patches in macaque inferotemporal (IT) cortex using a no-report paradigm in which the animal's conscious percept was inferred from eye movements. We found that high proportions of IT neurons represented the conscious percept even without active report. Furthermore, on single trials we could decode both the conscious percept and the suppressed stimulus. Together, these findings indicate that (1) IT cortex possesses a true neural correlate of consciousness, and (2) this correlate consists of a population code wherein single cells multiplex representation of the conscious percept and veridical physical stimulus, rather than a subset of cells perfectly reflecting consciousness.},
  journal    = {eLife},
  keywords   = {binocular rivalry,consciousness,face patch,face perception,inferotemporal cortex,no-report paradigm,r8.8,read},
  month      = nov,
  publisher  = {{eLife Sciences Publications, Ltd}},
  readstatus = {read},
  year       = {2020},
}

@Article{brandAuthorshipAttributionContribution2015,
  author     = {Brand, Amy and Allen, Liz and Altman, Micah and Hlava, Marjorie and Scott, Jo},
  title      = {Beyond Authorship: Attribution, Contribution, Collaboration, and Credit},
  doi        = {10.1087/20150211},
  issn       = {1741-4857},
  language   = {en},
  number     = {2},
  pages      = {151--155},
  volume     = {28},
  abstract   = {Key points As the number of authors on scientific publications increases, ordered lists of author names are proving inadequate for the purposes of attribution and credit. A multi-stakeholder group has produced a contributor role taxonomy for use in scientific publications. Identifying specific contributions to published research will lead to appropriate credit, fewer author disputes, and fewer disincentives to collaboration and the sharing of data and code.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1087/20150211},
  copyright  = {\textcopyright{} 2015 The Authors},
  journal    = {Learned Publishing},
  shorttitle = {Beyond Authorship},
  year       = {2015},
}

@TechReport{eurichNeuralDynamicsNeural2003,
  author = {Eurich, C. W.},
  title  = {Neural {{Dynamics}} and {{Neural Coding Two Complementary Approaches}}},
  file   = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/DynamicCoding/eurich2003eur.pdf},
  year   = {2003},
}

@Book{churchlandComputationalBrain1992,
  author    = {Churchland, Patricia Smith and Sejnowski, Terrence J.},
  title     = {The Computational Brain},
  isbn      = {978-0-262-03188-2},
  publisher = {{MIT Press}},
  series    = {Computational Neuroscience},
  address   = {{Cambridge, Mass}},
  file      = {/home/ssafavi/Nextcloud/libraries/zoteroLib/books/churchland1992the.pdf},
  keywords  = {Brain,Computer simulation,Computer Simulation,methods,Models; Neurological,Neural networks (Neurobiology),Neurosciences,physiology},
  lccn      = {QP356 .C48 1992},
  year      = {1992},
}

@Article{heuvelCrossdisorderConnectomeLandscape2019,
  author     = {van den Heuvel, Martijn P. and Sporns, Olaf},
  title      = {A Cross-Disorder Connectome Landscape of Brain Dysconnectivity},
  doi        = {10.1038/s41583-019-0177-6},
  issn       = {1471-0048},
  language   = {En},
  number     = {7},
  pages      = {435},
  volume     = {20},
  abstract   = {In this Opinion article, Martijn van den Heuvel and Olaf Sporns examine alterations in structural and functional brain connectivity across brain disorders. They propose a common landscape for such alterations that is based on principles of network organization.},
  copyright  = {2019 The Publisher},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/psychiatry/cmpsy/connectomics/heuvel2019a.pdf},
  journal    = {Nature Reviews Neuroscience},
  keywords   = {read,review},
  month      = jul,
  readstatus = {read},
  year       = {2019},
}
% == BibTeX quality report for aitchisonZipfLawArises2016:
% ? Title looks like it was stored in title-case in Zotero

@Article{aitchisonZipfLawArises2016a,
  author     = {Aitchison, Laurence and Corradi, Nicola and Latham, Peter E.},
  title      = {Zipf's {{Law Arises Naturally When There Are Underlying}}, {{Unobserved Variables}}},
  doi        = {10.1371/journal.pcbi.1005110},
  issn       = {1553-7358},
  language   = {en},
  number     = {12},
  pages      = {e1005110},
  volume     = {12},
  abstract   = {Zipf's law, which states that the probability of an observation is inversely proportional to its rank, has been observed in many domains. While there are models that explain Zipf's law in each of them, those explanations are typically domain specific. Recently, methods from statistical physics were used to show that a fairly broad class of models does provide a general explanation of Zipf's law. This explanation rests on the observation that real world data is often generated from underlying causes, known as latent variables. Those latent variables mix together multiple models that do not obey Zipf's law, giving a model that does. Here we extend that work both theoretically and empirically. Theoretically, we provide a far simpler and more intuitive explanation of Zipf's law, which at the same time considerably extends the class of models to which this explanation can apply. Furthermore, we also give methods for verifying whether this explanation applies to a particular dataset. Empirically, these advances allowed us extend this explanation to important classes of data, including word frequencies (the first domain in which Zipf's law was discovered), data with variable sequence length, and multi-neuron spiking activity.},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/criticality/aitchison2016zip.pdf},
  journal    = {PLOS Computational Biology},
  keywords   = {Computational linguistics,Covariance,Entropy,Grammar,Morphology (linguistics),Neurons,Probability distribution,r8,read,Sequence analysis},
  month      = dec,
  readstatus = {read},
  year       = {2016},
}
% == BibTeX quality report for burkovHundredPageMachineLearning:
% ? Title looks like it was stored in title-case in Zotero

@Article{burmeisterPsychiatricGeneticsProgress2008,
  author     = {Burmeister, Margit and McInnis, Melvin G. and Z{\"o}llner, Sebastian},
  title      = {Psychiatric Genetics: Progress amid Controversy},
  doi        = {10.1038/nrg2381},
  issn       = {1471-0064},
  language   = {en},
  number     = {7},
  pages      = {527--540},
  volume     = {9},
  abstract   = {Most psychiatric disorders are highly heritable, yet few reproducible genetic risk factors have been identified by linkage analysis and candidate gene or genome-wide association studies.Large genomic rearrangements have been found in a subset of patients with autism and schizophrenia, suggesting that recurrent and/or new mutations are involved in psychiatric disorders.Several confirmed genetic risk factors of relevance to psychiatric disorders are with endophenotypes \textemdash{} that is, with quantitative phenotypes related to psychiatric disorders \textemdash{} rather than with diagnoses themselves.The incorporation of environmental risk factors into analysis has helped to elucidate and identify some genetic risk factors. Longitudinal studies will be needed to identify gene-by-environment effects.Psychiatric symptoms have a role in some Mendelian disorders that have known causes.Unique families with rare syndromes have led to the identification of some common genetic risk variants.The genetics of psychiatric disorders is complex and needs to be approached from several angles. It is therefore insufficient to focus only on linkage and association studies of clinical categories.Increased sample size and meta-analyses of large existing studies might allow the identification of common risk variants of psychiatric disorders.Future work will need to incorporate additional factors: alternative phenotypes; recurrent new mutations and rare, 'private' mutations that are not detectable by genome-wide association; the interaction of environment with genetic risk factors; and, by bioinformatic means, our growing knowledge of expression differences and biological pathways.},
  copyright  = {2008 Nature Publishing Group},
  journal    = {Nature Reviews Genetics},
  month      = jul,
  publisher  = {{Nature Publishing Group}},
  shorttitle = {Psychiatric Genetics},
  year       = {2008},
}

@Article{turingComputingMachineryIntelligence1950,
  author   = {Turing, A. M.},
  title    = {I.\textemdash{{Computing Machinery}} and {{Intelligence}}},
  doi      = {10.1093/mind/LIX.236.433},
  issn     = {0026-4423 1460-2113},
  language = {en},
  pages    = {433--460},
  volume   = {LIX},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neuroprinciples/turing1950i.pdf;/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neuroprinciples/turing1950i.pdf},
  journal  = {Mind},
  keywords = {princNeuro},
  month    = oct,
  year     = {1950},
}

@Article{denmanStructurePairwiseCorrelation2014,
  author    = {Denman, Daniel J. and Contreras, Diego},
  title     = {The {{Structure}} of {{Pairwise Correlation}} in {{Mouse Primary Visual Cortex Reveals Functional Organization}} in the {{Absence}} of an {{Orientation Map}}},
  doi       = {10.1093/cercor/bht128},
  issn      = {1047-3211},
  language  = {en},
  number    = {10},
  pages     = {2707--2720},
  volume    = {24},
  abstract  = {Abstract. Neural responses to sensory stimuli are not independent. Pairwise correlation can reduce coding efficiency, occur independent of stimulus representati},
  journal   = {Cerebral Cortex},
  month     = oct,
  publisher = {{Oxford Academic}},
  year      = {2014},
}

@Article{tononiIntegratedInformationTheory2016,
  author   = {Tononi, G. and Boly, M. and Massimini, M. and Koch, C.},
  title    = {Integrated Information Theory: From Consciousness to Its Physical Substrate},
  doi      = {10.1038/nrn.2016.44},
  issn     = {1471-0048 (Electronic) 1471-003X (Linking)},
  language = {en},
  abstract = {In this Opinion article, we discuss how integrated information theory accounts for several aspects of the relationship between consciousness and the brain. Integrated information theory starts from the essential properties of phenomenal experience, from which it derives the requirements for the physical substrate of consciousness. It argues that the physical substrate of consciousness must be a maximum of intrinsic cause-effect power and provides a means to determine, in principle, the quality and quantity of experience. The theory leads to some counterintuitive predictions and can be used to develop new tools for assessing consciousness in non-communicative patients.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/integratedInformationTheory_iit/tononi2016int.pdf},
  journal  = {Nat Rev Neurosci},
  keywords = {Consciousness; Cognitive neuroscience; Disorders of consciousness},
  month    = may,
  year     = {2016},
}

@Article{zbiliQuickEasyWay2020,
  author    = {Zbili, Mickael and Rama, Sylvain},
  title     = {A Quick and Easy Way to Estimate Entropy and Mutual Information for Neuroscience},
  doi       = {10.1101/2020.08.04.236174},
  language  = {en},
  pages     = {2020.08.04.236174},
  abstract  = {{$<$}p{$>$}Calculations of entropy of a signal or mutual information between two variables are valuable analytical tools in the field of neuroscience. They can be applied to all types of data, capture nonlinear interactions and are model independent. Yet the limited size and number of recordings one can collect in a series of experiments makes their calculation highly prone to sampling bias. Mathematical methods to overcome this so called "sampling disaster" exist, but require significant expertise, great time and computational costs. As such, there is a need for a simple, unbiased and computationally efficient tool for reliable entropy and mutual information estimation. In this paper, we propose that application of entropy-coding compression algorithms widely used in text and image compression fulfill these requirements. By simply saving the signal in PNG picture format and measuring the size of the file on the hard drive, we can reliably estimate entropy through different conditions. Furthermore, with some simple modifications of the PNG file, we can also estimate mutual information between a stimulus and the observed responses into multiple trials. We show this using White noise signals, electrophysiological signals and histological data. Although this method does not give an absolute value of entropy or mutual information, it is mathematically correct, and its simplicity and broad use make it a powerful tool for their estimation through experiments.{$<$}/p{$>$}},
  chapter   = {New Results},
  copyright = {\textcopyright{} 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial 4.0 International), CC BY-NC 4.0, as described at http://creativecommons.org/licenses/by-nc/4.0/},
  journal   = {bioRxiv},
  month     = aug,
  publisher = {{Cold Spring Harbor Laboratory}},
  year      = {2020},
}

@Article{logothetisWhatWeCan2008,
  author   = {Logothetis, N. K.},
  title    = {What We Can Do and What We Cannot Do with {{fMRI}}},
  doi      = {10.1038/nature06976},
  issn     = {1476-4687 (Electronic) 0028-0836 (Linking)},
  language = {en},
  pages    = {869--78},
  volume   = {453},
  abstract = {Functional magnetic resonance imaging (fMRI) is currently the mainstay of neuroimaging in cognitive neuroscience. Advances in scanner technology, image acquisition protocols, experimental design, and analysis methods promise to push forward fMRI from mere cartography to the true study of brain organization. However, fundamental questions concerning the interpretation of fMRI data abound, as the conclusions drawn often ignore the actual limitations of the methodology. Here I give an overview of the current state of fMRI, and draw on neuroimaging and physiological data to present the current understanding of the haemodynamic signals and the constraints they impose on neuroimaging data interpretation.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/multiModal/logothetis2008wha.pdf;/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/multiModal/logothetis2008wha.pdf},
  journal  = {Nature},
  keywords = {*Magnetic Resonance Imaging/instrumentation/methods/standards,Animals,Brain/blood supply/*physiology,Feedback; Physiological,Humans,Sensitivity and Specificity},
  month    = jun,
  year     = {2008},
}

@Article{tononiNeuralCorrelatesConsciousness2008,
  author   = {Tononi, G. and Koch, C.},
  title    = {The Neural Correlates of Consciousness: An Update},
  doi      = {10.1196/annals.1440.004},
  issn     = {0077-8923 (Print) 0077-8923 (Linking)},
  language = {en},
  number   = {1},
  pages    = {239--61},
  volume   = {1124},
  abstract = {This review examines recent advances in the study of brain correlates of consciousness. First, we briefly discuss some useful distinctions between consciousness and other brain functions. We then examine what has been learned by studying global changes in the level of consciousness, such as sleep, anesthesia, and seizures. Next we consider some of the most common paradigms used to study the neural correlates for specific conscious percepts and examine what recent findings say about the role of different brain regions in giving rise to consciousness for that percept. Then we discuss dynamic aspects of neural activity, such as sustained versus phasic activity, feedforward versus reentrant activity, and the role of neural synchronization. Finally, we briefly consider how a theoretical analysis of the fundamental properties of consciousness can usefully complement neurobiological studies.},
  file     = {/Users/ssafavi/Documents/libraries/EndnoteLib_fromWin407/EndnoteLib_MPIPClocal_20170723.Data/PDF/1247279779/Tononi-2008.pdf},
  journal  = {Ann N Y Acad Sci},
  keywords = {*Brain Mapping,Brain/anatomy \& histology/*physiology,Consciousness/*physiology},
  month    = mar,
  year     = {2008},
}

@Article{cocchiCriticalityBrainSynthesis2017,
  author     = {Cocchi, Luca and Gollo, Leonardo L. and Zalesky, Andrew and Breakspear, Michael},
  title      = {Criticality in the Brain: {{A}} Synthesis of Neurobiology, Models and Cognition},
  doi        = {10.1016/j.pneurobio.2017.07.002},
  issn       = {0301-0082},
  pages      = {132--152},
  volume     = {158},
  abstract   = {Cognitive function requires the coordination of neural activity across many scales, from neurons and circuits to large-scale networks. As such, it is unlikely that an explanatory framework focused upon any single scale will yield a comprehensive theory of brain activity and cognitive function. Modelling and analysis methods for neuroscience should aim to accommodate multiscale phenomena. Emerging research now suggests that multi-scale processes in the brain arise from so-called critical phenomena that occur very broadly in the natural world. Criticality arises in complex systems perched between order and disorder, and is marked by fluctuations that do not have any privileged spatial or temporal scale. We review the core nature of criticality, the evidence supporting its role in neural systems and its explanatory potential in brain health and disease.},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/criticality/cocchi2017cri.pdf},
  journal    = {Progress in Neurobiology},
  keywords   = {Bifurcations,Cognition,Dynamics,Metastability,Multistability,Power-law,r7,read,review},
  month      = nov,
  readstatus = {read},
  shorttitle = {Criticality in the Brain},
  year       = {2017},
}

@Article{deneveBayesianSpikingNeurons2008a,
  author   = {Deneve, S.},
  title    = {Bayesian Spiking Neurons {{I}}: Inference},
  doi      = {10.1162/neco.2008.20.1.91},
  issn     = {0899-7667 (Print) 0899-7667 (Linking)},
  language = {en},
  pages    = {91--117},
  volume   = {20},
  abstract = {We show that the dynamics of spiking neurons can be interpreted as a form of Bayesian inference in time. Neurons that optimally integrate evidence about events in the external world exhibit properties similar to leaky integrate-and-fire neurons with spike-dependent adaptation and maximally respond to fluctuations of their input. Spikes signal the occurrence of new information-what cannot be predicted from the past activity. As a result, firing statistics are close to Poisson, albeit providing a deterministic representation of probabilities.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/computation/bayesian/bayesianNeuralSystems/deneve2008bay.pdf},
  journal  = {Neural Comput},
  keywords = {Action Potentials/*physiology,Adaptation; Physiological/physiology,Algorithms,Animals,Bayes Theorem,Central Nervous System/*physiology,Computer Simulation,Humans,Markov Chains,Models; Statistical,Movement/*physiology,Nerve Net/*physiology,Neural Networks (Computer),Neurons/*physiology,Perception/*physiology,Synaptic Transmission/physiology},
  month    = jan,
  year     = {2008},
}
% == BibTeX quality report for ashidaEffectSamplingFrequency2010:
% ? Title looks like it was stored in title-case in Zotero

@InCollection{ashidaProcessingPhaseLockedSpikes2010,
  author    = {Ashida, Go and Wagner, Hermann and Carr, Catherine E.},
  booktitle = {Analysis of {{Parallel Spike Trains}}},
  title     = {Processing of {{Phase}}-{{Locked Spikes}} and {{Periodic Signals}}},
  doi       = {10.1007/978-1-4419-5675-0_4},
  isbn      = {978-1-4419-5674-3 978-1-4419-5675-0},
  language  = {en},
  pages     = {59--74},
  publisher = {{Springer, Boston, MA}},
  series    = {Springer {{Series}} in {{Computational Neuroscience}}},
  abstract  = {Studies of synchrony in the nervous system have revealed circuits specialized for the encoding and processing of temporal information. Periodic signals are generally coded by phase-locked action potentials and often processed in a dedicated pathway in parallel with other stimulus variables. We discuss circular statistics and current data analysis tools to quantify phase locking such as vector strength.},
  file      = {/home/ssafavi/Nextcloud/libraries/zoteroLib/dataAnalysis/circularStatistics/ashida2010pro.pdf},
  year      = {2010},
}
% == BibTeX quality report for christofkochHowComputerBeat2016:
% ? Title looks like it was stored in title-case in Zotero

@Book{christofQuestConsciousnessNeurobiological2004,
  author     = {Christof, Koch},
  title      = {The {{Quest}} for {{Consciousness}}: {{A Neurobiological Approach}}},
  edition    = {1st edition},
  isbn       = {978-1-936221-04-2},
  language   = {English},
  publisher  = {{Roberts and Company Publishers}},
  abstract   = {Rare book},
  address    = {{Denver, Colo.}},
  month      = jan,
  shorttitle = {The {{Quest}} for {{Consciousness}}},
  year       = {2004},
}
% == BibTeX quality report for morowitzEmergenceEverythingHow2004:
% ? Title looks like it was stored in title-case in Zotero

@Book{morowitzMindBrainComplex1995,
  author    = {Morowitz, Harold J. and Singer, Jerome L.},
  title     = {The {{Mind}}, {{The Brain And Complex Adaptive Systems}}},
  isbn      = {978-0-201-40986-4},
  language  = {English},
  publisher = {{Westview Press}},
  abstract  = {Based upon a conference held in May 1993, this book discusses the intersection of neurobiology, cognitive psychology and computational approaches to cognition.},
  address   = {{Reading, Mass}},
  month     = jan,
  year      = {1995},
}
% == BibTeX quality report for mpsComplexSystems2010:
% Missing required field 'institution'

@Article{mSocialIsolationAlters2020,
  author   = {M, Donovan and Cs, Mackey and Gn, Platt and J, Rounds and An, Brown and Dj, Trickey and Y, Liu and Km, Jones and Zx, Wang},
  title    = {Social Isolation Alters Behavior, the Gut-Immune-Brain Axis, and Neurochemical Circuits in Male and Female Prairie Voles},
  doi      = {10.1016/j.ynstr.2020.100278},
  issn     = {2352-2895},
  language = {en},
  pages    = {100278},
  abstract = {The absence of social support, or social isolation, can be stressful, leading to a suite of physical and psychological health issues. Growing evidence suggests that disruption of the gut-immune-brain axis plays a crucial role in the negative outcomes seen from social isolation stress. However, the mechanisms remain largely unknown. The socially monogamous prairie vole (Microtus ochrogaster) has been validated as a useful model for studying negative effects of social isolation on the brain and behaviors, yet how the gut microbiome and central immune system are altered in isolated prairie voles are still unknown. Here, we utilized this social rodent to examine how social isolation stress alters the gut-immune-brain axis and relevant behaviors. Adult male and female prairie voles (n = 48 per sex) experienced social isolation or were cohoused with a same-sex cagemate (control) for six weeks. Thereafter, their social and anxiety-like behaviors, neuronal circuit activation, neurochemical expression, and microgliosis in key brain regions, as well as gut microbiome alterations from the isolation treatment were examined. Social isolation increased anxiety-like behaviors and impaired social affiliation. Isolation also resulted in sex- and brain region-specific alterations in neuronal activation, neurochemical expression, and microgliosis. Further, social isolation resulted in alterations to the gut microbiome that were correlated with key brain and behavioral measures. Our data suggest that social isolation alters the gut-immune-brain axis in a sex-dependent manner and that gut microbes, central glial cells, and neurochemical systems may play a critical, integrative role in mediating negative outcomes from social isolation.},
  journal  = {Neurobiology of Stress},
  keywords = {6): social isolation,Gut microbiome-immune-brain axis,Microglia,Oxytocin,Sex difference},
  month    = nov,
  year     = {2020},
}
% == BibTeX quality report for hallStatisticalMechanicsTwitter2018:
% ? Possibly abbreviated journal title arXiv:1812.07029 [physics]

@Article{hallStatisticalMechanicsTwitter2019,
  author   = {Hall, Gavin and Bialek, William},
  title    = {The Statistical Mechanics of {{Twitter}} Communities},
  doi      = {10.1088/1742-5468/ab3af0},
  issn     = {1742-5468},
  language = {en},
  number   = {9},
  pages    = {093406},
  volume   = {2019},
  abstract = {We build models for the distribution of social states in Twitter communities. States can be defined by the participation versus silence of individuals in conversations that surround key words, and we approximate the joint distribution of these binary variables using the maximum entropy principle, finding the least structured models that match the mean probability of individuals tweeting and their pairwise correlations. These models provide very accurate, quantitative descriptions of higher order structure in these social networks. The parameters of these models seem poised close to critical surfaces in the space of possible models, and we observe scaling behavior of the data under coarse-graining. These results suggest that simple models, grounded in statistical physics, may provide a useful point of view on the larger data sets now emerging from complex social systems.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/criticality/hall2019the.pdf},
  journal  = {Journal of Statistical Mechanics: Theory and Experiment},
  month    = sep,
  year     = {2019},
}

@Article{wangBrainMechanismsSimple2013,
  author   = {Wang, M. and Arteaga, D. and He, B. J.},
  title    = {Brain Mechanisms for Simple Perception and Bistable Perception},
  doi      = {10.1073/pnas.1221945110},
  issn     = {1091-6490 (Electronic) 0027-8424 (Linking)},
  language = {en},
  number   = {35},
  pages    = {E3350-9},
  volume   = {110},
  abstract = {When faced with ambiguous sensory inputs, subjective perception alternates between the different interpretations in a stochastic manner. Such multistable perception phenomena have intrigued scientists and laymen alike for over a century. Despite rigorous investigations, the underlying mechanisms of multistable perception remain elusive. Recent studies using multivariate pattern analysis revealed that activity patterns in posterior visual areas correlate with fluctuating percepts. However, increasing evidence suggests that vision--and perception at large--is an active inferential process involving hierarchical brain systems. We applied searchlight multivariate pattern analysis to functional magnetic resonance imaging signals across the human brain to decode perceptual content during bistable perception and simple unambiguous perception. Although perceptually reflective activity patterns during simple perception localized predominantly to posterior visual regions, bistable perception involved additionally many higher-order frontoparietal and temporal regions. Moreover, compared with simple perception, both top-down and bottom-up influences were dramatically enhanced during bistable perception. We further studied the intermittent presentation of ambiguous images--a condition that is known to elicit perceptual memory. Compared with continuous presentation, intermittent presentation recruited even more higher-order regions and was accompanied by further strengthened top-down influences but relatively weakened bottom-up influences. Taken together, these results strongly support an active top-down inferential process in perception.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/perception/multiStablePerception_msp/wang2013bra.pdf},
  journal  = {Proc Natl Acad Sci U S A},
  month    = aug,
  year     = {2013},
}
% == BibTeX quality report for carterModulatingRateRhythmicity2005:
% ? Title looks like it was stored in title-case in Zotero

@Article{carterPerceptualRivalryAnimal2020,
  author     = {Carter, Olivia and van Swinderen, Bruno and Leopold, David and Collin, Shaun and Maier, Alex},
  title      = {Perceptual Rivalry across Animal Species},
  doi        = {10.1002/cne.24939},
  issn       = {1096-9861},
  language   = {en},
  number     = {n/a},
  volume     = {n/a},
  abstract   = {This review in memoriam of Jack Pettigrew provides an overview of past and current research into the phenomenon of multistable perception across multiple animal species. Multistable perception is characterized by two or more perceptual interpretations spontaneously alternating, or rivalling, when animals are exposed to stimuli with inherent sensory ambiguity. There is a wide array of ambiguous stimuli across sensory modalities, ranging from the configural changes observed in simple line drawings, such as the famous Necker cube, to the alternating perception of entire visual scenes that can be instigated by interocular conflict. The latter phenomenon, called binocular rivalry, in particular caught the attention of the late Jack Pettigrew, who combined his interest in the neuronal basis of perception with a unique comparative biological approach that considered ambiguous sensation as a fundamental problem of sensory systems that has shaped the brain throughout evolution. Here, we examine the research findings on visual perceptual alternation and suppression in a wide variety of species including insects, fish, reptiles and primates. We highlight several interesting commonalities across species and behavioral indicators of perceptual alternation. In addition, we show how the comparative approach provides new avenues for understanding how the brain suppresses opposing sensory signals and generates alternations in perceptual dominance. This article is protected by copyright. All rights reserved.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/cne.24939},
  copyright  = {\textcopyright{} 2020 Wiley Periodicals, Inc.},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/perception/multiStablePerception_msp/carter2020per.pdf},
  ids        = {carterPerceptualRivalryAnimal},
  journal    = {Journal of Comparative Neurology},
  keywords   = {binocular rivalry,Binocular Rivalry,Drosophila,fish,Fish,multistable,Multistable,perception,Perception,primate,Primate,read,review,suppression,Suppression},
  readstatus = {read},
  year       = {2020},
}

@TechReport{logothetisStudiesLargeScaleNetworks2014,
  author      = {Logothetis, Nikos},
  institution = {{Max Planck Institute for Biological Cybernetics}},
  title       = {Studies of {{Large}}-{{Scale Networks}} with {{DES}}- \& {{NET}}-{{fMRI}}},
  abstract    = {Nikos K. Logothetis Brains are exquisite examples of an adaptive self-organizing system. Our entire behavior is nothing but a reflection of a global-order or coordination that arises out of the local interactions between the vast number of functional components of an initially disordered system. Understanding such systems requires concurrent studies of microcircuits, of local and long- range interconnectivity between small assemblies, and of the synergistic activity of larger neuronal populations. The document briefly describes our current and future projects that rely on multimodal methodologies, such as electrophysiology, pharmacology, and microstimulation, as well as on noninvasive global neuroimaging techniques},
  year        = {2014},
}

@Article{anastassiouEphapticCouplingEndogenous2014,
  author   = {Anastassiou, C. A. and Koch, C.},
  title    = {Ephaptic Coupling to Endogenous Electric Field Activity: Why Bother?},
  doi      = {10.1016/j.conb.2014.09.002},
  issn     = {1873-6882 (Electronic) 0959-4388 (Linking)},
  pages    = {95--103},
  volume   = {31C},
  abstract = {There has been a revived interest in the impact of electric fields on neurons and networks. Here, we discuss recent advances in our understanding of how endogenous and externally imposed electric fields impact brain function at different spatial (from synapses to single neurons and neural networks) and temporal scales (from milliseconds to seconds). How such ephaptic effects are mediated and manifested in the brain remains a mystery. We argue that it is both possible (based on available technologies) and worthwhile to vigorously pursue such research as it has significant implications on our understanding of brain processing and for translational neuroscience.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neuralInteractions/ephaptic/anastassiou2014eph.pdf},
  journal  = {Current Opinion in Neurobiology},
  keywords = {review},
  month    = sep,
  year     = {2014},
}

@Article{yuanInflammationrelatedBiomarkersMajor2019,
  author     = {Yuan, Ning and Chen, Yu and Xia, Yan and Dai, Jiacheng and Liu, Chunyu},
  title      = {Inflammation-Related Biomarkers in Major Psychiatric Disorders: A Cross-Disorder Assessment of Reproducibility and Specificity in 43 Meta-Analyses},
  doi        = {10.1038/s41398-019-0570-y},
  issn       = {2158-3188},
  language   = {en},
  number     = {1},
  pages      = {1--13},
  volume     = {9},
  abstract   = {Inflammation is a natural defence response of the immune system against environmental insult, stress and injury, but hyper- and hypo-inflammatory responses can trigger diseases. Accumulating evidence suggests that inflammation is involved in multiple psychiatric disorders. Using inflammation-related factors as biomarkers of psychiatric disorders requires the proof of reproducibility and specificity of the changes in different disorders, which remains to be established. We performed a cross-disorder study by systematically evaluating the meta-analysis results of inflammation-related factors in eight major psychiatric disorders, including schizophrenia (SCZ), bipolar disorder (BD), autism spectrum disorder (ASD), major depression disorder (MDD), post-trauma stress disorder (PTSD), sleeping disorder (SD), obsessive\textendash compulsive disorder (OCD) and suicide. A total of 43 meta-analyses involving 704 publications on 44 inflammation-related factors were included in the study. We calculated the effect size and statistical power for every inflammation-related factor in each disorder. Our analyses showed that well-powered case\textendash control studies provided more consistent results than underpowered studies when one factor was meta-analysed by different researchers. After removing underpowered studies, 30 of the 44 inflammation-related factors showed significant alterations in at least one disorder based on well-powered meta-analyses. Eleven of them changed in patients of more than two disorders when compared with the controls. A few inflammation-related factors showed unique changes in specific disorders (e.g., IL-4 increased in BD, decreased in suicide, but had no change in MDD, ASD, PTSD and SCZ). MDD had the largest number of changes while SD has the least. Clustering analysis showed that closely related disorders share similar patterns of inflammatory changes, as genome-wide genetic studies have found. According to the effect size obtained from the meta-analyses, 13 inflammation-related factors would need {$<$}50 cases and 50 controls to achieve 80\% power to show significant differences (p\,{$<$}\,0.0016) between patients and controls. Changes in different states of MDD, SCZ or BD were also observed in various comparisons. Studies comparing first-episode SCZ to controls may have more reproducible findings than those comparing pre- and post-treatment results. Longitudinal, system-wide studies of inflammation regulation that can differentiate trait- and state-specific changes will be needed to establish valuable biomarkers.},
  copyright  = {2019 The Author(s)},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/ImmunoNeuro/yuan2019inf.pdf},
  journal    = {Translational Psychiatry},
  month      = sep,
  shorttitle = {Inflammation-Related Biomarkers in Major Psychiatric Disorders},
  year       = {2019},
}

@Article{sherfeyPrefrontalOscillationsModulate2020a,
  author   = {Sherfey, Jason and Ardid, Salva and Miller, Earl K. and Hasselmo, Michael E. and Kopell, Nancy J.},
  title    = {Prefrontal Oscillations Modulate the Propagation of Neuronal Activity Required for Working Memory},
  doi      = {10.1016/j.nlm.2020.107228},
  issn     = {1074-7427},
  language = {en},
  pages    = {107228},
  volume   = {173},
  abstract = {Cognition involves using attended information, maintained in working memory (WM), to guide action. During a cognitive task, a correct response requires flexible, selective gating so that only the appropriate information flows from WM to downstream effectors that carry out the response. In this work, we used biophysically-detailed modeling to explore the hypothesis that network oscillations in prefrontal cortex (PFC), leveraging local inhibition, can independently gate responses to items in WM. The key role of local inhibition was to control the period between spike bursts in the outputs, and to produce an oscillatory response no matter whether the WM item was maintained in an asynchronous or oscillatory state. We found that the WM item that induced an oscillatory population response in the PFC output layer with the shortest period between spike bursts was most reliably propagated. The network resonant frequency (i.e., the input frequency that produces the largest response) of the output layer can be flexibly tuned by varying the excitability of deep layer principal cells. Our model suggests that experimentally-observed modulation of PFC beta-frequency (15\textendash 30~Hz) and gamma-frequency (30\textendash 80~Hz) oscillations could leverage network resonance and local inhibition to govern the flexible routing of signals in service to cognitive processes like gating outputs from working memory and the selection of rule-based actions. Importantly, we show for the first time that nonspecific changes in deep layer excitability can tune the output gate's resonant frequency, enabling the specific selection of signals encoded by populations in asynchronous or fast oscillatory states. More generally, this represents a dynamic mechanism by which adjusting network excitability can govern the propagation of asynchronous and oscillatory signals throughout neocortex.},
  journal  = {Neurobiology of Learning and Memory},
  keywords = {Beta rhythm,Cognition,Gamma rhythm,Gating,Resonance,Working memory},
  month    = sep,
  year     = {2020},
}
% == BibTeX quality report for dayanFastOscillationsCortical2000:
% Missing required field 'journal'

@Article{dayanHierarchicalModelBinocular1998,
  author     = {Dayan, Peter},
  title      = {A {{Hierarchical Model}} of {{Binocular Rivalry}}},
  doi        = {10.1162/089976698300017377},
  issn       = {0899-7667 1530-888X},
  language   = {en},
  number     = {5},
  pages      = {1119--1135},
  volume     = {10},
  abstract   = {Binocular rivalry is the alternating percept that can result when the two eyes see different scenes. Recent psychophysical evidence supports the notion that some aspects of binocular rivalry bear functional similarities to other bistable percepts. We build a model based on the hypothesis (Logothetis \& Schall, 1989; Leopold \& Logothetis, 1996; Logothetis, Leopold, \& Sheinberg, 1996) that alternation can be generated by competition between top-down cortical explanations for the inputs, rather than by direct competition between the inputs. Recent neurophysiological evidence shows that some binocular neurons are modulated with the changing percept; others are not, even if they are selective between the stimuli presented to the eyes. We extend our model to a hierarchy to address these effects.},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/perception/multiStablePerception_msp/models/dayan2006a.pdf},
  journal    = {Neural Comput},
  keywords   = {238 Main St.; Suite 500; Cambridge; MA 02142-1046 USA journals-info@mit.edu,read},
  readstatus = {read},
  year       = {1998},
}

@Article{marrUnderstandingComputationUnderstanding1979,
  author     = {Marr, D. and Poggio, T.},
  title      = {From {{Understanding Computation}} to {{Understanding Neural Circuitry}}},
  number     = {3},
  pages      = {470--488},
  volume     = {15},
  abstract   = {Author: Marr, D et al.; Genre: Journal Article; Published in Print: 1979; Title: From Understanding Computation to Understanding Neural Circuitry},
  journal    = {Neuroscience Research Program Bulletin},
  keywords   = {read},
  readstatus = {read},
  year       = {1979},
}
% == BibTeX quality report for kfirNaturalVariationNeural2012:
% ? Title looks like it was stored in title-case in Zotero

@Article{khajehabdollahiEmergenceIntegratedInformation2019,
  author    = {Khajehabdollahi, Sina and Abeyasinghe, Pubuditha and Owen, Adrian and Soddu, Andrea},
  title     = {The Emergence of Integrated Information, Complexity, and Consciousness at Criticality},
  doi       = {10.1101/521567},
  language  = {en},
  pages     = {521567},
  abstract  = {{$<$}p{$>$}Using the critical Ising model of the brain, integrated information as a measure of consciousness is measured in toy models of generic neural networks. Monte Carlo simulations are run on 159 random weighted networks analogous to small 5 node neural network motifs. The integrated information generated by this sample of small Ising models is measured across the model parameter space. It is observed that integrated information, as a type of order parameter not unlike a concept like magnetism, undergoes a phase transition at the critical point in the model. This critical point is demarcated by the peaks of the generalized susceptibility of integrated information, a point where the `consciousness9 of the system is maximally susceptible to perturbations and on the boundary between an ordered and disordered form. This study adds further evidence to support that the emergence of consciousness coincides with the more universal patterns of self-organized criticality, evolution, the emergence of complexity, and the integration of complex systems.{$<$}/p{$>$}},
  copyright = {\textcopyright{} 2019, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
  file      = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/criticality/khajehabdollahi2019the.pdf},
  journal   = {bioRxiv},
  month     = jan,
  year      = {2019},
}

@Article{paivaInnerProductsRepresentation2010,
  author   = {Paiva, A. R. C. and Park, I. and Principe, J. C.},
  title    = {Inner {{Products}} for {{Representation}} and {{Learning}} in the {{Spike Train Domain}}},
  doi      = {10.1016/B978-0-12-375027-3.00008-9},
  language = {English},
  pages    = {265--309},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/nda_kernelMethods/paiva2010inn.pdf},
  journal  = {Statistical Signal Processing for Neuroscience and Neurotechnology},
  keywords = {framework,metric-space analysis,neuronal data,precision,probability,redundancy,reliability,rkhs approach,signals,visual-cortex},
  year     = {2010},
}

@Article{santoLandauGinzburgTheory2018,
  author     = {di Santo, Serena and Villegas, Pablo and Burioni, Raffaella and Mu{\~n}oz, Miguel A.},
  title      = {Landau\textendash{{Ginzburg}} Theory of Cortex Dynamics: {{Scale}}-Free Avalanches Emerge at the Edge of Synchronization},
  doi        = {10.1073/pnas.1712989115},
  issn       = {0027-8424, 1091-6490},
  language   = {en},
  pages      = {201712989},
  abstract   = {Understanding the origin, nature, and functional significance of complex patterns of neural activity, as recorded by diverse electrophysiological and neuroimaging techniques, is a central challenge in neuroscience. Such patterns include collective oscillations emerging out of neural synchronization as well as highly heterogeneous outbursts of activity interspersed by periods of quiescence, called ``neuronal avalanches.'' Much debate has been generated about the possible scale invariance or criticality of such avalanches and its relevance for brain function. Aimed at shedding light onto this, here we analyze the large-scale collective properties of the cortex by using a mesoscopic approach following the principle of parsimony of Landau\textendash Ginzburg. Our model is similar to that of Wilson\textendash Cowan for neural dynamics but crucially, includes stochasticity and space; synaptic plasticity and inhibition are considered as possible regulatory mechanisms. Detailed analyses uncover a phase diagram including down-state, synchronous, asynchronous, and up-state phases and reveal that empirical findings for neuronal avalanches are consistently reproduced by tuning our model to the edge of synchronization. This reveals that the putative criticality of cortical dynamics does not correspond to a quiescent-to-active phase transition as usually assumed in theoretical approaches but to a synchronization phase transition, at which incipient oscillations and scale-free avalanches coexist. Furthermore, our model also accounts for up and down states as they occur (e.g., during deep sleep). This approach constitutes a framework to rationalize the possible collective phases and phase transitions of cortical networks in simple terms, thus helping to shed light on basic aspects of brain functioning from a very broad perspective.},
  copyright  = {\textcopyright{} 2018 . Published under the PNAS license.},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/criticality/santo2018lan.pdf},
  journal    = {Proceedings of the National Academy of Sciences},
  keywords   = {cortical dynamics,criticality,neural oscillations,neuronal avalanches,read,synchronization},
  month      = jan,
  pmid       = {29378970},
  readstatus = {read},
  shorttitle = {Landau\textendash{{Ginzburg}} Theory of Cortex Dynamics},
  year       = {2018},
}

@Article{kapoorDecodingContentsConsciousness2020,
  author    = {Kapoor, Vishal and Dwarakanath, Abhilash and Safavi, Shervin and Werner, Joachim and Besserve, Michel and Panagiotaropoulos, Theofanis I. and Logothetis, Nikos K.},
  title     = {Decoding the Contents of Consciousness from Prefrontal Ensembles},
  doi       = {10.1101/2020.01.28.921841},
  language  = {en},
  pages     = {2020.01.28.921841},
  abstract  = {{$<$}h3{$>$}ABSTRACT{$<$}/h3{$>$} {$<$}p{$>$}Multiple theories attribute to the primate prefrontal cortex a critical role in conscious perception. However, opposing views caution that prefrontal activity could reflect other cognitive variables during paradigms investigating consciousness, such as decision-making, monitoring and motor reports. To resolve this ongoing debate, we recorded from prefrontal ensembles of macaque monkeys during a no-report paradigm of binocular rivalry that instigates internally driven transitions in conscious perception. We could decode the contents of consciousness from prefrontal ensemble activity during binocular rivalry with an accuracy similar to when these stimuli were presented without competition. Oculomotor signals, used to infer conscious content, were not the only source of these representations since visual input could be significantly decoded when eye movements were suppressed. Our results suggest that the collective dynamics of prefrontal cortex populations reflect internally generated changes in the content of consciousness during multistable perception.{$<$}/p{$><$}h3{$>$}One sentence summary{$<$}/h3{$>$} {$<$}p{$>$}Neural correlates of conscious perception can be detected and perceptual contents can be reliably decoded from the spiking activity of prefrontal populations.{$<$}/p{$>$}},
  chapter   = {New Results},
  copyright = {\textcopyright{} 2020, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
  file      = {/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/perception/multiStablePerception_msp/observations/kapoor2020dec.pdf},
  journal   = {bioRxiv},
  month     = jan,
  publisher = {{Cold Spring Harbor Laboratory}},
  year      = {2020},
}
% == BibTeX quality report for shialComparisonStudyFile2015:
% ? Title looks like it was stored in title-case in Zotero

@Article{shieldsPsychosocialInterventionsImmune2020,
  author     = {Shields, Grant S. and Spahr, Chandler M. and Slavich, George M.},
  title      = {Psychosocial {{Interventions}} and {{Immune System Function}}: {{A Systematic Review}} and {{Meta}}-Analysis of {{Randomized Clinical Trials}}},
  doi        = {10.1001/jamapsychiatry.2020.0431},
  issn       = {2168-622X},
  language   = {en},
  number     = {10},
  pages      = {1031--1043},
  volume     = {77},
  abstract   = {{$<$}h3{$>$}Importance{$<$}/h3{$><$}p{$>$}Recent estimates suggest that more than 50\% of all deaths worldwide are currently attributable to inflammation-related diseases. Psychosocial interventions may represent a potentially useful strategy for addressing this global public health problem, but which types of interventions reliably improve immune system function, under what conditions, and for whom are unknown.{$<$}/p{$><$}h3{$>$}Objective{$<$}/h3{$><$}p{$>$}To address this issue, we conducted a systematic review and meta-analysis of randomized clinical trials (RCTs) in which we estimated associations between 8 different psychosocial interventions and 7 markers of immune system function, and examined 9 potential moderating factors.{$<$}/p{$><$}h3{$>$}Data Sources{$<$}/h3{$><$}p{$>$}PubMed, Scopus, PsycInfo, and ClinicalTrials.gov databases were systematically searched from February 1, 2017, to December 31, 2018, for all relevant RCTs published through December 31, 2018.{$<$}/p{$><$}h3{$>$}Study Selection{$<$}/h3{$><$}p{$>$}Eligible RCTs included a psychosocial intervention, immune outcome, and preintervention and postintervention immunologic assessments. Studies were independently examined by 2 investigators. Of 4621 studies identified, 62 were eligible and 56 included.{$<$}/p{$><$}h3{$>$}Data Extraction and Synthesis{$<$}/h3{$><$}p{$>$}Data were extracted and analyzed from January 1, 2019, to July 29, 2019. The Preferred Reporting Items for Systematic Reviews and Meta-analyses (PRISMA) guideline was followed. Data were extracted by 2 investigators who were blind to study hypotheses and analyses, and were then analyzed using robust variance estimation. Analysis included 8 psychosocial interventions (behavior therapy, cognitive therapy, cognitive behavior therapy [CBT], CBT plus additive treatment or mode of delivery that augmented the CBT, bereavement or supportive therapy, multiple or combined interventions, other psychotherapy, and psychoeducation), 7 immune outcomes (proinflammatory cytokine or marker levels, anti-inflammatory cytokine levels, antibody levels, immune cell counts, natural killer cell activity, viral load, and other immune outcomes), and 9 moderating factors (intervention type, intervention format, intervention length, immune marker type, basal vs stimulated markers, immune marker measurement timing, disease state or reason for treatment, age, and sex).{$<$}/p{$><$}h3{$>$}Main Outcomes and Measures{$<$}/h3{$><$}p{$>$}The primary a priori outcomes were pretest-posttest-control (ppc) group effect sizes (ppc\emph{g}) for the 7 immunologic outcomes investigated.{$<$}/p{$><$}h3{$>$}Results{$<$}/h3{$><$}p{$>$}Across 56 RCTs and 4060 participants, psychosocial interventions were associated with enhanced immune system function (ppc\emph{g} = 0.30, 95\% CI, 0.21-0.40;\emph{t}\textsubscript{50.9} = 6.22;\emph{P} \&lt; .001). Overall, being randomly assigned to a psychosocial intervention condition vs a control condition was associated with a 14.7\% (95\% CI, 5.7\%-23.8\%) improvement in beneficial immune system function and an 18.0\% (95\% CI, 7.2\%-28.8\%) decrease in harmful immune system function over time. These associations persisted for at least 6 months following treatment and were robust across age, sex, and intervention duration. These associations were most reliable for CBT (ppc\emph{g} = 0.33, 95\% CI, 0.19-0.47;\emph{t}\textsubscript{27.2} = 4.82;\emph{P} \&lt; .001) and multiple or combined interventions (ppc\emph{g} = 0.52, 95\% CI, 0.17-0.88;\emph{t}\textsubscript{5.7} = 3.63;\emph{P} = .01), and for studies that assessed proinflammatory cytokines or markers (ppc\emph{g} = 0.33, 95\% CI, 0.19-0.48;\emph{t}\textsubscript{25.6} = 4.70;\emph{P} \&lt; .001).{$<$}/p{$><$}h3{$>$}Conclusions and Relevance{$<$}/h3{$><$}p{$>$}These findings suggest that psychosocial interventions are reliably associated with enhanced immune system function and may therefore represent a viable strategy for improving immune-related health.{$<$}/p{$>$}},
  journal    = {JAMA Psychiatry},
  month      = oct,
  publisher  = {{American Medical Association}},
  shorttitle = {Psychosocial {{Interventions}} and {{Immune System Function}}},
  year       = {2020},
}

@Article{steveninckReproducibilityVariabilityNeural1997,
  author    = {van Steveninck, Rob R. de Ruyter and Lewen, Geoffrey D. and Strong, Steven P. and Koberle, Roland and Bialek, William},
  title     = {Reproducibility and {{Variability}} in {{Neural Spike Trains}}},
  doi       = {10.1126/science.275.5307.1805},
  issn      = {0036-8075, 1095-9203},
  language  = {en},
  number    = {5307},
  pages     = {1805--1808},
  volume    = {275},
  abstract  = {To provide information about dynamic sensory stimuli, the pattern of action potentials in spiking neurons must be variable. To ensure reliability these variations must be related, reproducibly, to the stimulus. For H1, a motion-sensitive neuron in the fly's visual system, constant-velocity motion produces irregular spike firing patterns, and spike counts typically have a variance comparable to the mean, for cells in the mammalian cortex. But more natural, time-dependent input signals yield patterns of spikes that are much more reproducible, both in terms of timing and of counting precision. Variability and reproducibility are quantified with ideas from information theory, and measured spike sequences in H1 carry more than twice the amount of information they would if they followed the variance-mean relation seen with constant inputs. Thus, models that may accurately account for the neural response to static stimuli can significantly underestimate the reliability of signal transfer under more natural conditions.},
  chapter   = {Report},
  copyright = {\textcopyright{} 1997 American Association for the Advancement of Science},
  journal   = {Science},
  month     = mar,
  pmid      = {9065407},
  publisher = {{American Association for the Advancement of Science}},
  year      = {1997},
}

@Article{shpiroBalanceNoiseAdaptation2009a,
  author     = {Shpiro, A. and {Moreno-Bote}, R. and Rubin, N. and Rinzel, J.},
  title      = {Balance between Noise and Adaptation in Competition Models of Perceptual Bistability},
  doi        = {10.1007/s10827-008-0125-3},
  issn       = {1573-6873 (Electronic) 0929-5313 (Linking)},
  language   = {English},
  number     = {1},
  pages      = {37--54},
  volume     = {27},
  abstract   = {Perceptual bistability occurs when a physical stimulus gives rise to two distinct interpretations that alternate irregularly. Noise and adaptation processes are two possible mechanisms for switching in neuronal competition models that describe the alternating behaviors. Either of these processes, if strong enough, could alone cause the alternations in dominance. We examined their relative role in producing alternations by studying models where by smoothly varying the parameters, one can change the rhythmogenesis mechanism from being adaptation-driven to noise-driven. In consideration of the experimental constraints on the statistics of the alternations (mean and shape of the dominance duration distribution and correlations between successive durations) we ask whether we can rule out one of the mechanisms. We conclude that in order to comply with the observed mean of the dominance durations and their coefficient of variation, the models must operate within a balance between the noise and adaptation strength-both mechanisms are involved in producing alternations, in such a way that the system operates near the boundary between being adaptation-driven and noise-driven.},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/perception/multiStablePerception_msp/models/shpiro2009bal.pdf},
  journal    = {J Comput Neurosci},
  keywords   = {*Adaptation; Physiological,*Models; Neurological,Algorithms,Animals,Feedback; Psychological/physiology,Neural Inhibition/physiology,Neuronal Plasticity/physiology,Neurons/physiology,Perception/*physiology,Periodicity,read,Synaptic Transmission/physiology,Time Factors},
  month      = aug,
  readstatus = {read},
  year       = {2009},
}

@Article{logothetisVisionWindowConsciousness2006,
  author   = {Logothetis, N. K.},
  title    = {Vision: {{A Window}} into {{Consciousness}}},
  doi      = {10.1038/scientificamerican0906-4sp},
  issn     = {0036-8733},
  language = {en},
  number   = {3},
  pages    = {4--11},
  volume   = {16},
  file     = {/Users/ssafavi/Documents/libraries/EndnoteLib_fromWin407/EndnoteLib_MPIPClocal_20170723.Data/PDF/3429635083/Logothetis-2006.pdf},
  journal  = {Scientific American},
  month    = sep,
  year     = {2006},
}

@Misc{bahmaniNeuralCorrelatesBinocular2011,
  author   = {Bahmani, H. and Logothetis, N. and Keliris, G.},
  title    = {Neural Correlates of Binocular Rivalry in Parietal Cortex},
  abstract = {Frontiers Events is a rapidly growing calendar management system dedicated to the scheduling of academic events. This includes announcements and invitations, participant listings and search functionality, abstract handling and publication, related events and post-event exchanges. Whether an organizer or participant, make your event a Frontiers Event!},
  address  = {{Freiburg, Germany}},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/perception/multiStablePerception_msp/bahmani2011neu.docx;/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/perception/multiStablePerception_msp/bahmani2011neu.pdf},
  keywords = {Frontiers},
  year     = {2011},
}

@Article{schillerNeuronalRegulationImmunity2020,
  author     = {Schiller, Maya and {Ben-Shaanan}, Tamar L. and Rolls, Asya},
  title      = {Neuronal Regulation of Immunity: Why, How and Where?},
  doi        = {10.1038/s41577-020-0387-1},
  issn       = {1474-1741},
  language   = {en},
  pages      = {1--17},
  abstract   = {Neuroimmunology is one of the fastest-growing fields in the life sciences, and for good reason; it fills the gap between two principal systems of the organism, the nervous system and the immune system. Although both systems affect each other through bidirectional interactions, we focus here on one direction \textemdash{} the effects of the nervous system on immunity. First, we ask why is it beneficial to allow the nervous system any control over immunity? We evaluate the potential benefits to the immune system that arise by taking advantage of some of the brain's unique features, such as its capacity to integrate and synchronize physiological functions, its predictive capacity and its speed of response. Second, we explore how the brain communicates with the peripheral immune system, with a focus on the endocrine, sympathetic, parasympathetic, sensory and meningeal lymphatic systems. Finally, we examine where in the brain this immune information is processed and regulated. We chart a partial map of brain regions that may be relevant for brain\textendash immune system communication, our goal being to introduce a conceptual framework for formulating new hypotheses to study these interactions.},
  copyright  = {2020 Springer Nature Limited},
  journal    = {Nature Reviews Immunology},
  month      = aug,
  publisher  = {{Nature Publishing Group}},
  shorttitle = {Neuronal Regulation of Immunity},
  year       = {2020},
}

@Article{bassettUnderstandingComplexityHuman2011,
  author     = {Bassett, D. S. and Gazzaniga, M. S.},
  title      = {Understanding Complexity in the Human Brain},
  doi        = {10.1016/j.tics.2011.03.006},
  issn       = {1879-307X (Electronic) 1364-6613 (Linking)},
  pages      = {200--9},
  volume     = {15},
  abstract   = {Although the ultimate aim of neuroscientific enquiry is to gain an understanding of the brain and how its workings relate to the mind, the majority of current efforts are largely focused on small questions using increasingly detailed data. However, it might be possible to successfully address the larger question of mind-brain mechanisms if the cumulative findings from these neuroscientific studies are coupled with complementary approaches from physics and philosophy. The brain, we argue, can be understood as a complex system or network, in which mental states emerge from the interaction between multiple physical and functional levels. Achieving further conceptual progress will crucially depend on broad-scale discussions regarding the properties of cognition and the tools that are currently available or must be developed in order to study mind-brain mechanisms.},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neuroprinciples/connectomics/bassett2011und.pdf},
  journal    = {Trends Cogn Sci},
  keywords   = {*Brain Mapping,*Psychophysiology,Animals,Brain/anatomy \& histology/*physiology,Humans,Mental Processes/*physiology,Models; Neurological,Models; Psychological,Neural Pathways/physiology,read,review},
  month      = may,
  pmcid      = {PMC3170818},
  readstatus = {read},
  year       = {2011},
}

@Book{sethnaStatisticalMechanicsEntropy2006,
  author      = {Sethna, James and Sethna, Laboratory of Atomic {and} Solid State Physics James P.},
  title       = {Statistical {{Mechanics}}: {{Entropy}}, {{Order Parameters}}, and {{Complexity}}},
  isbn        = {978-0-19-856676-2},
  language    = {en},
  publisher   = {{OUP Oxford}},
  abstract    = {In each generation, scientists must redefine their fields: abstracting, simplifying and distilling the previous standard topics to make room for new advances and methods. Sethna's book takes this step for statistical mechanics--a field rooted in physics and chemistry whose ideas and methods are now central to information theory, complexity, and modern biology. Aimed at advanced undergraduates and early graduate students in all of these fields, Sethna limits his main presentation to the topics that future mathematicians and biologists, as well as physicists and chemists, will find fascinating and central to their work. The amazing breadth of the field is reflected in the author's large supply of carefully crafted exercises, each an introduction to a whole field of study: everything from chaos through information theory to life at the end of the universe.},
  googlebooks = {O09uBAAAQBAJ},
  keywords    = {Computers / Desktop Applications / Design \& Graphics,Mathematics / Applied,Science / Mechanics / Thermodynamics,Science / Physics / Atomic \& Molecular,Science / Physics / Condensed Matter,Science / Physics / General,Science / Physics / Quantum Theory,Technology \& Engineering / Mechanical},
  month       = apr,
  shorttitle  = {Statistical {{Mechanics}}},
  year        = {2006},
}
% == BibTeX quality report for vandenbrinkBrainstemModulationLargeScale2019:
% ? Title looks like it was stored in title-case in Zotero

@Article{vandenheuvelMultiscaleNeurosciencePsychiatric2019,
  author   = {{van den Heuvel}, Martijn P. and Scholtens, Lianne H. and Kahn, Ren{\'e} S.},
  title    = {Multi-Scale Neuroscience of Psychiatric Disorders},
  doi      = {10.1016/j.biopsych.2019.05.015},
  issn     = {0006-3223},
  abstract = {The human brain comprises a multi-scale network with multiple levels of organization. Neurons with dendritic and axonal connections form the microscale fabric of brain circuitry, and macroscale brain regions and white matter connections form the infrastructure for system level brain communication and information integration. In this review we discuss the emerging trend of `multi-scale neuroscience', the multi-disciplinary field that brings together data from these different levels of nervous system organization to form a better understanding of between-scale relationships of brain structure, function and behavior in health and disease. We provide a broad overview of this developing field, and discuss recent findings of exemplary multi-scale neuroscience studies that illustrate the importance of studying cross-scale interactions between the genetic, molecular, cellular, and macroscale level of brain circuitry and connectivity and behavior. We particularly consider a central, overarching goal of these `multi-scale neuroscience' studies of human brain connectivity: to obtain insight into how disease-related alterations at one level of organization may underlie alterations observed at other scales of brain network organization in mental disorders. We conclude by discussing the current limitations, challenges and future directions of the field.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/psychiatry/cmpsy/van_den_heuvel2019mul.pdf;/home/ssafavi/Nextcloud/libraries/zoteroLib/psychiatry/cmpsy/van_den_heuvel2019mul.html},
  journal  = {Biological Psychiatry},
  keywords = {brain network,connectivity,cross-scale,mental disorders,multi-scale,psychiatry},
  month    = may,
  year     = {2019},
}

@InCollection{schwalmCortexwideBOLDFMRI2017,
  author    = {Schwalm, M. and Schmid, F. and Wachsmuth, L. and Backhaus, H. and Kronfeld, A. and Aedo Jury, F. and Prouvot, P. H. and Fois, C. and Albers, F. and {van Alst}, T. and Faber, C. and Stroh, A.},
  booktitle = {{{eLife}}},
  title     = {Cortex-Wide {{BOLD fMRI}} Activity Reflects Locally-Recorded Slow Oscillation-Associated Calcium Waves},
  isbn      = {2050-084X (Electronic)},
  language  = {eng},
  volume    = {6},
  abstract  = {Spontaneous slow oscillation-associated slow wave activity represents an internally generated state which is characterized by alternations of network quiescence and stereotypical episodes of neuronal activity - slow wave events. However, it remains unclear which macroscopic signal is related to these active periods of the slow wave rhythm. We used optic fiber-based calcium recordings of local neural populations in cortex and thalamus to detect neurophysiologically defined slow calcium waves in isoflurane anesthetized rats. The individual slow wave events were used for an event-related analysis of simultaneously acquired whole-brain BOLD fMRI. We identified BOLD responses directly related to onsets of slow calcium waves, revealing a cortex-wide BOLD correlate: the entire cortex was engaged in this specific type of slow wave activity. These findings demonstrate a direct relation of defined neurophysiological events to a specific BOLD activity pattern and were confirmed for ongoing slow wave activity by independent component and seed-based analyses.},
  file      = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/multiModal/schwalm2017cor.pdf},
  year      = {2017},
}

@Article{pfeifferBrainImmuneCells2020,
  author     = {Pfeiffer, Thomas and Attwell, David},
  title      = {Brain's Immune Cells Put the Brakes on Neurons},
  doi        = {10.1038/d41586-020-02713-7},
  language   = {en},
  abstract   = {A role for microglia in adenosine-mediated neuronal inhibition.},
  copyright  = {2020 Nature},
  journal    = {Nature},
  keywords   = {read},
  month      = sep,
  publisher  = {{Nature Publishing Group}},
  readstatus = {read},
  year       = {2020},
}

@Article{agrawalScaleChangeSymmetryRules2019,
  author     = {Agrawal, Vidit and Chakraborty, Srimoy and Kn{\"o}pfel, Thomas and Shew, Woodrow L.},
  title      = {Scale-{{Change Symmetry}} in the {{Rules Governing Neural Systems}}},
  doi        = {10.1016/j.isci.2019.01.009},
  issn       = {2589-0042},
  pages      = {121--131},
  volume     = {12},
  abstract   = {Summary Similar universal phenomena can emerge in different complex systems when those systems share a common symmetry in their governing laws. In physical systems operating near a critical phase transition, the governing physical laws obey a fractal symmetry; they are the same whether considered at fine or coarse scales. This scale-change symmetry is responsible for universal critical phenomena found across diverse systems. Experiments suggest that the cerebral cortex can also operate near a critical phase transition. Thus we hypothesize that the laws governing cortical dynamics may obey scale-change symmetry. Here we develop a practical approach to test this hypothesis. We confirm, using two different computational models, that neural dynamical laws exhibit scale-change symmetry near a dynamical phase transition. Moreover, we show that as a mouse awakens from anesthesia, scale-change symmetry emerges. Scale-change symmetry of the rules governing cortical dynamics may explain observations of similar critical phenomena across diverse neural systems.},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/criticality/agrawal2019sca.pdf;/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/criticality/agrawal2019sca.html},
  journal    = {iScience},
  keywords   = {Mathematical Biosciences,read,Statistical Mechanics,Systems Neuroscience},
  month      = feb,
  readstatus = {read},
  year       = {2019},
}

@Article{pesaranInvestigatingLargescaleBrain2018,
  author     = {Pesaran, Bijan and Vinck, Martin and Einevoll, Gaute T. and Sirota, Anton and Fries, Pascal and Siegel, Markus and Truccolo, Wilson and Schroeder, Charles E. and Srinivasan, Ramesh},
  title      = {Investigating Large-Scale Brain Dynamics Using Field Potential Recordings: Analysis and Interpretation},
  doi        = {10.1038/s41593-018-0171-8},
  issn       = {1546-1726},
  language   = {en},
  pages      = {1},
  abstract   = {This article presents best practices on how field potential recordings (EEG, MEG, ECoG and LFP) can be analyzed to identify large-scale brain dynamics, and highlights issues and limitations of interpretation.},
  copyright  = {2018 The Author(s)},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neurophysiology/lfp/pesaran2018inv.pdf},
  journal    = {Nature Neuroscience},
  keywords   = {r7,read,review},
  month      = jun,
  readstatus = {read},
  shorttitle = {Investigating Large-Scale Brain Dynamics Using Field Potential Recordings},
  year       = {2018},
}

@Article{bokilChronuxPlatformAnalyzing2010,
  author   = {Bokil, H. and Andrews, P. and Kulkarni, J. E. and Mehta, S. and Mitra, P. P.},
  title    = {Chronux: A Platform for Analyzing Neural Signals},
  doi      = {10.1016/j.jneumeth.2010.06.020},
  issn     = {1872-678X (Electronic) 0165-0270 (Linking)},
  number   = {1},
  pages    = {146--51},
  volume   = {192},
  abstract = {Chronux is an open-source software package developed for the analysis of neural data. The current version of Chronux includes software for signal processing of neural time-series data including several specialized mini-packages for spike-sorting, local regression, audio segmentation, and other data-analysis tasks typically encountered by a neuroscientist. Chronux is freely available along with user tutorials, sample data, and extensive documentation from http://chronux.org/.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/projects/nnr/MT/bokil2010chr.pdf},
  journal  = {J Neurosci Methods},
  keywords = {*Software,Action Potentials/*physiology,Animals,Humans,Likelihood Functions,Neurons/*physiology,Regression Analysis,Spectrum Analysis,Statistics as Topic/*methods},
  month    = sep,
  year     = {2010},
}
% == BibTeX quality report for costaSubcorticalSubstratesExploreExploit2019:
% ? Title looks like it was stored in title-case in Zotero

@Article{costaThalamocorticalNeuralMass2016,
  author    = {Costa, Michael Schellenberger and Weigenand, Arne and Ngo, Hong-Viet V. and Marshall, Lisa and Born, Jan and Martinetz, Thomas and Claussen, Jens Christian},
  title     = {A {{Thalamocortical Neural Mass Model}} of the {{EEG}} during {{NREM Sleep}} and {{Its Response}} to {{Auditory Stimulation}}},
  doi       = {10.1371/journal.pcbi.1005022},
  issn      = {1553-7358},
  language  = {en},
  number    = {9},
  pages     = {e1005022},
  volume    = {12},
  abstract  = {Few models exist that accurately reproduce the complex rhythms of the thalamocortical system that are apparent in measured scalp EEG and at the same time, are suitable for large-scale simulations of brain activity. Here, we present a neural mass model of the thalamocortical system during natural non-REM sleep, which is able to generate fast sleep spindles (12\textendash 15 Hz), slow oscillations ({$<$}1 Hz) and K-complexes, as well as their distinct temporal relations, and response to auditory stimuli. We show that with the inclusion of detailed calcium currents, the thalamic neural mass model is able to generate different firing modes, and validate the model with EEG-data from a recent sleep study in humans, where closed-loop auditory stimulation was applied. The model output relates directly to the EEG, which makes it a useful basis to develop new stimulation protocols.},
  file      = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/learning_memory_sleep/costa2016a.pdf},
  journal   = {PLOS Computational Biology},
  keywords  = {Depolarization,Electroencephalography,Functional electrical stimulation,Gamma-aminobutyric acid,Membrane potential,Memory consolidation,Sleep,Thalamus},
  month     = sep,
  publisher = {{Public Library of Science}},
  year      = {2016},
}

@Article{mathisEmergenceLifeFirstOrder2017,
  author    = {Mathis, Cole and Bhattacharya, Tanmoy and Walker, Sara Imari},
  title     = {The {{Emergence}} of {{Life}} as a {{First}}-{{Order Phase Transition}}},
  doi       = {10.1089/ast.2016.1481},
  issn      = {1531-1074},
  number    = {3},
  pages     = {266--276},
  volume    = {17},
  abstract  = {It is well known that life on Earth alters its environment over evolutionary and geological timescales. An important open question is whether this is a result of evolutionary optimization or a universal feature of life. In the latter case, the origin of life would be coincident with a shift in environmental conditions. Here we present a model for the emergence of life in which replicators are explicitly coupled to their environment through the recycling of a finite supply of resources. The model exhibits a dynamic, first-order phase transition from nonlife to life, where the life phase is distinguished by selection on replicators. We show that environmental coupling plays an important role in the dynamics of the transition. The transition corresponds to a redistribution of matter in replicators and their environment, driven by selection on replicators, exhibiting an explosive growth in diversity as replicators are selected. The transition is accurately tracked by the mutual information shared between replicators and their environment. In the absence of successfully repartitioning system resources, the transition fails to complete, leading to the possibility of many frustrated trials before life first emerges. Often, the replicators that initiate the transition are not those that are ultimately selected. The results are consistent with the view that life's propensity to shape its environment is indeed a universal feature of replicators, characteristic of the transition from nonlife to life. We discuss the implications of these results for understanding life's emergence and evolutionary transitions more broadly. Key Words: Origin of life\textemdash Prebiotic evolution\textemdash Astrobiology\textemdash Biopolymers\textemdash Life. Astrobiology 17, 266\textendash 276.},
  journal   = {Astrobiology},
  month     = mar,
  publisher = {{Mary Ann Liebert, Inc., publishers}},
  year      = {2017},
}

@Article{smithSpatialTemporalScales2013a,
  author   = {Smith, M. A. and Sommer, M. A.},
  title    = {Spatial and Temporal Scales of Neuronal Correlation in Visual Area {{V4}}},
  doi      = {10.1523/JNEUROSCI.4782-12.2013},
  issn     = {1529-2401 (Electronic) 0270-6474 (Linking)},
  number   = {12},
  pages    = {5422--32},
  volume   = {33},
  abstract = {The spiking activity of nearby cortical neurons is correlated on both short and long time scales. Understanding this shared variability in firing patterns is critical for appreciating the representation of sensory stimuli in ensembles of neurons, the coincident influences of neurons on common targets, and the functional implications of microcircuitry. Our knowledge about neuronal correlations, however, derives largely from experiments that used different recording methods, analysis techniques, and cortical regions. Here we studied the structure of neuronal correlation in area V4 of alert macaques using recording and analysis procedures designed to match those used previously in primary visual cortex (V1), the major input to V4. We found that the spatial and temporal properties of correlations in V4 were remarkably similar to those of V1, with two notable differences: correlated variability in V4 was approximately one-third the magnitude of that in V1 and synchrony in V4 was less temporally precise than in V1. In both areas, spontaneous activity (measured during fixation while viewing a blank screen) was approximately twice as correlated as visual-evoked activity. The results provide a foundation for understanding how the structure of neuronal correlation differs among brain regions and stages in cortical processing and suggest that it is likely governed by features of neuronal circuits that are shared across the visual cortex.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neuralInteractions/PWcorrelations/smith2013spa.pdf},
  journal  = {J Neurosci},
  keywords = {Action Potentials/*physiology,Animals,Evoked Potentials; Visual/*physiology,Fixation; Ocular/physiology,Interneurons/physiology,Macaca mulatta,Male,Photic Stimulation/methods,Reaction Time/*physiology,Space Perception/*physiology,Visual Cortex/cytology/*physiology,Visual Pathways/cytology/physiology},
  month    = mar,
  year     = {2013},
}

@Article{murayamaRelationshipNeuralHemodynamic2010,
  author   = {Murayama, Y. and Biessmann, F. and Meinecke, F. C. and Muller, K. R. and Augath, M. and Oeltermann, A. and Logothetis, N. K.},
  title    = {Relationship between Neural and Hemodynamic Signals during Spontaneous Activity Studied with Temporal Kernel {{CCA}}},
  doi      = {10.1016/j.mri.2009.12.016},
  issn     = {1873-5894 (Electronic) 0730-725X (Linking)},
  pages    = {1095--103},
  volume   = {28},
  abstract = {Functional magnetic resonance imaging (fMRI) based on the so-called blood oxygen level-dependent (BOLD) contrast is a powerful tool for studying brain function not only locally but also on the large scale. Most studies assume a simple relationship between neural and BOLD activity, in spite of the fact that it is important to elucidate how the "when" and "what" components of neural activity are correlated to the "where" of fMRI data. Here we conducted simultaneous recordings of neural and BOLD signal fluctuations in primary visual (V1) cortex of anesthetized monkeys. We explored the neurovascular relationship during periods of spontaneous activity by using temporal kernel canonical correlation analysis (tkCCA). tkCCA is a multivariate method that can take into account any features in the signals that univariate analysis cannot. The method detects filters in voxel space (for fMRI data) and in frequency-time space (for neural data) that maximize the neurovascular correlation without any assumption of a hemodynamic response function (HRF). Our results showed a positive neurovascular coupling with a lag of 4-5 s and a larger contribution from local field potentials (LFPs) in the gamma range than from low-frequency LFPs or spiking activity. The method also detected a higher correlation around the recording site in the concurrent spatial map, even though the pattern covered most of the occipital part of V1. These results are consistent with those of previous studies and represent the first multivariate analysis of intracranial electrophysiology and high-resolution fMRI.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/nda_kernelMethods/murayama2010rel.pdf;/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/multiModal/murayama2010rel.pdf},
  journal  = {Magn Reson Imaging},
  keywords = {*Hemodynamics,Algorithms,Animals,Brain Mapping/methods,Brain/*pathology,Electrodes,Electrophysiology/methods,Image Processing; Computer-Assisted/methods,Macaca mulatta,Magnetic Resonance Imaging/*methods,Multivariate Analysis,Neurons/metabolism,Oxygen/*blood,Time Factors,Visual Cortex},
  month    = oct,
  year     = {2010},
}

@Article{chialvoLifeEdgeComplexity2018,
  author        = {Chialvo, Dante R.},
  title         = {Life at the Edge: Complexity and Criticality in Biological Function},
  eprint        = {1810.11737},
  eprinttype    = {arxiv},
  abstract      = {Why life is complex and --most importantly-- what is the origin of the over abundance of complexity in nature? This is a fundamental scientific question which, paraphrasing the late Per Bak, "is screaming to be answered but seldom is even being asked". In these lectures we review recent attempts across several scales to understand the origins of complex biological problems from the perspective of critical phenomena. To illustrate the approach three cases are discussed, namely the large scale brain dynamics, the characterisation of spontaneous fluctuations of proteins and the physiological complexity of the cell mitochondria network.},
  archiveprefix = {arXiv},
  file          = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/criticality/chialvo2018lif.pdf},
  journal       = {arXiv:1810.11737 [q-bio]},
  keywords      = {Quantitative Biology - Other Quantitative Biology,r6,read},
  month         = oct,
  primaryclass  = {q-bio},
  readstatus    = {read},
  shorttitle    = {Life at the Edge},
  year          = {2018},
}

@Article{hidalgoInformationbasedFitnessEmergence2014a,
  author     = {Hidalgo, J. and Grilli, J. and Suweis, S. and Munoz, M. A. and Banavar, J. R. and Maritan, A.},
  title      = {Information-Based Fitness and the Emergence of Criticality in Living Systems},
  doi        = {10.1073/pnas.1319166111},
  issn       = {1091-6490 (Electronic) 0027-8424 (Linking)},
  pages      = {10095--100},
  volume     = {111},
  abstract   = {Empirical evidence suggesting that living systems might operate in the vicinity of critical points, at the borderline between order and disorder, has proliferated in recent years, with examples ranging from spontaneous brain activity to flock dynamics. However, a well-founded theory for understanding how and why interacting living systems could dynamically tune themselves to be poised in the vicinity of a critical point is lacking. Here we use tools from statistical mechanics and information theory to show that complex adaptive or evolutionary systems can be much more efficient in coping with diverse heterogeneous environmental conditions when operating at criticality. Analytical as well as computational evolutionary and adaptive models vividly illustrate that a community of such systems dynamically self-tunes close to a critical state as the complexity of the environment increases while they remain noncritical for simple and predictable environments. A more robust convergence to criticality emerges in coevolutionary and coadaptive setups in which individuals aim to represent other agents in the community with fidelity, thereby creating a collective critical ensemble and providing the best possible tradeoff between accuracy and flexibility. Our approach provides a parsimonious and general mechanism for the emergence of critical-like behavior in living systems needing to cope with complex environments or trying to efficiently coordinate themselves as an ensemble.},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/criticality/hidalgo2014inf.pdf},
  journal    = {Proc Natl Acad Sci U S A},
  keywords   = {*Models; Neurological,adaptation,Animals,Brain/*physiology,evolution,Humans,r10,read,self-organization princNeuro},
  month      = jul,
  readstatus = {read},
  year       = {2014},
}
% == BibTeX quality report for NONLINEARDYNAMICSCOMPUTATIONAL2018:
% Missing required field 'author/editor'
% ? Title looks like it was stored in title-case in Zotero

@Article{nonnenmacherSignaturesCriticalityArise2017,
  author   = {Nonnenmacher, Marcel and Behrens, Christian and Berens, Philipp and Bethge, Matthias and Macke, Jakob H.},
  title    = {Signatures of Criticality Arise from Random Subsampling in Simple Population Models},
  doi      = {10.1371/journal.pcbi.1005718},
  issn     = {1553-7358},
  language = {en},
  number   = {10},
  pages    = {e1005718},
  volume   = {13},
  abstract = {The rise of large-scale recordings of neuronal activity has fueled the hope to gain new insights into the collective activity of neural ensembles. How can one link the statistics of neural population activity to underlying principles and theories? One attempt to interpret such data builds upon analogies to the behaviour of collective systems in statistical physics. Divergence of the specific heat\textemdash a measure of population statistics derived from thermodynamics\textemdash has been used to suggest that neural populations are optimized to operate at a ``critical point''. However, these findings have been challenged by theoretical studies which have shown that common inputs can lead to diverging specific heat. Here, we connect ``signatures of criticality'', and in particular the divergence of specific heat, back to statistics of neural population activity commonly studied in neural coding: firing rates and pairwise correlations. We show that the specific heat diverges whenever the average correlation strength does not depend on population size. This is necessarily true when data with correlations is randomly subsampled during the analysis process, irrespective of the detailed structure or origin of correlations. We also show how the characteristic shape of specific heat capacity curves depends on firing rates and correlations, using both analytically tractable models and numerical simulations of a canonical feed-forward population model. To analyze these simulations, we develop efficient methods for characterizing large-scale neural population activity with maximum entropy models. We find that, consistent with experimental findings, increases in firing rates and correlation directly lead to more pronounced signatures. Thus, previous reports of thermodynamical criticality in neural populations based on the analysis of specific heat can be explained by average firing rates and correlations, and are not indicative of an optimized coding strategy. We conclude that a reliable interpretation of statistical tests for theories of neural coding is possible only in reference to relevant ground-truth models.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/criticality/nonnenmacher2017sig.pdf},
  journal  = {PLOS Computational Biology},
  keywords = {Algorithms,Coding mechanisms,Neurons,Probability distribution,Retina,Retinal ganglion cells,Simulation and modeling,Thermodynamics},
  month    = oct,
  year     = {2017},
}

@Article{shewInformationCapacityTransmission2011,
  author     = {Shew, W. L. and Yang, H. and Yu, S. and Roy, R. and Plenz, D.},
  title      = {Information Capacity and Transmission Are Maximized in Balanced Cortical Networks with Neuronal Avalanches},
  doi        = {10.1523/JNEUROSCI.4637-10.2011},
  issn       = {1529-2401 (Electronic) 0270-6474 (Linking)},
  number     = {1},
  pages      = {55--63},
  volume     = {31},
  abstract   = {The repertoire of neural activity patterns that a cortical network can produce constrains the ability of the network to transfer and process information. Here, we measured activity patterns obtained from multisite local field potential recordings in cortex cultures, urethane-anesthetized rats, and awake macaque monkeys. First, we quantified the information capacity of the pattern repertoire of ongoing and stimulus-evoked activity using Shannon entropy. Next, we quantified the efficacy of information transmission between stimulus and response using mutual information. By systematically changing the ratio of excitation/inhibition (E/I) in vitro and in a network model, we discovered that both information capacity and information transmission are maximized at a particular intermediate E/I, at which ongoing activity emerges as neuronal avalanches. Next, we used our in vitro and model results to correctly predict in vivo information capacity and interactions between neuronal groups during ongoing activity. Close agreement between our experiments and model suggest that neuronal avalanches and peak information capacity arise because of criticality and are general properties of cortical networks with balanced E/I.},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/shew2011inf.pdf},
  journal    = {J Neurosci},
  keywords   = {*Models; Neurological,Analysis of Variance,Animals,Animals; Newborn,Cerebral Cortex/*cytology,Computer Simulation,Dose-Response Relationship; Drug,Entropy,Evoked Potentials/drug effects/physiology,Excitatory Amino Acid Antagonists/pharmacology,Female,GABA Antagonists/pharmacology,Likelihood Functions,Macaca mulatta,Male,Microelectrodes,Nerve Net/*physiology,Neurons/*physiology,Organ Culture Techniques,Picrotoxin/pharmacology,Quinoxalines/pharmacology,Rats,read,Synaptic Transmission/*physiology,Valine/analogs \& derivatives/pharmacology},
  month      = jan,
  readstatus = {read},
  year       = {2011},
}

@Article{raschNeuronsCircuitsLinear2009,
  author   = {Rasch, M. and Logothetis, N. K. and Kreiman, G.},
  title    = {From Neurons to Circuits: Linear Estimation of Local Field Potentials},
  doi      = {10.1523/JNEUROSCI.2390-09.2009},
  issn     = {1529-2401 (Electronic) 0270-6474 (Linking)},
  pages    = {13785--96},
  volume   = {29},
  abstract = {Extracellular physiological recordings are typically separated into two frequency bands: local field potentials (LFPs) (a circuit property) and spiking multiunit activity (MUA). Recently, there has been increased interest in LFPs because of their correlation with functional magnetic resonance imaging blood oxygenation level-dependent measurements and the possibility of studying local processing and neuronal synchrony. To further understand the biophysical origin of LFPs, we asked whether it is possible to estimate their time course based on the spiking activity from the same electrode or nearby electrodes. We used "signal estimation theory" to show that a linear filter operation on the activity of one or a few neurons can explain a significant fraction of the LFP time course in the macaque monkey primary visual cortex. The linear filter used to estimate the LFPs had a stereotypical shape characterized by a sharp downstroke at negative time lags and a slower positive upstroke for positive time lags. The filter was similar across different neocortical regions and behavioral conditions, including spontaneous activity and visual stimulation. The estimations had a spatial resolution of approximately 1 mm and a temporal resolution of approximately 200 ms. By considering a causal filter, we observed a temporal asymmetry such that the positive time lags in the filter contributed more to the LFP estimation than the negative time lags. Additionally, we showed that spikes occurring within approximately 10 ms of spikes from nearby neurons yielded better estimation accuracies than nonsynchronous spikes. In summary, our results suggest that at least some circuit-level local properties of the field potentials can be predicted from the activity of one or a few neurons.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/multiModal/neuroNetworkRelationship_nnr/methods/rasch2009fro.pdf},
  journal  = {J Neurosci},
  keywords = {Action Potentials/*physiology,Animals,Linear Models,Macaca mulatta,Nerve Net/*physiology,Neurons/*physiology,Visual Fields/*physiology,Visual Pathways/physiology},
  month    = nov,
  year     = {2009},
}

@Article{chialvoEmergentComplexNeural2010c,
  author   = {Chialvo, D. R.},
  title    = {Emergent Complex Neural Dynamics},
  doi      = {Doi 10.1038/Nphys1803},
  issn     = {1745-2473},
  language = {English},
  number   = {10},
  pages    = {744--750},
  volume   = {6},
  abstract = {A large repertoire of spatiotemporal activity patterns in the brain is the basis for adaptive behaviour. Understanding the mechanism by which the brain's hundred billion neurons and hundred trillion synapses manage to produce such a range of cortical configurations in a flexible manner remains a fundamental problem in neuroscience. One plausible solution is the involvement of universal mechanisms of emergent complex phenomena evident in dynamical systems poised near a critical point of a second-order phase transition. We review recent theoretical and empirical results supporting the notion that the brain is naturally poised near criticality, as well as its implications for better understanding of the brain.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/c_onTabelPrince/chialvo2010eme.pdf},
  journal  = {Nature Physics},
  keywords = {1/f noise,cortex,critical-behavior,functional connectivity,genetic regulatory networks,human brain,neuronal avalanches,phase-transition,self-organized criticality,state princNeuro},
  month    = oct,
  year     = {2010},
}

@Article{leopoldActivityChangesEarly1996,
  author   = {Leopold, D. A. and Logothetis, N. K.},
  title    = {Activity Changes in Early Visual Cortex Reflect Monkeys' Percepts during Binocular Rivalry},
  doi      = {10.1038/379549a0},
  issn     = {0028-0836 (Print) 0028-0836 (Linking)},
  language = {en},
  number   = {6565},
  pages    = {549--53},
  volume   = {379},
  abstract = {When the two eyes view dissimilar images, we experience binocular rivalry, in which one eye's view dominates for several seconds and is then replaced by that of the other eye. What causes these perceptual changes in the absence of any change in the stimulus? We showed previously that some neurons in monkey cortical area MT show changes in activity during motion rivalry that reflect the perceived direction of motion. To determine whether perception-related modulation of activity occurs in other visual cortical areas, we recorded from individual neurons in V1, V2 and V4 while monkeys reported the perceived orientation of rival gratings of two orthogonal orientations. Many cells, particularly in V4, showed patterns of activity that correlated with the perceptual dominance and suppression of one stimulus. The majority were orientation-selective and could be driven equally well from either eye. It has been previously suggested that binocular rivalry involves reciprocal inhibition between monocular neurons within V1 (for example, see ref. 4), but our results do not support this view; rather, we propose that binocular rivalry arises through interactions between binocular neurons at several levels in the visual pathways, and that similar mechanisms may underlie other multistable perceptual states that occur when viewing ambiguous images.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/perception/multiStablePerception_msp/leopold1996act.pdf},
  journal  = {Nature},
  keywords = {Animals,Humans,Macaca mulatta,Neurons/physiology,Vision; Binocular/*physiology,Visual Cortex/cytology/*physiology,Visual Perception/*physiology},
  month    = feb,
  year     = {1996},
}
% == BibTeX quality report for ForschungszentrumJulichComputational:
% ? Title looks like it was stored in title-case in Zotero

@Book{forstmannIntroductionModelbasedCognitive2015,
  title      = {An Introduction to Model-Based Cognitive Neuroscience},
  editor     = {Forstmann, Birte U. and Wagenmakers, Eric-Jan},
  isbn       = {978-1-4939-2235-2},
  publisher  = {{Springer}},
  address    = {{New York}},
  annotation = {OCLC: ocn909486676},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/books/forstmann2015an.pdf},
  keywords   = {Behavior,Cognition,Cognitive neuroscience,Human behavior models,Mathematical models,methods,Models; Psychological,Neuropsychology,physiology,Psychomotor Performance},
  lccn       = {QP360.5 .I57 2015},
  year       = {2015},
}

@Article{deabreuPsychoneuroimmunologyImmunopsychiatryZebrafish2018,
  author     = {{de Abreu}, Murilo S. and Giacomini, Ana C. V. V. and Zanandrea, Rodrigo and {dos Santos}, Bruna E. and Genario, Rafael and {de Oliveira}, Gabriel G. and Friend, Ashton J. and Amstislavskaya, Tamara G. and Kalueff, Allan V.},
  title      = {Psychoneuroimmunology and Immunopsychiatry of Zebrafish},
  doi        = {10.1016/j.psyneuen.2018.03.014},
  issn       = {0306-4530},
  language   = {en},
  pages      = {1--12},
  volume     = {92},
  abstract   = {Despite the high prevalence of neural and immune disorders, their etiology and molecular mechanisms remain poorly understood. As the zebrafish (Danio rerio) is increasingly utilized as a powerful model organism in biomedical research, mounting evidence suggests these fish as a useful tool to study neural and immune mechanisms and their interplay. Here, we discuss zebrafish neuro-immune mechanisms and their pharmacological and genetic modulation, the effect of stress on cytokines, as well as relevant models of microbiota-brain interplay. As many human brain diseases are based on complex interplay between the neural and the immune system, here we discuss zebrafish models, as well as recent successes and challenges, in this rapidly expanding field. We particularly emphasize the growing utility of zebrafish models in translational immunopsychiatry research, as they improve our understanding of pathogenetic neuro-immune interactions, thereby fostering future discovery of potential therapeutic agents.},
  journal    = {Psychoneuroendocrinology},
  keywords   = {CNS,Cytokines,Immune system,Immunopsychiatry,Microbiota-brain,read,review,Stress},
  month      = jun,
  readstatus = {read},
  year       = {2018},
}

@Article{wernerConsciousnessViewedFramework2013,
  author   = {Werner, G.},
  title    = {Consciousness Viewed in the Framework of Brain Phase Space Dynamics, Criticality, and the {{Renormalization Group}}},
  doi      = {DOI 10.1016/j.chaos.2012.03.014},
  issn     = {0960-0779},
  language = {English},
  pages    = {3--12},
  volume   = {55},
  abstract = {The topic of this paper will be addressed in three stages: I will first review currently prominent theoretical conceptualizations of the neurobiology of consciousness and, where appropriate, identify ill-advised and flawed notions in theoretical neuroscience that may impede viewing consciousness as a phenomenon in the physics of brain. In this context, I will also introduce relevant facts that tend not to receive adequate attention in much of the current consciousness discourse. Next, I will review the evidence that accrued in the last decade that identifies the resting brain as being in a state of criticality. In the framework of state phase dynamics of statistical physics, this observational evidence also entails that the resting brain is poised at the brink of a second order phase transition. On this basis, I will in the third stage propose applying the framework of the Renormalization Group to viewing consciousness as a phenomenon in statistical physics. In physics, concepts of phase space transitions and the Renormalization Group are powerful tools for interpreting phenomena involving many scales of length and time in complex systems. The significance of these concepts lies in their accounting for the emergence of different levels of new collective behaviors in complex systems, each level with its distinct macroscopic physics, organization, and laws, as a new pattern of reality. In this framework, I propose to view subjectivity as the symbolic description of the physical brain state of consciousness that emerges as one of the levels of phase transitions of the brain-body-environment system, along the trajectory of Renormalization Group Transformations. (C) 2012 Published by Elsevier Ltd.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/c_onTabelPrince/werner2012con.pdf;/home/ssafavi/Nextcloud/libraries/zoteroLib/c_onTabelPrince/werner2013con.pdf},
  journal  = {Chaos Solitons \& Fractals},
  keywords = {complex networks,connectivity,information,integration,metastability,neural populations,neuroanatomy,neuronal avalanches,system,transitions},
  month    = oct,
  year     = {2013},
}
% == BibTeX quality report for MentalHealthRecovery:
% ? Title looks like it was stored in title-case in Zotero

@Article{mentchGABAergicInhibitionGates2019,
  author     = {Mentch, Jeff and Spiegel, Alina and Ricciardi, Catherine and Robertson, Caroline E.},
  title      = {{{GABAergic Inhibition Gates Perceptual Awareness During Binocular Rivalry}}},
  doi        = {10.1523/JNEUROSCI.0836-19.2019},
  issn       = {0270-6474, 1529-2401},
  language   = {en},
  number     = {42},
  pages      = {8398--8407},
  volume     = {39},
  abstract   = {Binocular rivalry is a classic experimental tool to probe the neural machinery of perceptual awareness. During rivalry, perception alternates between the two eyes, and the ebb and flow of perception is modeled to rely on the strength of inhibitory interactions between competitive neuronal populations in visual cortex. As a result, rivalry has been suggested as a noninvasive perceptual marker of inhibitory signaling in visual cortex, and its putative disturbance in psychiatric conditions, including autism. Yet, direct evidence causally implicating inhibitory signaling in the dynamics of binocular rivalry is currently lacking. We previously found that people with higher GABA levels in visual cortex, measured using magnetic resonance spectroscopy, have stronger perceptual suppression during rivalry. Here, we present direct causal tests of the impact of GABAergic inhibition on rivalry dynamics, and the contribution of specific GABA receptors to these dynamics. In a crossover pharmacological design with male and female adult participants, we found that drugs that modulate the two dominant GABA receptor types in the brain, GABAA (clobazam) and GABAB (arbaclofen), increase perceptual suppression during rivalry relative to a placebo. Crucially, these results could not be explained by changes in reaction times or response criteria, as determined through rivalry simulation trials, suggesting a direct and specific influence of GABA on perceptual suppression. A full replication study of the GABAB modulator reinforces these findings. These results provide causal evidence for a link between the strength of inhibition in the brain and perceptual suppression during rivalry and have implications for psychiatric conditions including autism. SIGNIFICANCE STATEMENT How does the brain accomplish perceptual gating? Here we use a direct and causal pharmacological manipulation to present insight into the neural machinery of a classic illusion of perceptual awareness: binocular rivalry. We show that drugs that increase GABAergic inhibition in the brain, clobazam (GABAA modulator) and arbaclofen (GABAB modulator), increase perceptual suppression during rivalry relative to a placebo. These results present the first causal link between GABAergic inhibition and binocular rivalry in humans, complementing classic models of binocular rivalry, and have implications for our understanding of psychiatric conditions, such as autism, where binocular rivalry is posited as a behavioral marker of disruptions in inhibitory signaling in the brain.},
  chapter    = {Research Articles},
  copyright  = {Copyright \textcopyright{} 2019 the authors},
  journal    = {Journal of Neuroscience},
  keywords   = {awareness,binocular rivalry,GABA,inhibition,perception,pharma,read},
  month      = oct,
  pmid       = {31451579},
  publisher  = {{Society for Neuroscience}},
  readstatus = {read},
  year       = {2019},
}

@Article{boerlinPredictiveCodingDynamical2013,
  author   = {Boerlin, M. and Machens, C. K. and Deneve, S.},
  title    = {Predictive Coding of Dynamical Variables in Balanced Spiking Networks},
  doi      = {10.1371/journal.pcbi.1003258},
  issn     = {1553-7358 (Electronic) 1553-734X (Linking)},
  pages    = {e1003258},
  volume   = {9},
  abstract = {Two observations about the cortex have puzzled neuroscientists for a long time. First, neural responses are highly variable. Second, the level of excitation and inhibition received by each neuron is tightly balanced at all times. Here, we demonstrate that both properties are necessary consequences of neural networks that represent information efficiently in their spikes. We illustrate this insight with spiking networks that represent dynamical variables. Our approach is based on two assumptions: We assume that information about dynamical variables can be read out linearly from neural spike trains, and we assume that neurons only fire a spike if that improves the representation of the dynamical variables. Based on these assumptions, we derive a network of leaky integrate-and-fire neurons that is able to implement arbitrary linear dynamical systems. We show that the membrane voltage of the neurons is equivalent to a prediction error about a common population-level signal. Among other things, our approach allows us to construct an integrator network of spiking neurons that is robust against many perturbations. Most importantly, neural variability in our networks cannot be equated to noise. Despite exhibiting the same single unit properties as widely used population code models (e.g. tuning curves, Poisson distributed spike trains), balanced networks are orders of magnitudes more reliable. Our approach suggests that spikes do matter when considering how the brain computes, and that the reliability of cortical representations could have been strongly underestimated.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/computation/bayesian/bayesianNeuralSystems/implementations/boerlin2013pre.pdf;/home/ssafavi/Zotero/storage/K2H7NFCP/Boerlin-20131.pdf},
  journal  = {PLoS Comput Biol},
  keywords = {*Models; Neurological,*Models; Statistical,Action Potentials/*physiology,Algorithms,Computational Biology,Reproducibility of Results},
  pmcid    = {PMC3828152},
  year     = {2013},
}
% == BibTeX quality report for RoemerHasIt2018:
% ? Title looks like it was stored in title-case in Zotero

@Article{roethEfficientPopulationCoding2020,
  author    = {Roeth, Kai and Shao, Shuai and Gjorgjieva, Julijana},
  title     = {Efficient Population Coding Depends on Stimulus Convergence and Source of Noise},
  doi       = {10.1101/2020.06.15.151795},
  language  = {en},
  pages     = {2020.06.15.151795},
  abstract  = {{$<$}p{$>$}Sensory organs transmit information to downstream brain circuits using a neural code comprised of spikes from multiple neurons. According to the prominent efficient coding framework, the properties of sensory populations have evolved to encode maximum information about stimuli given biophysical constraints. How information coding depends on the way sensory signals from multiple channels converge downstream is still unknown, especially in the presence of noise which corrupts the signal at different points along the pathway. Here, we calculated the optimal information transfer of a population of nonlinear neurons under two scenarios. First, a lumped-coding channel where the information from different inputs converges to a single channel, thus reducing the number of neurons. Second, an independent-coding channel when different inputs contribute independent information without convergence. In each case, we investigated information loss when the sensory signal was corrupted by two sources of noise. We determined critical noise levels at which the optimal number of distinct thresholds of individual neurons in the population changes. Comparing our system to classical physical systems, these changes correspond to first- or second-order phase transitions for the lumped- or the independent-coding channel, respectively. We relate our theoretical predictions to coding in a population of auditory nerve fibers recorded experimentally, and find signatures of efficient coding. Our results yield important insights into the diverse coding strategies used by neural populations to optimally integrate sensory stimuli in the presence of distinct sources of noise.{$<$}/p{$>$}},
  chapter   = {New Results},
  copyright = {\textcopyright{} 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
  journal   = {bioRxiv},
  month     = jun,
  publisher = {{Cold Spring Harbor Laboratory}},
  year      = {2020},
}

@Article{logothetisIntracorticalRecordingsFMRI2012,
  author   = {Logothetis, N. K.},
  title    = {Intracortical Recordings and {{fMRI}}: An Attempt to Study Operational Modules and Networks Simultaneously},
  doi      = {10.1016/j.neuroimage.2012.01.033},
  issn     = {1095-9572 (Electronic) 1053-8119 (Linking)},
  number   = {2},
  pages    = {962--9},
  volume   = {62},
  abstract = {The brain can be envisaged as a complex adaptive system. It is characterized by a very high structural complexity and by massive connectivity, both of which change and evolve in response to experience. Information related to sensors and effectors is processed in both a parallel and a hierarchical fashion; the connectivity between different hierarchical levels is bidirectional, and its effectiveness is continuously controlled by specific associational and neuromodulatory centers. When questions are addressed at the level of a distributed, large-scale whole system such as that underlying perception and cognition, it is not clear what should be considered as an elementary operational unit because the behavior of integral, aggregate systems is always emergent and most often remains unpredicted by the behaviors of single cells. To localize and comprehend the neural mechanisms underlying our perceptual or cognitive capacities, concurrent studies of microcircuits, of local and long-range interconnectivity between small assemblies, and of the synergistic activity of larger neuronal populations are called for. In other words, multimodal methodologies that include invasive neuroscientific methods as well as global neuroimaging techniques are required, such as the various functional aspects of magnetic resonance imaging. These facts were the driving force behind the decision to begin animal-MRI in my lab. The wonderful idea of the editors of NeuroImage to publish a Special Issue commemorating 20years of functional fMRI provides me with the opportunity of sharing not only our first moments of frustration with the readers, but also our successful results.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/multiModal/networkBrainRelationshop_nbr/logothetis2012int.pdf},
  journal  = {Neuroimage},
  keywords = {Animals,Brain Mapping/*history/methods,Brain/anatomy \& histology/*physiology,History; 20th Century,History; 21st Century,Humans,Magnetic Resonance Imaging/*history/methods,Nerve Net/*physiology,review},
  month    = aug,
  year     = {2012},
}

@Article{fazliLearningMoreOne2015,
  author   = {Fazli, S. and Dahne, S. and Samek, W. and Biessmann, F. and Muller, K. R.},
  title    = {Learning {{From More Than One Data Source}}: {{Data Fusion Techniques}} for {{Sensorimotor Rhythm}}-{{Based Brain}}-{{Computer Interfaces}}},
  doi      = {10.1109/Jproc.2015.2413993},
  issn     = {0018-9219},
  language = {English},
  pages    = {891--906},
  volume   = {103},
  abstract = {Brain-computer interfaces (BCIs) are successfully used in scientific, therapeutic and other applications. Remaining challenges are among others a low signal-to-noise ratio of neural signals, lack of robustness for decoders in the presence of inter-trial and inter-subject variability, time constraints on the calibration phase and the use of BCIs outside a controlled lab environment. Recent advances in BCI research addressed these issues by novel combinations of complementary analysis as well as recording techniques, so called hybrid BCIs. In this paper, we review a number of data fusion techniques for BCI along with hybrid methods for BCI that have recently emerged. Our focus will be on sensorimotor rhythm-based BCIs. We will give an overview of the three main lines of research in this area, integration of complementary features of neural activation, integration of multiple previous sessions and of multiple subjects, and show how these techniques can be used to enhance modern BCI systems.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/unfiled/fazli2015lea.pdf},
  journal  = {Proceedings of the Ieee},
  keywords = {alpha-rhythm,boosting bit rates,brain-computer interface (bci),common spatial-patterns,data fusion,electroencephalography (eeg),error-detection,hybrid bci,multi-modal,mutual information,near-infrared spectroscopy,near-infrared spectroscopy (nirs),noninvasive eeg,resolution eeg,single-trial eeg,slow cortical potentials,zero-training},
  month    = jun,
  year     = {2015},
}

@Article{levanquyenDisentanglingDynamicCore00,
  author     = {Le Van Quyen, Michel},
  title      = {Disentangling the Dynamic Core: A Research Program for a Neurodynamics at the Large-Scale},
  doi        = {10.4067/S0716-97602003000100006},
  issn       = {0716-9760},
  number     = {1},
  pages      = {67--88},
  volume     = {36},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neuroprinciples/nonLinearDynamics/le_van_quyen2003dis.pdf},
  journal    = {Biological Research},
  publisher  = {{Sociedad de Biolog\'ia de Chile}},
  shorttitle = {Disentangling the Dynamic Core},
  year       = {2003},
}
% == BibTeX quality report for kritchmanNonParametricDetectionNumber2009:
% ? Title looks like it was stored in title-case in Zotero

@Article{kritzerIntrinsicCircuitOrganization1995,
  author     = {Kritzer, M. F. and Goldman-Rakic, P. S.},
  title      = {Intrinsic Circuit Organization of the Major Layers and Sublayers of the Dorsolateral Prefrontal Cortex in the Rhesus Monkey},
  doi        = {10.1002/cne.903590109},
  issn       = {1096-9861},
  language   = {en},
  number     = {1},
  pages      = {131--143},
  volume     = {359},
  abstract   = {Intrinsic connections are likely to play important roles in cognitive information processing to in the prefrontal association cortex. To gain insight into the organization of these circuits, intracortical connections of major laminar and sublaminar divisions were retrogradely labeled in Walker's area 9 and 46 in rhesus monkeys by using cholera toxin (B-subunit) conjugated to colloidal gold. Microinjections placed within particular cortical laminae produced unique patterns of retrograde labeling. Injections in layers II/III yielded labeling which was laterally widespread (2\textendash 7 mm) in supragranular layers, and more narrowly focused, i.e., conforming to a column, in layers IV\textendash VI. In contrast, local circuits associated with layers IV and Vb displayed a regular, cylindrical organization, whereas intrinsic connections of layer Va were laterally extensive (3\textendash 5 mm) in layers III and Va. Finally, injections in layer VI gave rise to a narrow column of cell labeling traversing all layers, augmented by laterally extensive labeling ({$\sim$} 7 mm) in layer VI. The intrinsic connections of the prefrontal cortex were arrayed within mediolaterally elongated stripes which were often distributed asymmetrically in either the medial or lateral direction. In addition, labsled cells within these mediolaterally oriented fields were frequently grouped within discrete clusters or narrow bands. The intrinsic connections identified in this study differ from the local circuits of corresponding layers reported for primary visual cortex; the unique intrinsic wiring diagram of the prefrontal cortex may be related to its specialized cognitive and mnemonic functions. \textcopyright{} 1995 Wiley-Liss, Inc.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/cne.903590109},
  copyright  = {Copyright \textcopyright{} 1995 Wiley-Liss, Inc.},
  journal    = {Journal of Comparative Neurology},
  keywords   = {association cortex,local circuits,non-human primates,retrograde tracing,working memory},
  year       = {1995},
}

@Article{goenseNeurophysiologyBOLDFMRI2008a,
  author   = {Goense, J. B. and Logothetis, N. K.},
  title    = {Neurophysiology of the {{BOLD fMRI}} Signal in Awake Monkeys},
  doi      = {10.1016/j.cub.2008.03.054},
  issn     = {0960-9822 (Print) 0960-9822 (Linking)},
  language = {English},
  pages    = {631--40},
  volume   = {18},
  abstract = {BACKGROUND: Simultaneous intracortical recordings of neural activity and blood-oxygen-level-dependent (BOLD) functional magnetic resonance imaging (fMRI) in primary visual cortex of anesthetized monkeys demonstrated varying degrees of correlation between fMRI signals and the different types of neural activity, such as local field potentials (LFPs), multiple-unit activity (MUA), and single-unit activity (SUA). One important question raised by the aforementioned investigation is whether the reported correlations also apply to alert subjects. RESULTS: Monkeys were trained to perform a fixation task while stimuli within the receptive field of each recording site were used to elicit neural responses followed by a BOLD response. We show -- also in alert behaving monkeys -- that although both LFP and MUA make significant contributions to the BOLD response, LFPs are better and more reliable predictors of the BOLD signal. Moreover, when MUA responses adapt but LFP remains unaffected, the BOLD signal remains unaltered. CONCLUSIONS: The persistent coupling of the BOLD signal to the field potential when LFP and MUA have different time evolutions suggests that BOLD is primarily determined by the local processing of inputs in a given cortical area. In the alert animal the largest portion of the BOLD signal's variance is explained by an LFP range (20-60 Hz) that is most likely related to neuromodulation. Finally, the similarity of the results in alert and anesthetized subjects indicates that at least in V1 anesthesia is not a confounding factor. This enables the comparison of human fMRI results with a plethora of electrophysiological results obtained in alert or anesthetized animals.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/multiModal/goense2008neu.pdf},
  journal  = {Curr Biol},
  keywords = {*Magnetic Resonance Imaging,Animals,Consciousness/physiology,Evoked Potentials; Visual/*physiology,Fixation; Ocular/physiology,Haplorhini/*physiology,Oxygen/*blood,Visual Cortex/*physiology},
  month    = may,
  year     = {2008},
}

@Article{heScalefreeBrainActivity2014,
  author   = {He, B. J.},
  title    = {Scale-Free Brain Activity: Past, Present, and Future},
  doi      = {10.1016/j.tics.2014.04.003},
  issn     = {1879-307X (Electronic) 1364-6613 (Linking)},
  pages    = {480--7},
  volume   = {18},
  abstract = {Brain activity observed at many spatiotemporal scales exhibits a 1/f-like power spectrum, including neuronal membrane potentials, neural field potentials, noninvasive electroencephalography (EEG), magnetoencephalography (MEG), and functional magnetic resonance imaging (fMRI) signals. A 1/f-like power spectrum is indicative of arrhythmic brain activity that does not contain a predominant temporal scale (hence, 'scale-free'). This characteristic of scale-free brain activity distinguishes it from brain oscillations. Although scale-free brain activity and brain oscillations coexist, our understanding of the former remains limited. Recent research has shed light on the spatiotemporal organization, functional significance, and potential generative mechanisms of scale-free brain activity, as well as its developmental and clinical relevance. A deeper understanding of this prevalent brain signal should provide new insights into, and analytical tools for, cognitive neuroscience.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/criticality/he2014sca.pdf},
  journal  = {Trends Cogn Sci},
  month    = sep,
  year     = {2014},
}
% == BibTeX quality report for bertrandEfficientTrackingSparse2020:
% ? Title looks like it was stored in title-case in Zotero

@Article{bertschingerRealtimeComputationEdge2004,
  author  = {Bertschinger, N. and Natschlager, T.},
  title   = {Real-Time Computation at the Edge of Chaos in Recurrent Neural Networks},
  pages   = {1413--1436},
  volume  = {16},
  file    = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/criticality/bertschinger2004rea.pdf},
  journal = {Neural Comput},
  year    = {2004},
}
% == BibTeX quality report for mallatUnderstandingDeepConvolutional2016:
% Missing required field 'journal'
% ? Title looks like it was stored in title-case in Zotero

@Book{mallatWaveletTourSignal1999,
  author    = {Mallat, S. G.},
  title     = {A Wavelet Tour of Signal Processing},
  edition   = {2nd ed},
  isbn      = {978-0-12-466606-1},
  publisher = {{Academic Press}},
  address   = {{San Diego}},
  keywords  = {Mathematics,Signal processing,Wavelets (Mathematics)},
  lccn      = {TK5102.9 .M34 1999},
  year      = {1999},
}

@Article{levanquyenBrainwebCrossscaleInteractions2011,
  author   = {Le Van Quyen, Michel},
  title    = {The Brainweb of Cross-Scale Interactions},
  doi      = {10.1016/j.newideapsych.2010.11.001},
  issn     = {0732-118X},
  language = {en},
  number   = {2},
  pages    = {57--63},
  volume   = {29},
  abstract = {From neuron to behaviour, the nervous system operates on many levels of organization, each with its own scales of time and space. Very large sets of data can now be obtained from these multiple levels by the explosive growth of new physiological recording techniques and functional neuroimaging. Among the most difficult tasks are those of conceiving and describing the exchanges between levels, seeing that the scales of time and distance are braided together in a complex web of interactions, and that causal inference is far more ambiguous between than within levels. In this paper, I propose that a generic description of these multi-level interactions can be based on the temporal coordination of neuronal oscillations that operate at multiple frequencies and on different spatial scales. Specifically, the amplitude of the oscillations at each characteristic frequency is modulated by cyclical variations in neuronal excitability induced by lower frequency oscillations and emerging simultaneously on a larger spatial scale. Following this general rule, global patterns of integration can produce downward effects, occasionally acting on and constraining the local level of cell assemblies, whose activity can thus be taken as a signature of the downward influence. This cross-scale framework is firmly rooted in neurophysiology and as such is entirely amenable to experimental testing.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neuroprinciples/multiScale/le_van_quyen2011the.pdf},
  journal  = {New Ideas in Psychology},
  keywords = {High-frequency oscillations,Large-scale brain dynamics,Slow cortical oscillations,Upward and downward causations},
  month    = aug,
  year     = {2011},
}

@Article{leopoldMeasuringSubjectiveVisual2003,
  author   = {Leopold, David and Maier, A. and Logothetis, N.K.},
  title    = {Measuring {{Subjective Visual Perception}} in the {{Nonhuman Primate}}},
  number   = {9-10},
  pages    = {115--130},
  volume   = {10},
  abstract = {Understanding how activity in the brain leads to a subjective percept is of great interest to philosophers and neuroscientists alike. In the last years, neurophysiological experiments have approached this problem directly by measuring neural signals in animals as they experience well-defined visual percepts. Stimuli in these studies are often inherently ambiguous, and thus rely upon the subjective report, generally from trained monkeys, to provide a measure of perception. By correlating activity levels in the brain to this report, one can speculate on the role of individual neurons and groups of neurons in the formation and maintenance of a particular percept. However, in order to draw valid conclusions from such experiments, it is critical that the responses accurately and reliably reflect what is perceived. For this reason, a number of behavioural paradigms have been developed to control and evaluate the truthfulness of responses from behaving animals. Here we describe several approaches to optimizing the reliability of a monkey's perceptual report, and argue that their combination provides an invaluable approach in the study of subjective visual perception.},
  journal  = {Journal of Consciousness Studies},
  month    = jan,
  year     = {2003},
}

@Article{malamudForestFiresExample1998,
  author     = {Malamud, Bruce D. and Morein, Gleb and Turcotte, Donald L.},
  title      = {Forest {{Fires}}: {{An Example}} of {{Self}}-{{Organized Critical Behavior}}},
  doi        = {10.1126/science.281.5384.1840},
  issn       = {0036-8075, 1095-9203},
  language   = {en},
  number     = {5384},
  pages      = {1840--1842},
  volume     = {281},
  abstract   = {Despite the many complexities concerning their initiation and propagation, forest fires exhibit power-law frequency-area statistics over many orders of magnitude. A simple forest fire model, which is an example of self-organized criticality, exhibits similar behavior. One practical implication of this result is that the frequency-area distribution of small and medium fires can be used to quantify the risk of large fires, as is routinely done for earthquakes.},
  chapter    = {Report},
  journal    = {Science},
  month      = sep,
  pmid       = {9743494},
  publisher  = {{American Association for the Advancement of Science}},
  shorttitle = {Forest {{Fires}}},
  year       = {1998},
}
% == BibTeX quality report for zenonInformationtheoreticPerspectiveCosts2017:
% Missing required field 'journal'

@Article{zeraatiSelforganizationCriticalitySynaptic2020,
  author        = {Zeraati, Roxana and Priesemann, Viola and Levina, Anna},
  title         = {Self-Organization toward Criticality by Synaptic Plasticity},
  eprint        = {2010.07888},
  eprinttype    = {arxiv},
  abstract      = {Self-organized criticality has been proposed to be a universal mechanism for the emergence of scale-free dynamics in many complex systems, and possibly in the brain. While such scale-free patterns were identified experimentally in many different types of neural recordings, the biological principles behind their emergence remained unknown. Utilizing different network models and motivated by experimental observations, synaptic plasticity was proposed as a possible mechanism to self-organize brain dynamics towards a critical point. In this review, we discuss how various biologically plausible plasticity rules operating across multiple timescales are implemented in the models and how they alter the network's dynamical state through modification of number and strength of the connections between the neurons. Some of these rules help to stabilize criticality, some need additional mechanisms to prevent divergence from the critical state. We propose that rules that are capable of bringing the network to criticality can be classified by how long the near-critical dynamics persists after their disabling. Finally, we discuss the role of self-organization and criticality in computation. Overall, the concept of criticality helps to shed light on brain function and self-organization, yet the overall dynamics of living neural networks seem to harnesses not only criticality for computation, but also deviations thereof.},
  archiveprefix = {arXiv},
  journal       = {arXiv:2010.07888 [cond-mat, physics:physics, q-bio]},
  keywords      = {Condensed Matter - Disordered Systems and Neural Networks,Physics - Biological Physics,Quantitative Biology - Neurons and Cognition},
  month         = oct,
  primaryclass  = {cond-mat, physics:physics, q-bio},
  year          = {2020},
}
% == BibTeX quality report for safaviUncoveringOrganizationNeural2020:
% ? Unsure about the formatting of the booktitle

@Article{safaviUncoveringOrganizationNeural2020a,
  author    = {Safavi, Shervin and Panagiotaropoulos, Theofanis I. and Kapoor, Vishal and {Ramirez-Villegas}, Juan F. and Logothetis, Nikos K. and Besserve, Michel},
  title     = {Uncovering the {{Organization}} of {{Neural Circuits}} with {{Generalized Phase Locking Analysis}}},
  doi       = {10.1101/2020.12.09.413401},
  language  = {en},
  pages     = {2020.12.09.413401},
  abstract  = {{$<$}p{$>$}Spike-field coupling characterizes the relationship between neurophysiological activities observed at two different scales: on the one hand, the action potential produced by a neuron, on the other hand a mesoscopic "field" signal, reflecting subthreshold activities. This provides insights about the role of a specific unit in network dynamics. However, assessing the overall organization of neural circuits based on multivariate data requires going beyond pairwise approaches, and remains largely unaddressed. We develop Generalized Phase Locking Analysis (GPLA) as an multichannel extension of univariate spike-field coupling. GPLA estimates the dominant spatio-temporal distributions of field activity and neural ensembles, and the strength of the coupling between them. We demonstrate the statistical benefits and interpretability of this approach in various biophysical neuronal network models and Utah array recordings. In particular, we show that GPLA, combined with neural field modeling, help untangle the contribution of recurrent interactions to the spatio-temporal dynamics observed in multi-channel recordings.{$<$}/p{$>$}},
  chapter   = {New Results},
  copyright = {\textcopyright{} 2020, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
  file      = {/home/ssafavi/Nextcloud/libraries/zoteroLib/safavi2020unc.pdf},
  journal   = {bioRxiv},
  month     = dec,
  publisher = {{Cold Spring Harbor Laboratory}},
  year      = {2020},
}

@Article{balduzziIntegratedInformationDiscrete2008b,
  author   = {Balduzzi, D. and Tononi, G.},
  title    = {Integrated Information in Discrete Dynamical Systems: Motivation and Theoretical Framework},
  doi      = {10.1371/journal.pcbi.1000091},
  issn     = {1553-7358 (Electronic) 1553-734X (Linking)},
  number   = {6},
  pages    = {e1000091},
  volume   = {4},
  abstract = {This paper introduces a time- and state-dependent measure of integrated information, phi, which captures the repertoire of causal states available to a system as a whole. Specifically, phi quantifies how much information is generated (uncertainty is reduced) when a system enters a particular state through causal interactions among its elements, above and beyond the information generated independently by its parts. Such mathematical characterization is motivated by the observation that integrated information captures two key phenomenological properties of consciousness: (i) there is a large repertoire of conscious experiences so that, when one particular experience occurs, it generates a large amount of information by ruling out all the others; and (ii) this information is integrated, in that each experience appears as a whole that cannot be decomposed into independent parts. This paper extends previous work on stationary systems and applies integrated information to discrete networks as a function of their dynamics and causal architecture. An analysis of basic examples indicates the following: (i) phi varies depending on the state entered by a network, being higher if active and inactive elements are balanced and lower if the network is inactive or hyperactive. (ii) phi varies for systems with identical or similar surface dynamics depending on the underlying causal architecture, being low for systems that merely copy or replay activity states. (iii) phi varies as a function of network architecture. High phi values can be obtained by architectures that conjoin functional specialization with functional integration. Strictly modular and homogeneous systems cannot generate high phi because the former lack integration, whereas the latter lack information. Feedforward and lattice architectures are capable of generating high phi but are inefficient. (iv) In Hopfield networks, phi is low for attractor states and neutral states, but increases if the networks are optimized to achieve tension between local and global interactions. These basic examples appear to match well against neurobiological evidence concerning the neural substrates of consciousness. More generally, phi appears to be a useful metric to characterize the capacity of any physical system to integrate information.},
  file     = {/Users/ssafavi/Documents/libraries/EndnoteLib_fromWin407/EndnoteLib_MPIPClocal_20170723.Data/PDF/1130816815/Balduzzi-20081.pdf;/Users/ssafavi/Documents/libraries/EndnoteLib_fromWin407/EndnoteLib_MPIPClocal_20170723.Data/PDF/2443960071/Balduzzi-2008.pdf},
  journal  = {PLoS Comput Biol},
  keywords = {*Models; Neurological,*Signal Processing; Computer-Assisted,Animals,Brain/*physiology,Cognition/*physiology,Computer Simulation,Consciousness/*physiology,Humans,Information Storage and Retrieval/*methods,Nerve Net/*physiology,Systems Integration princNeuro},
  month    = jun,
  year     = {2008},
}
% == BibTeX quality report for babichevTopologicalModelHippocampal2016:
% ? Title looks like it was stored in title-case in Zotero

@Article{bachAlgorithmsSurvivalComparative2017,
  author     = {Bach, Dominik R. and Dayan, Peter},
  title      = {Algorithms for Survival: A Comparative Perspective on Emotions},
  doi        = {10.1038/nrn.2017.35},
  issn       = {1471-0048},
  language   = {en},
  number     = {5},
  pages      = {311--319},
  volume     = {18},
  abstract   = {There is little agreement on the definition of emotions or the neural mechanisms by which they are realized. Bach and Dayan here use decision theory to shed light on the nature and implementation of the algorithms that underlie emotion-related behaviours.},
  copyright  = {2017 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/psychiatry/cmpsy/objectives/bach2017alg.pdf},
  journal    = {Nature Reviews Neuroscience},
  keywords   = {read,review},
  month      = may,
  readstatus = {read},
  shorttitle = {Algorithms for Survival},
  year       = {2017},
}

@Article{levanquyenExploringNonlinearDynamics2003,
  author   = {Le Van Quyen, Michel and Chavez, Mario and Rudrauf, David and Martinerie, Jacques},
  title    = {Exploring the Nonlinear Dynamics of the Brain},
  doi      = {10.1016/j.jphysparis.2004.01.019},
  issn     = {0928-4257},
  language = {en},
  number   = {4},
  pages    = {629--639},
  series   = {Neuroscience and {{Computation}}},
  volume   = {97},
  abstract = {The growing need for a better understanding of large-scale brain dynamics has stimulated in the last decade the development of new and more advanced data analysis techniques. Progress in this domain has greatly benefited from developments in nonlinear time series analysis. This review gives a short overview of some of the nonlinear properties one may wish to infer from brain recordings and presents some examples and recent applications.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neuroprinciples/nonLinearDynamics/le_van_quyen2003exp.pdf},
  journal  = {Journal of Physiology-Paris},
  month    = jul,
  year     = {2003},
}

@Article{logothetisUnderpinningsBOLDFunctional2003,
  author   = {Logothetis, N. K.},
  title    = {The Underpinnings of the {{BOLD}} Functional Magnetic Resonance Imaging Signal},
  issn     = {1529-2401 (Electronic) 0270-6474 (Linking)},
  language = {en},
  pages    = {3963--71},
  volume   = {23},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/multiModal/logothetis2003the.pdf},
  journal  = {J Neurosci},
  keywords = {Animals,Brain/blood supply/physiology,Carbon Dioxide/blood,Cerebrovascular Circulation/physiology,Echo-Planar Imaging/methods,Humans,Magnetic Resonance Imaging/*methods,Magnetic Resonance Spectroscopy/methods,Oxygen/*blood},
  month    = may,
  year     = {2003},
}

@Article{friedmanUniversalCriticalDynamics2012,
  author   = {Friedman, N. and Ito, S. and Brinkman, B. A. and Shimono, M. and DeVille, R. E. and Dahmen, K. A. and Beggs, J. M. and Butler, T. C.},
  title    = {Universal Critical Dynamics in High Resolution Neuronal Avalanche Data},
  issn     = {1079-7114 (Electronic) 0031-9007 (Linking)},
  pages    = {208102},
  volume   = {108},
  abstract = {The tasks of neural computation are remarkably diverse. To function optimally, neuronal networks have been hypothesized to operate near a nonequilibrium critical point. However, experimental evidence for critical dynamics has been inconclusive. Here, we show that the dynamics of cultured cortical networks are critical. We analyze neuronal network data collected at the individual neuron level using the framework of nonequilibrium phase transitions. Among the most striking predictions confirmed is that the mean temporal profiles of avalanches of widely varying durations are quantitatively described by a single universal scaling function. We also show that the data have three additional features predicted by critical phenomena: approximate power law distributions of avalanche sizes and durations, samples in subcritical and supercritical phases, and scaling laws between anomalous exponents.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/criticality/friedman2012uni.pdf},
  journal  = {Phys Rev Lett},
  keywords = {*Models; Neurological,Action Potentials/physiology,Animals,Cells; Cultured,Nerve Net/*physiology,Neurons/*physiology,Rats princNeuro},
  month    = may,
  year     = {2012},
}

@Article{schilbachSecondpersonNeuropsychiatry2016,
  author   = {Schilbach, Leonhard},
  title    = {Towards a Second-Person Neuropsychiatry},
  doi      = {10.1098/rstb.2015.0081},
  issn     = {0962-8436},
  number   = {1686},
  volume   = {371},
  abstract = {Psychiatric disorders can affect our ability to successfully and enjoyably interact with others. Conversely, having difficulties in social relations is known to increase the risk of developing a psychiatric disorder. In this article, the assumption that psychiatric disorders can be construed as disorders of social interaction is reviewed from a clinical point of view. Furthermore, it is argued that a psychiatrically motivated focus on the dynamics of social interaction may help to provide new perspectives for the field of social neuroscience. Such progress may be crucial to realize social neuroscience's translational potential and to advance the transdiagnostic investigation of the neurobiology of psychiatric disorders.},
  journal  = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  month    = jan,
  pmcid    = {PMC4685526},
  pmid     = {26644599},
  year     = {2016},
}

@Book{mitchellComplexityGuidedTour2011,
  author     = {Mitchell, Melanie},
  title      = {Complexity: {{A Guided Tour}}},
  edition    = {1 edition},
  isbn       = {978-0-19-979810-0},
  language   = {English},
  publisher  = {{Oxford University Press}},
  abstract   = {What enables individually simple insects like ants to act with such precision and purpose as a group? How do trillions of neurons produce something as extraordinarily complex as consciousness? In this remarkably clear and companionable book, leading complex systems scientist Melanie Mitchell provides an intimate tour of the sciences of complexity, a broad set of efforts that seek to explain how large-scale complex, organized, and adaptive behavior can emerge from simple interactions among myriad individuals. Based on her work at the Santa Fe Institute and drawing on its interdisciplinary strategies, Mitchell brings clarity to the workings of complexity across a broad range of biological, technological, and social phenomena, seeking out the general principles or laws that apply to all of them. Richly illustrated, Complexity: A Guided Tour--winner of the 2010 Phi Beta Kappa Book Award in Science--offers a wide-ranging overview of the ideas underlying complex systems science, the current research at the forefront of this field, and the prospects for its contribution to solving some of the most important scientific questions of our time.},
  address    = {{Oxford}},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/books/mitchell2011com.pdf},
  month      = sep,
  shorttitle = {Complexity},
  year       = {2011},
}

@Article{woergoetterReinforcementLearning2008,
  author   = {Woergoetter, Florentin and Porr, Bernd},
  title    = {Reinforcement Learning},
  doi      = {10.4249/scholarpedia.1448},
  issn     = {1941-6016},
  language = {en},
  number   = {3},
  pages    = {1448},
  volume   = {3},
  journal  = {Scholarpedia},
  month    = mar,
  year     = {2008},
}
% == BibTeX quality report for voitStepsModelingComplex2008:
% ? Title looks like it was stored in title-case in Zotero

@Article{volgushevLongrangeCorrelationMembrane2011,
  author   = {Volgushev, M. and Chauvette, S. and Timofeev, I.},
  title    = {Long-Range Correlation of the Membrane Potential in Neocortical Neurons during Slow Oscillation},
  doi      = {10.1016/B978-0-444-53839-0.00012-0},
  issn     = {1875-7855 (Electronic) 0079-6123 (Linking)},
  pages    = {181--99},
  volume   = {193},
  abstract = {Large amplitude slow waves are characteristic for the summary brain activity, recorded as electroencephalogram (EEG) or local field potentials (LFP), during deep stages of sleep and some types of anesthesia. Slow rhythm of the synchronized EEG reflects an alternation of active (depolarized, UP) and silent (hyperpolarized, DOWN) states of neocortical neurons. In neurons, involvement in the generalized slow oscillation results in a long-range synchronization of changes of their membrane potential as well as their firing. Here, we aimed at intracellular analysis of details of this synchronization. We asked which components of neuronal activity exhibit long-range correlations during the synchronized EEG? To answer this question, we made simultaneous intracellular recordings from two to four neocortical neurons in cat neocortex. We studied how correlated is the occurrence of active and silent states, and how correlated are fluctuations of the membrane potential in pairs of neurons located close one to the other or separated by up to 13 mm. We show that strong long-range correlation of the membrane potential was observed only (i) during the slow oscillation but not during periods without the oscillation, (ii) during periods which included transitions between the states but not during within-the-state periods, and (iii) for the low-frequency ({$<$} 5 Hz) components of membrane potential fluctuations but not for the higher-frequency components ({$>$} 10 Hz). In contrast to the neurons located several millimeters one from the other, membrane potential fluctuations in neighboring neurons remain strongly correlated during periods without slow oscillation. We conclude that membrane potential correlation in distant neurons is brought about by synchronous transitions between the states, while activity within the states is largely uncorrelated. The lack of the generalized fine-scale synchronization of membrane potential changes in neurons during the active states of slow oscillation may allow individual neurons to selectively engage in short living episodes of correlated activity-a process that may be similar to dynamical formation of neuronal ensembles during activated brain states.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/unfiled/volgushev2011lon.pdf},
  journal  = {Prog Brain Res},
  keywords = {*Periodicity,Animals,Cats,Electroencephalography,Electromyography,Electrophysiology,Membrane Potentials/*physiology,Neocortex/*cytology/*physiology,Neurons/cytology/*physiology,Sleep/physiology},
  pmcid    = {PMC3397925},
  year     = {2011},
}
% == BibTeX quality report for liLearningBrainsHow2019:
% ? Possibly abbreviated journal title arXiv:1911.05072 [cs, q-bio]
% ? Title looks like it was stored in title-case in Zotero

@Article{liljenstroemMesoscopicBrainDynamics2012,
  author  = {Liljenstroem, Hans},
  title   = {Mesoscopic Brain Dynamics},
  doi     = {10.4249/scholarpedia.4601},
  issn    = {1941-6016},
  number  = {9},
  pages   = {4601},
  volume  = {7},
  file    = {/home/ssafavi/Nextcloud/libraries/zoteroLib/projects/nnr/MT/liljenstroem2012mes.pdf},
  journal = {Scholarpedia},
  month   = sep,
  year    = {2012},
}

@Article{strongEntropyInformationNeural1998,
  author    = {Strong, S. P. and Koberle, Roland and {de Ruyter van Steveninck}, Rob R. and Bialek, William},
  title     = {Entropy and {{Information}} in {{Neural Spike Trains}}},
  doi       = {10.1103/PhysRevLett.80.197},
  number    = {1},
  pages     = {197--200},
  volume    = {80},
  abstract  = {The nervous system represents time dependent signals in sequences of discrete, identical action potentials or spikes; information is carried only in the spike arrival times. We show how to quantify this information, in bits, free from any assumptions about which features of the spike train or input signal are most important, and we apply this approach to the analysis of experiments on a motion sensitive neuron in the fly visual system. This neuron transmits information about the visual stimulus at rates of up to 90 bits/s, within a factor of 2 of the physical limit set by the entropy of the spike train itself.},
  journal   = {Physical Review Letters},
  month     = jan,
  publisher = {{American Physical Society}},
  year      = {1998},
}

@Article{sangerNeuralPopulationCodes2003,
  author   = {Sanger, T. D.},
  title    = {Neural Population Codes},
  issn     = {0959-4388 (Print) 0959-4388 (Linking)},
  pages    = {238--49},
  volume   = {13},
  abstract = {In many regions of the brain, information is represented by patterns of activity occurring over populations of neurons. Understanding the encoding of information in neural population activity is important both for grasping the fundamental computations underlying brain function, and for interpreting signals that may be useful for the control of prosthetic devices. We concentrate on the representation of information in neurons with Poisson spike statistics, in which information is contained in the average spike firing rate. We analyze the properties of population codes in terms of the tuning functions that describe individual neuron behavior. The discussion centers on three computational questions: first, what information is encoded in a population; second, how does the brain compute using populations; and third, when is a population optimal? To answer these questions, we discuss several methods for decoding population activity in an experimental setting. We also discuss how computation can be performed within the brain in networks of interconnected populations. Finally, we examine questions of optimal design of population codes that may help to explain their particular form and the set of variables that are best represented. We show that for population codes based on neurons that have a Poisson distribution of spike probabilities, the behavior and computational properties of the code can be understood in terms of the tuning properties of individual cells.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/unfiled/sanger2003neu.pdf},
  journal  = {Current Opinion in Neurobiology},
  keywords = {*Models; Neurological,*Models; Theoretical,Action Potentials/physiology,Animals,Brain/*physiology,Humans,Nerve Net/*physiology,Neurons/*physiology,Poisson Distribution},
  month    = apr,
  year     = {2003},
}

@Article{singerFormationCorticalCell1990a,
  author   = {Singer, W. and Gray, C. and Engel, A. and Konig, P. and Artola, A. and Brocher, S.},
  title    = {Formation of Cortical Cell Assemblies},
  issn     = {0091-7451 (Print) 0091-7451 (Linking)},
  language = {English},
  pages    = {939--52},
  volume   = {55},
  journal  = {Cold Spring Harbor Symposia on Quantitative Biology},
  keywords = {Animals,Biological Clocks,Cerebral Cortex/*cytology/growth \& development/physiology,Electrophysiology,Evoked Potentials; Visual,Photic Stimulation,Synapses/physiology,Visual Perception/physiology},
  year     = {1990},
}

@Article{huysAdvancesComputationalUnderstanding2020,
  author     = {Huys, Quentin J. M. and Browning, Michael and Paulus, Martin P. and Frank, Michael J.},
  title      = {Advances in the Computational Understanding of Mental Illness},
  doi        = {10.1038/s41386-020-0746-4},
  issn       = {1740-634X},
  language   = {en},
  pages      = {1--17},
  abstract   = {Computational psychiatry is a rapidly growing field attempting to translate advances in computational neuroscience and machine learning into improved outcomes for patients suffering from mental illness. It encompasses both data-driven and theory-driven efforts. Here, recent advances in theory-driven work are reviewed. We argue that the brain is a computational organ. As such, an understanding of the illnesses arising from it will require a computational framework. The review divides work up into three theoretical approaches that have deep mathematical connections: dynamical systems, Bayesian inference and reinforcement learning. We discuss both general and specific challenges for the field, and suggest ways forward.},
  copyright  = {2020 The Author(s), under exclusive licence to American College of Neuropsychopharmacology},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/psychiatry/cmpsy/huys2020adv.pdf},
  journal    = {Neuropsychopharmacology},
  keywords   = {read,review},
  month      = jul,
  publisher  = {{Nature Publishing Group}},
  readstatus = {read},
  year       = {2020},
}
% == BibTeX quality report for hollandComplexAdaptiveSystems2002:
% ? Unsure about the formatting of the booktitle
% ? Title looks like it was stored in title-case in Zotero

@Book{hollandComplexityVeryShort2014,
  author     = {Holland, John H.},
  title      = {Complexity: {{A Very Short Introduction}}},
  edition    = {1 edition},
  isbn       = {978-0-19-966254-8},
  language   = {English},
  publisher  = {{Oxford University Press}},
  abstract   = {The importance of complexity is well-captured by Hawking's comment: "Complexity is the science of the 21st century". From the movement of flocks of birds to the Internet, environmental sustainability, and market regulation, the study and understanding of complex non-linear systems has become highly influential over the last 30 years.In this Very Short Introduction, one of the leading figures in the field, John Holland, introduces the key elements and conceptual framework of complexity. From complex physical systems such as fluid flow and the difficulties of predicting weather, to complex adaptive systems such as the highly diverse and interdependent ecosystems of rainforests, he combines simple, well-known examples -- Adam Smith's pin factory, Darwin's comet orchid, and Simon's 'watchmaker' -- with an account of the approaches, involving agents and urn models, taken by complexity theory. ABOUT THE SERIES: The Very Short Introductions series from Oxford University Press contains hundreds of titles in almost every subject area. These pocket-sized books are the perfect way to get ahead in a new subject quickly. Our expert authors combine facts, analysis, perspective, new ideas, and enthusiasm to make interesting and challenging topics highly readable.},
  address    = {{Oxford, United Kingdom}},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/books/holland2014com.epub},
  month      = sep,
  shorttitle = {Complexity},
  year       = {2014},
}
% == BibTeX quality report for lawDichopticViewingMethods2013a:
% ? Title looks like it was stored in title-case in Zotero

@Article{lawEffectStimulusStrength2017,
  author     = {Law, Phillip C.F. and Miller, Steven M. and Ngo, Trung T.},
  title      = {The Effect of Stimulus Strength on Binocular Rivalry Rate in Healthy Individuals: {{Implications}} for Genetic, Clinical and Individual Differences Studies},
  doi        = {10.1016/j.physbeh.2017.08.023},
  issn       = {00319384},
  language   = {en},
  pages      = {127--136},
  volume     = {181},
  journal    = {Physiology \& Behavior},
  month      = nov,
  shorttitle = {The Effect of Stimulus Strength on Binocular Rivalry Rate in Healthy Individuals},
  year       = {2017},
}
% == BibTeX quality report for sevgiSocialBayesUsing2016:
% ? Title looks like it was stored in title-case in Zotero

@Article{sevgiSocialBayesUsing2020,
  author     = {Sevgi, Meltem and Diaconescu, Andreea O. and Henco, Lara and Tittgemeyer, Marc and Schilbach, Leonhard},
  title      = {Social {{Bayes}}: {{Using Bayesian Modeling}} to {{Study Autistic Trait}}\textendash{{Related Differences}} in {{Social Cognition}}},
  doi        = {10.1016/j.biopsych.2019.09.032},
  issn       = {0006-3223},
  language   = {en},
  number     = {2},
  pages      = {185--193},
  series     = {Molecular {{Mechanisms}} of {{Neurodevelopmental Disorders}}},
  volume     = {87},
  abstract   = {Background The autistic spectrum is characterized by profound impairments of social interaction. The exact subpersonal processes, however, that underlie the observable lack of social reciprocity are still a matter of substantial controversy. Recently, it has been suggested that the autistic spectrum might be characterized by alterations of the brain's inference about the causes of socially relevant sensory signals. Methods We used a novel reward-based learning task that required integration of nonsocial and social cues in conjunction with computational modeling. Thirty-six healthy subjects were selected based on their score on the Autism-Spectrum Quotient (AQ), and AQ scores were assessed for correlations with cue-related model parameters and task scores. Results Individual differences in AQ scores were significantly correlated with participants' total task scores, with high AQ scorers performing more poorly in the task (r~=~-.39, 95\% confidence interval~=~-0.68 to~-0.13). Computational modeling of the behavioral data unmasked a learning deficit in high AQ scorers, namely, the failure to integrate social context to adapt one's belief precision\textemdash the precision afforded to prior beliefs about changing states in the world\textemdash particularly in relation to the nonsocial cue. Conclusions More pronounced autistic traits in a group of healthy control subjects were related to lower scores associated with misintegration of the social cue. Computational modeling further demonstrated that these trait-related performance differences are not explained by an inability to process the social stimuli and their causes, but rather by the extent to which participants consider social information to infer the nonsocial cue.},
  journal    = {Biological Psychiatry},
  keywords   = {Autistic traits,Bayesian modeling,Computational psychiatry,Reward-based learning,Social cognition,Social gaze},
  month      = jan,
  shorttitle = {Social {{Bayes}}},
  year       = {2020},
}

@Article{bonilla-quintanaActinDendriticSpines2020,
  author     = {{Bonilla-Quintana}, Mayte and W{\"o}rg{\"o}tter, Florentin and D'Este, Elisa and Tetzlaff, Christian and Fauth, Michael},
  title      = {Actin in {{Dendritic Spines Self}}-{{Organizes}} into a {{Critical State}}},
  doi        = {10.1101/2020.04.22.054577},
  language   = {en},
  pages      = {2020.04.22.054577},
  abstract   = {{$<$}h3{$>$}Summary{$<$}/h3{$>$} {$<$}p{$>$}It is known that dendritic spines change their size and shape spontaneously and sometimes to a large degree, but the function of this remains unclear. Here, we quantify these changes using time-series analysis of confocal data and demonstrate that spine size can follow different autoregressive integrated moving average (ARIMA) models and that shape- and size-changes are not correlated. We capture this behavior with a biophysical model, based on the spines' actin dynamics, and find the presence of 1\emph{/f} noise. When investigating its origins, the model predicts that actin in the dendritic spines self-organizes into a critical state, which creates a fine balance between static actin filaments and free monomers. We speculate that such a balance might be functionally beneficially to allow a spine to quickly reconfigure itself after LTP induction.{$<$}/p{$>$}},
  chapter    = {New Results},
  copyright  = {\textcopyright{} 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NoDerivs 4.0 International), CC BY-ND 4.0, as described at http://creativecommons.org/licenses/by-nd/4.0/},
  journal    = {bioRxiv},
  keywords   = {read},
  month      = apr,
  publisher  = {{Cold Spring Harbor Laboratory}},
  readstatus = {read},
  year       = {2020},
}

@Article{douglasRecurrentNeuronalCircuits2007,
  author     = {Douglas, R. J. and Martin, K. A.},
  title      = {Recurrent Neuronal Circuits in the Neocortex},
  doi        = {10.1016/j.cub.2007.04.024},
  issn       = {0960-9822 (Print) 0960-9822 (Linking)},
  pages      = {R496-500},
  volume     = {17},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neuroprinciples/computation/douglas2007rec.pdf},
  journal    = {Curr Biol},
  keywords   = {Animals,Humans,Neocortex/*physiology,Neurons/*physiology,read},
  month      = jul,
  readstatus = {read},
  year       = {2007},
}

@Article{kapoorParallelFunctionallySegregated2018,
  author    = {Kapoor, Vishal and Besserve, Michel and Logothetis, Nikos K. and Panagiotaropoulos, Theofanis I.},
  title     = {Parallel and Functionally Segregated Processing of Task Phase and Conscious Content in the Prefrontal Cortex},
  doi       = {10.1038/s42003-018-0225-1},
  issn      = {2399-3642},
  language  = {en},
  number    = {1},
  pages     = {1--12},
  volume    = {1},
  abstract  = {The role of lateral prefrontal cortex (LPFC) in mediating conscious perception has been recently questioned due to potential confounds resulting from the parallel operation of task related processes. We have previously demonstrated encoding of contents of~visual consciousness in LPFC neurons during a no-report task involving perceptual suppression. Here, we report a separate LPFC population that exhibits task-phase related activity during the same task. The activity profile of these neurons could be captured as canonical response patterns (CRPs), with their peak amplitudes sequentially distributed across different task phases. Perceptually suppressed visual input had a negligible impact on sequential firing and functional connectivity structure. Importantly, task-phase related neurons were functionally segregated from the neuronal population, which encoded conscious perception. These results suggest that neurons exhibiting task-phase related~activity operate in the LPFC concurrently with, but segregated from neurons representing conscious content during a no-report task involving perceptual suppression.},
  copyright = {2018 The Author(s)},
  journal   = {Communications Biology},
  month     = dec,
  publisher = {{Nature Publishing Group}},
  year      = {2018},
}

@Misc{bar-yamWhyComplexityDifferent2017,
  author     = {{Bar-Yam}, Yaneer},
  title      = {Why {{Complexity}} Is {{Different}}},
  language   = {en-US},
  abstract   = {One of the hardest things to explain is why complex systems are actually different from simple systems. The problem is rooted in a set of ideas that work together and reinforce each other so that they appear seamless: Given a set of properties that a system has, we can study those properties with experiments and model what those properties do over time. Everything that is needed should be found in the data and the model we write down. The flaw in this seemingly obvious statement is that what is missing is realizing that one may be starting from the wrong properties. One might have missed one of the key properties that we need to include, or the set of properties that one has to describe might change over time. Then why don't we add more properties until we include enough? The problem is that we will be overwhelmed by too many of them; the process never ends. The key, it turns out, is figuring out how to identify which properties are important, which itself is a dynamic property of the system. To explain this idea we can start from a review of the way this problem came up in physics and how it was solved for that case. The ideas are rooted in an approximation called "separation of scales."},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neuroprinciples/multiScale/bar-yam2017why.pdf},
  keywords   = {read},
  readstatus = {read},
  year       = {2017},
}
% == BibTeX quality report for kueblerHarnessingVariabilityNeuronal2018a:
% ? Title looks like it was stored in title-case in Zotero

@InCollection{kueblerOptimalFisherDecoding2019,
  author     = {Kuebler, Eric S. and Calderini, Matias and Lambert, Philippe and Thivierge, Jean-Philippe},
  booktitle  = {The {{Functional Role}} of {{Critical Dynamics}} in {{Neural Systems}}},
  title      = {Optimal {{Fisher Decoding}} of {{Neural Activity Near Criticality}}},
  doi        = {10.1007/978-3-030-20965-0_9},
  editor     = {Tomen, Nergis and Herrmann, J. Michael and Ernst, Udo},
  isbn       = {978-3-030-20965-0},
  language   = {en},
  pages      = {159--177},
  publisher  = {{Springer International Publishing}},
  series     = {Springer {{Series}} on {{Bio}}- and {{Neurosystems}}},
  abstract   = {Studies on the functional role of criticality in the brain have thus far mainly examined the role of neural dynamics on stimulus encoding, with scant attention devoted to the impact of these dynamics on downstream decoding. Here, we consider the question of how a linear decoder may classify spontaneous cortical activity both near and away from a critical state. We show that accurate performance of the decoder is obtained only when network activity is near criticality. Simulations of a branching process capture these results and argue for a potential role of the critical state in providing a format for neural activity that can be adequately processed by downstream brain structures.},
  address    = {{Cham}},
  keywords   = {r14,read},
  readstatus = {read},
  year       = {2019},
}

@Article{singerBrainComplexSelforganizing2009,
  author   = {Singer, W.},
  title    = {The {{Brain}}, a {{Complex Self}}-Organizing {{System}}},
  doi      = {10.1017/S1062798709000751},
  issn     = {1062-7987},
  language = {English},
  number   = {2},
  pages    = {321--329},
  volume   = {17},
  abstract = {Our intuition assumes that there is a centre in our brain in which all relevant information converges and where all decisions are reached. To neurobiologists, the brain presents itself as a highly distributed system in which a very large number of processes occur simultaneously and in parallel without requiring coordination by a central convergence centre. The specific architecture resembles, in many respects, small world networks and raises the question of how the multiple operations occurring in parallel are bound together in order to give rise to coherent perception and action. Based on data obtained with massive parallel recordings, the hypothesis will be forwarded that temporal coherence serves as an important organizing principle and that this coherence is achieved by the synchronization of oscillatory activity in distinct frequency bands.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/brain/singer2009the.pdf},
  journal  = {European Review},
  month    = may,
  year     = {2009},
}

@Article{constantinidisCorrelatedDischargesPutative2002,
  author   = {Constantinidis, C. and {Goldman-Rakic}, P. S.},
  title    = {Correlated Discharges among Putative Pyramidal Neurons and Interneurons in the Primate Prefrontal Cortex},
  doi      = {DOI 10.1152/jn.00188.2002},
  issn     = {0022-3077},
  language = {English},
  number   = {6},
  pages    = {3487--3497},
  volume   = {88},
  abstract = {Neurophysiological recordings have revealed that the discharges of nearby cortical cells are positively correlated in time scales that range from millisecond synchronization of action potentials to much slower firing rate co-variations, evident in rates averaged over hundreds of milliseconds. The presence of correlated firing can offer insights into the patterns of connectivity between neurons; however, few models of population coding have taken account of the neuronal diversity present in cerebral cortex, notably a distinction between inhibitory and excitatory cells. We addressed this question in the monkey dorsolateral prefrontal cortex by recording neuronal activity from multiple micro-electrodes, typically spaced 0.2-0.3 mm apart. Putative excitatory and inhibitory neurons were distinguished based on their action potential waveform and baseline discharge rate. We tested each pair of simultaneously recorded neurons for presence of significant cross-correlation peaks and measured the correlation of their averaged firing rates in successive trials. When observed, cross-correlation peaks were centered at time 0, indicating synchronous firing consistent with two neurons receiving common input. Discharges in pairs of putative inhibitory interneurons were found to be significantly more strongly correlated than in pairs of putative excitatory cells. The degree of correlated firing was also higher for neurons with similar spatial receptive fields and neurons active in the same epochs of the behavioral task. These factors were important in predicting the strength of both short time scale ({$<$}5 ms) correlations and of trial-to-trial discharge rate covariations. Correlated firing was only marginally accounted for by motor and behavioral variations between trials. Our findings suggest that nearby inhibitory neurons are more tightly synchronized than excitatory ones and account for much of the correlated discharges commonly observed in undifferentiated cortical networks. In contrast, the discharge of pyramidal neurons, the sole projection cells of the cerebral cortex, appears largely independent, suggesting that correlated firing may be a property confined within local circuits and only to a lesser degree propagated to distant cortical areas and modules.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neuralInteractions/PWcorrelations/constantinidis2002cor.pdf},
  journal  = {J Neurophysiol},
  keywords = {cortical-neurons,inhibitory neurons,monkey,nonpyramidal cells,primary visual-cortex,rat frontal-cortex,spatial working-memory,spike trains,striate cortex,time-course},
  month    = dec,
  year     = {2002},
}

@Article{frassleBinocularRivalryFrontal2014,
  author   = {Frassle, S. and Sommer, J. and Jansen, A. and Naber, M. and Einhauser, W.},
  title    = {Binocular Rivalry: Frontal Activity Relates to Introspection and Action but Not to Perception},
  doi      = {10.1523/JNEUROSCI.4403-13.2014},
  issn     = {1529-2401 (Electronic) 0270-6474 (Linking)},
  number   = {5},
  pages    = {1738--47},
  volume   = {34},
  abstract = {When two dissimilar stimuli are presented to the eyes, perception alternates between multiple interpretations, a phenomenon dubbed binocular rivalry. Numerous recent imaging studies have attempted to unveil neural substrates underlying multistable perception. However, these studies had a conceptual constraint: access to observers' perceptual state relied on their introspection and active report. Here, we investigated to what extent neural correlates of binocular rivalry in healthy humans are confounded by this subjective measure and by action. We used the optokinetic nystagmus and pupil size to objectively and continuously map perceptual alternations for binocular-rivalry stimuli. Combining these two measures with fMRI allowed us to assess the neural correlates of binocular rivalry time locked to the perceptual alternations in the absence of active report. When observers were asked to actively report their percept, our objective measures matched the report. In this active condition, objective measures and subjective reporting revealed that occipital, parietal, and frontal areas underlie the processing of binocular rivalry, replicating earlier findings. Furthermore, objective measures provided additional statistical power due to their continuous nature. Importantly, when observers passively experienced rivalry without reporting perceptual alternations, a different picture emerged: differential neural activity in frontal areas was absent, whereas activation in occipital and parietal regions persisted. Our results question the popular view of a driving role of frontal areas in the initiation of perceptual alternations during binocular rivalry. Instead, we conclude that frontal areas are associated with active report and introspection rather than with rivalry per se.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/perception/multiStablePerception_msp/frassle2014bin.pdf},
  journal  = {J Neurosci},
  month    = jan,
  year     = {2014},
}

@Article{crickVisualPerceptionRivalry1996a,
  author   = {Crick, F.},
  title    = {Visual Perception: Rivalry and Consciousness},
  doi      = {10.1038/379485a0},
  issn     = {0028-0836 (Print) 0028-0836 (Linking)},
  language = {en},
  number   = {6565},
  pages    = {485--6},
  volume   = {379},
  file     = {/Users/ssafavi/Documents/libraries/EndnoteLib_fromWin407/EndnoteLib_MPIPClocal_20170723.Data/PDF/3475289885/Crick-1996.pdf},
  journal  = {Nature},
  keywords = {*Consciousness/physiology,*Visual Perception/physiology,Animals,Humans,Macaca,Neurons/physiology,Vision; Binocular/physiology,Visual Cortex/physiology},
  month    = feb,
  year     = {1996},
}

@Article{brochiniPhaseTransitionsSelforganized2016,
  author    = {Brochini, Ludmila and {de Andrade Costa}, Ariadne and Abadi, Miguel and Roque, Ant{\^o}nio C. and Stolfi, Jorge and Kinouchi, Osame},
  title     = {Phase Transitions and Self-Organized Criticality in Networks of Stochastic Spiking Neurons},
  doi       = {10.1038/srep35831},
  issn      = {2045-2322},
  language  = {en},
  pages     = {35831},
  volume    = {6},
  abstract  = {Phase transitions and critical behavior are crucial issues both in theoretical and experimental neuroscience. We report analytic and computational results about phase transitions and self-organized criticality (SOC) in networks with general stochastic neurons. The stochastic neuron has a firing probability given by a smooth monotonic function {$\Phi$}(V) of the membrane potential V, rather than a sharp firing threshold. We find that such networks can operate in several dynamic regimes (phases) depending on the average synaptic weight and the shape of the firing function {$\Phi$}. In particular, we encounter both continuous and discontinuous phase transitions to absorbing states. At the continuous transition critical boundary, neuronal avalanches occur whose distributions of size and duration are given by power laws, as observed in biological neural networks. We also propose and test a new mechanism to produce SOC: the use of dynamic neuronal gains \textendash{} a form of short-term plasticity probably located at the axon initial segment (AIS) \textendash{} instead of depressing synapses at the dendrites (as previously studied in the literature). The new self-organization mechanism produces a slightly supercritical state, that we called SOSC, in accord to some intuitions of Alan Turing.},
  copyright = {2016 Nature Publishing Group},
  file      = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/criticality/brochini2016pha.pdf;/home/ssafavi/Zotero/storage/G8M3IGQP/Brochini et al. - 2016 - Phase transitions and self-organized criticality i.pdf},
  journal   = {Scientific Reports},
  month     = nov,
  year      = {2016},
}
% == BibTeX quality report for dainiNeuropsychologicalEvidenceHighLevel2010a:
% ? Title looks like it was stored in title-case in Zotero

@InProceedings{daiRecurrentCoevolutionaryLatent2016,
  author    = {Dai, Hanjun and Wang, Yichen and Trivedi, Rakshit and Song, Le},
  booktitle = {Proceedings of the 1st {{Workshop}} on {{Deep Learning}} for {{Recommender Systems}}},
  title     = {Recurrent {{Coevolutionary Latent Feature Processes}} for {{Continuous}}-{{Time Recommendation}}},
  doi       = {10.1145/2988450.2988451},
  isbn      = {978-1-4503-4795-2},
  pages     = {29--34},
  publisher = {{Association for Computing Machinery}},
  series    = {{{DLRS}} 2016},
  abstract  = {Matching users to the right items at the right time is a fundamental task in recommender systems. As users interact with different items over time, users' and items' feature may drift, evolve and co-evolve over time. Traditional models based on static latent features or discretizing time into epochs can become ineffective for capturing the fine-grained temporal dynamics in the user-item interactions. We propose a coevolutionary latent feature process model that accurately captures the coevolving nature of users' and items' feature. We use a recurrent neural network to automatically learn a representation of influences from drift, evolution and co-evolution of user and item features. We develop an efficient stochastic gradient algorithm for learning the model parameters which can readily scale up to millions of events. Experiments on diverse real-world datasets demonstrate significant improvements in user behavior prediction compared to state-of-the-arts.},
  address   = {{New York, NY, USA}},
  month     = sep,
  year      = {2016},
}

@Article{ramirez-villegasDissectingSynapseFrequencyDependent2018,
  author   = {{Ramirez-Villegas}, Juan F. and Willeke, Konstantin F. and Logothetis, Nikos K. and Besserve, Michel},
  title    = {Dissecting the {{Synapse}}- and {{Frequency}}-{{Dependent Network Mechanisms}} of {{In~Vivo Hippocampal Sharp Wave}}-{{Ripples}}},
  doi      = {10.1016/j.neuron.2018.09.041},
  issn     = {0896-6273},
  number   = {5},
  pages    = {1224-1240.e13},
  volume   = {100},
  abstract = {Summary Hippocampal ripple oscillations likely support reactivation of memory traces that manifest themselves as~temporally organized spiking of sparse neuronal ensembles. However, the network mechanisms concurring to achieve this function are largely unknown. We designed a multi-compartmental model of the CA3-CA1 subfields to generate biophysically realistic ripple dynamics from the cellular level to local field potentials. Simulations broadly parallel in~vivo observations and support that ripples emerge from CA1 pyramidal spiking paced by recurrent inhibition. In addition to ripple oscillations, key coordination mechanisms involve concomitant aspects of network activity. Recurrent synaptic interactions in CA1 exhibit slow-gamma band coherence with CA3 input, thus offering a way to coordinate CA1 activities with CA3 inducers. Moreover, CA1 feedback inhibition controls the content of spontaneous replay during CA1 ripples, forming new mnemonic representations through plasticity. These insights are consistent with slow-gamma interactions and interneuronal circuit plasticity observed in~vivo, suggesting a multifaceted ripple-related replay phenomenon.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/learning_memory_sleep/ramirez-villegas2018dis.pdf},
  journal  = {Neuron},
  keywords = {brain rhythms,compartmental models,E-I balance,hippocampus,learning,local field potentials,memory,plasticity,replay,sharp wave-ripples},
  month    = dec,
  year     = {2018},
}

@Article{olivaRoleHippocampalCA22016,
  author   = {Oliva, A. and {Fernandez-Ruiz}, A. and Buzsaki, G. and Berenyi, A.},
  title    = {Role of {{Hippocampal CA2 Region}} in {{Triggering Sharp}}-{{Wave Ripples}}},
  doi      = {10.1016/j.neuron.2016.08.008},
  issn     = {1097-4199 (Electronic) 0896-6273 (Linking)},
  pages    = {1342--55},
  volume   = {91},
  abstract = {Sharp-wave ripples (SPW-Rs) in the hippocampus are implied in memory consolidation, as shown by observational and interventional experiments. However, the mechanism of their generation remains unclear. Using two-dimensional silicon probe arrays, we investigated the propagation of SPW-Rs across the hippocampal CA1, CA2, and CA3 subregions. Synchronous activation of CA2 ensembles preceded SPW-R-related population activity in CA3 and CA1 regions. Deep CA2 neurons gradually increased their activity prior to ripples and were suppressed during the population bursts of CA3-CA1 neurons (ramping cells). Activity of superficial CA2 cells preceded the activity surge in CA3-CA1 (phasic cells). The trigger role of the CA2 region in SPW-R was more pronounced during waking than sleeping. These results point to the CA2 region as an initiation zone for SPW-Rs.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/unfiled/oliva2016rol.pdf;/home/ssafavi/Zotero/storage/LUSRMGWY/Oliva-2016.pdf},
  journal  = {Neuron},
  keywords = {Ca1,Ca2,Ca3,high-frequency,hippocampus,large-scale recordings,learning,Lfp,memory consolidation,network mechanism,ripple,sharp-wave,single-unit},
  month    = sep,
  year     = {2016},
}

@Article{beerDynamicalSystemsPerspective1995,
  author     = {Beer, Randall D.},
  title      = {A Dynamical Systems Perspective on Agent-Environment Interaction},
  doi        = {10.1016/0004-3702(94)00005-L},
  issn       = {0004-3702},
  language   = {en},
  number     = {1},
  pages      = {173--215},
  volume     = {72},
  abstract   = {Using the language of dynamical systems theory, a general theoretical framework for the synthesis and analysis of autonomous agents is sketched. In this framework, an agent and its environment are modeled as two coupled dynamical systems whose mutual interaction is in general jointly responsible for the agent's behavior. In addition, the adaptive fit between an agent and its environment is characterized in terms of the satisfaction of a given constraint on the trajectories of the coupled agent-environment system. The utility of this framework is demonstrated by using it to first synthesize and then analyze a walking behavior for a legged agent.},
  journal    = {Artificial Intelligence},
  keywords   = {read},
  month      = jan,
  readstatus = {read},
  year       = {1995},
}

@Book{rosenblithSensoryCommunication2012,
  title     = {Sensory {{Communication}}},
  doi       = {10.7551/mitpress/9780262518420.001.0001},
  editor    = {Rosenblith, Walter A.},
  isbn      = {978-0-262-51842-0},
  publisher = {{The MIT Press}},
  month     = sep,
  year      = {2012},
}

@Article{buzsakiOriginExtracellularFields2012,
  author   = {Buzsaki, G. and Anastassiou, C. A. and Koch, C.},
  title    = {The Origin of Extracellular Fields and Currents--{{EEG}}, {{ECoG}}, {{LFP}} and Spikes},
  doi      = {10.1038/nrn3241},
  issn     = {1471-0048 (Electronic) 1471-003X (Linking)},
  number   = {6},
  pages    = {407--20},
  volume   = {13},
  abstract = {Neuronal activity in the brain gives rise to transmembrane currents that can be measured in the extracellular medium. Although the major contributor of the extracellular signal is the synaptic transmembrane current, other sources--including Na(+) and Ca(2+) spikes, ionic fluxes through voltage- and ligand-gated channels, and intrinsic membrane oscillations--can substantially shape the extracellular field. High-density recordings of field activity in animals and subdural grid recordings in humans, combined with recently developed data processing tools and computational modelling, can provide insight into the cooperative behaviour of neurons, their average synaptic input and their spiking output, and can increase our understanding of how these processes contribute to the extracellular signal.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/projects/nnr/MT/buzsaki2012the.pdf},
  journal  = {Nat Rev Neurosci},
  keywords = {*Electroencephalography,Animals,Calcium Signaling/physiology,Electrical Synapses/physiology,Evoked Potentials/*physiology,Extracellular Space/*physiology,Humans,Ligand-Gated Ion Channels,Magnetoencephalography,Neural Conduction/physiology,Neuroglia/physiology,Neurons/physiology/ultrastructure,Synapses/physiology/ultrastructure,Voltage-Sensitive Dye Imaging},
  month    = may,
  pmcid    = {PMC4907333},
  year     = {2012},
}
% == BibTeX quality report for danielsDualCodingTheory2017:
% ? Title looks like it was stored in title-case in Zotero

@Article{danielsQuantifyingCollectivity2016,
  author     = {Daniels, B. C. and Ellison, C. J. and Krakauer, D. C. and Flack, J. C.},
  title      = {Quantifying Collectivity},
  doi        = {10.1016/j.conb.2016.01.012},
  issn       = {1873-6882 (Electronic) 0959-4388 (Linking)},
  pages      = {106--113},
  volume     = {37},
  abstract   = {In biological function emerges from the interactions of components with only partially aligned interests. An example is the brain-a large aggregation of neurons capable of producing unitary, coherent output. A theory for how such aggregations produce coherent output remains elusive. A first question we might ask is how collective is the behavior of the components? Here we introduce two properties of collectivity and illustrate how these properties can be quantified using approaches from information theory and statistical physics. First, amplification quantifies the sensitivity of the large scale to information at the small scale and is related to the notion of criticality in statistical physics. Second, decomposability reveals the extent to which aggregate behavior is reducible to individual contributions or is the result of synergistic interactions among components forming larger subgroups. These measures facilitate identification of causally important components and subgroups that might be experimentally manipulated to study the evolution and controllability of biological circuits and their outputs.},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/synergy/daniels2016qua.pdf},
  journal    = {Curr Opin Neurobiol},
  keywords   = {read},
  month      = feb,
  readstatus = {read},
  year       = {2016},
}

@Article{spornsConnectivityComplexityRelationship2000,
  author   = {Sporns, O. and Tononi, G. and Edelman, G. M.},
  title    = {Connectivity and Complexity: The Relationship between Neuroanatomy and Brain Dynamics},
  doi      = {Doi 10.1016/S0893-6080(00)00053-8},
  issn     = {0893-6080},
  language = {English},
  pages    = {909--922},
  volume   = {13},
  abstract = {Nervous systems facing complex environments have to balance two seemingly opposing requirements. First, there is a need quickly and reliably to extract important features from sensory inputs. This is accomplished by functionally segregated (specialized) sets of neurons, e.g. those found in different cortical areas. Second, there is a need to generate coherent perceptual and cognitive states allowing an organism to respond to objects and events, which represent conjunctions of numerous individual features. This need is accomplished by functional integration of the activity of specialized neurons through their dynamic interactions. These interactions produce patterns of temporal correlations or functional connectivity involving distributed neuronal populations, both within and across cortical areas. Empirical and computational studies suggest that changes in functional connectivity may underlie specific perceptual and cognitive states and involve the integration of information across specialized areas of the brain. The interplay between functional segregation and integration can be quantitatively captured using concepts from statistical information theory, in particular by defining a measure of neural complexity. Complexity measures the extent to which a pattern of functional connectivity produced by units or areas within a neural system combines the dual requirements of functional segregation and integration. We find that specific neuroanatomical motifs are uniquely associated with high levels of complexity and that such motifs are embedded in the pattern of long-range cortico-cortical pathways linking segregated areas of the mammalian cerebral cortex. Our theoretical findings offer new insight into the intricate relationship between connectivity and complexity in the nervous system. (C) 2000 Elsevier Science Ltd. All rights reserved.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/unfiled/sporns2000con.pdf},
  journal  = {Neural Networks},
  keywords = {brain imaging,cat visual-cortex,coherent oscillations,cortical areas,field potential oscillations,horizontal connections,integration,learning,neural dynamics,neuronal responses,oscillation,reentry,selection,synchronization,synchrony,thalamocortical system},
  month    = oct,
  year     = {2000},
}

@Article{rothschildFunctionalOrganizationPopulation2010,
  author    = {Rothschild, Gideon and Nelken, Israel and Mizrahi, Adi},
  title     = {Functional Organization and Population Dynamics in the Mouse Primary Auditory Cortex},
  doi       = {10.1038/nn.2484},
  issn      = {1546-1726},
  language  = {en},
  number    = {3},
  pages     = {353--360},
  volume    = {13},
  abstract  = {The authors use in vivo two-photon calcium imaging to examine the responses and network dynamics of layer 2/3 neurons in the primary auditory cortex of mice in response to pure tones. They find that local populations in A1 are heterogeneous, but, despite this, there was a higher than average noise correlation.},
  copyright = {2010 Nature Publishing Group},
  journal   = {Nature Neuroscience},
  month     = mar,
  publisher = {{Nature Publishing Group}},
  year      = {2010},
}

@Article{logothetisNeuralEventTriggeredFMRILargescale2014,
  author   = {Logothetis, N. K.},
  title    = {Neural-{{Event}}-{{Triggered fMRI}} of Large-Scale Neural Networks},
  doi      = {10.1016/j.conb.2014.11.009},
  issn     = {1873-6882 (Electronic) 0959-4388 (Linking)},
  pages    = {214--222},
  volume   = {31C},
  abstract = {Brains are dynamic systems, consisting of huge number of massively interconnected elementary components. The activity of these components results in an initial condition-sensitive evolution of network states through highly non-linear, probabilistic interactions. The dynamics of such systems cannot be described merely by studying the behavior of their components; instead their study benefits from employing multimodal methods. Neural-Event-Triggered (NET) fMRI is a novel method allowing identification of events that can be used to examine multi-structure activity in the brain. First results offered insights into the networks that might be involved in memory consolidation. On-going work examines the physiological underpinnings of the up and down modulation of metabolic activity, mapped with this methodology.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/multiModal/logothetis2014neu.pdf},
  journal  = {Current Opinion in Neurobiology},
  month    = dec,
  year     = {2014},
}

@Article{hidalgoCooperationCompetitionEmergence2016,
  author     = {Hidalgo, Jorge and Grilli, Jacopo and Suweis, Samir and Maritan, Amos and Mu{\~n}oz, Miguel A.},
  title      = {Cooperation, Competition and the Emergence of Criticality in Communities of Adaptive Systems},
  doi        = {10.1088/1742-5468/2016/03/033203},
  issn       = {1742-5468},
  language   = {en},
  number     = {3},
  pages      = {033203},
  volume     = {2016},
  abstract   = {The hypothesis that living systems can benefit from operating at the vicinity of critical points has gained momentum in recent years. Criticality may confer an optimal balance between too ordered and exceedingly noisy states. Here we present a model, based on information theory and statistical mechanics, illustrating how and why a community of agents aimed at understanding and communicating with each other converges to a globally coherent state in which all individuals are close to an internal critical state, i.e. at the borderline between order and disorder. We study\textemdash both analytically and computationally\textemdash the circumstances under which criticality is the best possible outcome of the dynamical process, confirming the convergence to critical points under very generic conditions. Finally, we analyze the effect of cooperation (agents trying to enhance not only their fitness, but also that of other individuals) and competition (agents trying to improve their own fitness and to diminish those of competitors) within our setting. The conclusion is that, while competition fosters criticality, cooperation hinders it and can lead to more ordered or more disordered consensual outcomes.},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/criticality/hidalgo2016coo.pdf},
  journal    = {Journal of Statistical Mechanics: Theory and Experiment},
  keywords   = {read},
  readstatus = {read},
  year       = {2016},
}

@Article{borsboomSmallWorldPsychopathology2011,
  author    = {Borsboom, Denny and Cramer, Ang{\'e}lique O. J. and Schmittmann, Verena D. and Epskamp, Sacha and Waldorp, Lourens J.},
  title     = {The {{Small World}} of {{Psychopathology}}},
  doi       = {10.1371/journal.pone.0027407},
  issn      = {1932-6203},
  language  = {en},
  number    = {11},
  pages     = {e27407},
  volume    = {6},
  abstract  = {Background Mental disorders are highly comorbid: people having one disorder are likely to have another as well. We explain empirical comorbidity patterns based on a network model of psychiatric symptoms, derived from an analysis of symptom overlap in the Diagnostic and Statistical Manual of Mental Disorders-IV (DSM-IV). Principal Findings We show that a) half of the symptoms in the DSM-IV network are connected, b) the architecture of these connections conforms to a small world structure, featuring a high degree of clustering but a short average path length, and c) distances between disorders in this structure predict empirical comorbidity rates. Network simulations of Major Depressive Episode and Generalized Anxiety Disorder show that the model faithfully reproduces empirical population statistics for these disorders. Conclusions In the network model, mental disorders are inherently complex. This explains the limited successes of genetic, neuroscientific, and etiological approaches to unravel their causes. We outline a psychosystems approach to investigate the structure and dynamics of mental disorders.},
  journal   = {PLOS ONE},
  keywords  = {Anxiety disorders,Built structures,Clinical genetics,Clinical psychology,Depression,Insomnia,Network analysis,Simulation and modeling},
  month     = nov,
  publisher = {{Public Library of Science}},
  year      = {2011},
}

@Article{klinkUnitedWeSense2012b,
  author     = {Klink, P. C. and {van Wezel}, R. J. A. and {van Ee}, R.},
  title      = {United We Sense, Divided We Fail: Context-Driven Perception of Ambiguous Visual Stimuli},
  doi        = {10.1098/rstb.2011.0358},
  issn       = {0962-8436},
  number     = {1591},
  pages      = {932--941},
  volume     = {367},
  abstract   = {Ambiguous visual stimuli provide the brain with sensory information that contains conflicting evidence for multiple mutually exclusive interpretations. Two distinct aspects of the phenomenological experience associated with viewing ambiguous visual stimuli are the apparent stability of perception whenever one perceptual interpretation is dominant, and the instability of perception that causes perceptual dominance to alternate between perceptual interpretations upon extended viewing. This review summarizes several ways in which contextual information can help the brain resolve visual ambiguities and construct temporarily stable perceptual experiences. Temporal context through prior stimulation or internal brain states brought about by feedback from higher cortical processing levels may alter the response characteristics of specific neurons involved in rivalry resolution. Furthermore, spatial or crossmodal context may strengthen the neuronal representation of one of the possible perceptual interpretations and consequently bias the rivalry process towards it. We suggest that contextual influences on perceptual choices with ambiguous visual stimuli can be highly informative about the neuronal mechanisms of context-driven inference in the general processes of perceptual decision-making.},
  journal    = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  month      = apr,
  pmcid      = {PMC3282309},
  pmid       = {22371615},
  shorttitle = {United We Sense, Divided We Fail},
  year       = {2012},
}

@Article{marinazzoInformationTransferCriticality2014,
  author   = {Marinazzo, D. and Pellicoro, M. and Wu, G. and Angelini, L. and Cortes, J. M. and Stramaglia, S.},
  title    = {Information Transfer and Criticality in the {{Ising}} Model on the Human Connectome},
  doi      = {10.1371/journal.pone.0093616},
  issn     = {1932-6203 (Electronic) 1932-6203 (Linking)},
  pages    = {e93616},
  volume   = {9},
  abstract = {We implement the Ising model on a structural connectivity matrix describing the brain at two different resolutions. Tuning the model temperature to its critical value, i.e. at the susceptibility peak, we find a maximal amount of total information transfer between the spin variables. At this point the amount of information that can be redistributed by some nodes reaches a limit and the net dynamics exhibits signature of the law of diminishing marginal returns, a fundamental principle connected to saturated levels of production. Our results extend the recent analysis of dynamical oscillators models on the connectome structure, taking into account lagged and directional influences, focusing only on the nodes that are more prone to became bottlenecks of information. The ratio between the outgoing and the incoming information at each node is related to the the sum of the weights to that node and to the average time between consecutive time flips of spins. The results for the connectome of 66 nodes and for that of 998 nodes are similar, thus suggesting that these properties are scale-independent. Finally, we also find that the brain dynamics at criticality is organized maximally to a rich-club w.r.t. the network of information flows.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/criticality/marinazzo2014inf.pdf},
  journal  = {PLoS One},
  year     = {2014},
}

@Article{buzsakiScalingBrainSize2013a,
  author   = {Buzsaki, G. and Logothetis, N. and Singer, W.},
  title    = {Scaling Brain Size, Keeping Timing: Evolutionary Preservation of Brain Rhythms},
  doi      = {10.1016/j.neuron.2013.10.002},
  issn     = {1097-4199 (Electronic) 0896-6273 (Linking)},
  number   = {3},
  pages    = {751--64},
  volume   = {80},
  abstract = {Despite the several-thousand-fold increase of brain volume during the course of mammalian evolution, the hierarchy of brain oscillations remains remarkably preserved, allowing for multiple-time-scale communication within and across neuronal networks at approximately the same speed, irrespective of brain size. Deployment of large-diameter axons of long-range neurons could be a key factor in the preserved time management in growing brains. We discuss the consequences of such preserved network constellation in mental disease, drug discovery, and interventional therapies.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/c_onTabelPrince/buzsaki2013sca.pdf},
  journal  = {Neuron},
  month    = oct,
  year     = {2013},
}
% == BibTeX quality report for harrisonSpatiotemporalConditionalInference2014:
% ? Title looks like it was stored in title-case in Zotero

@Article{harrisOrganizationCellAssemblies2003,
  author   = {Harris, K. D. and Csicsvari, J. and Hirase, H. and Dragoi, G. and Buzsaki, G.},
  title    = {Organization of Cell Assemblies in the Hippocampus},
  doi      = {10.1038/nature01834},
  issn     = {1476-4687 (Electronic) 0028-0836 (Linking)},
  language = {English},
  pages    = {552--6},
  volume   = {424},
  abstract = {Neurons can produce action potentials with high temporal precision. A fundamental issue is whether, and how, this capability is used in information processing. According to the 'cell assembly' hypothesis, transient synchrony of anatomically distributed groups of neurons underlies processing of both external sensory input and internal cognitive mechanisms. Accordingly, neuron populations should be arranged into groups whose synchrony exceeds that predicted by common modulation by sensory input. Here we find that the spike times of hippocampal pyramidal cells can be predicted more accurately by using the spike times of simultaneously recorded neurons in addition to the animals location in space. This improvement remained when the spatial prediction was refined with a spatially dependent theta phase modulation. The time window in which spike times are best predicted from simultaneous peer activity is 10-30 ms, suggesting that cell assemblies are synchronized at this timescale. Because this temporal window matches the membrane time constant of pyramidal neurons, the period of the hippocampal gamma oscillation and the time window for synaptic plasticity, we propose that cooperative activity at this timescale is optimal for information transmission and storage in cortical circuits.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neuralInteractions/harris2003org.pdf},
  journal  = {Nature},
  keywords = {*Action Potentials,Animals,Male,Pyramidal Cells/*cytology/*physiology,Rats,Rats; Sprague-Dawley,Time Factors},
  month    = jul,
  year     = {2003},
}
% == BibTeX quality report for clauwaertRoleDopamineVisual2014:
% Missing required field 'school'

@Article{clawsonAdaptationScalefreeDynamics2017,
  author   = {Clawson, W. P. and Wright, N. C. and Wessel, R. and Shew, W. L.},
  title    = {Adaptation towards Scale-Free Dynamics Improves Cortical Stimulus Discrimination at the Cost of Reduced Detection},
  doi      = {10.1371/journal.pcbi.1005574},
  issn     = {1553-7358 (Electronic) 1553-734X (Linking)},
  pages    = {e1005574},
  volume   = {13},
  abstract = {Fundamental to the function of nervous systems is the ability to reorganize to cope with changing sensory input. Although well-studied in single neurons, how such adaptive versatility manifests in the collective population dynamics and function of cerebral cortex remains unknown. Here we measured population neural activity with microelectrode arrays in turtle visual cortex while visually stimulating the retina. First, we found that, following the onset of stimulation, adaptation tunes the collective population dynamics towards a special regime with scale-free spatiotemporal activity, after an initial large-scale transient response. Concurrently, we observed an adaptive tradeoff between two important aspects of population coding-sensory detection and discrimination. As adaptation tuned the cortex toward scale-free dynamics, stimulus discrimination was enhanced, while stimulus detection was reduced. Finally, we used a network-level computational model to show that short-term synaptic depression was sufficient to mechanistically explain our experimental results. In the model, scale-free dynamics emerge only when the model operates near a special regime called criticality. Together our model and experimental results suggest unanticipated functional benefits and costs of adaptation near criticality in visual cortex.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/criticality/clawson2017ada_uncorrectedProof.pdf;/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/criticality/clawson2017ada.pdf},
  journal  = {PLoS Comput Biol},
  keywords = {Visual cortex;Neurons;Turtles;Cognition;Vision;Synapses;Population dynamics;Action potentials},
  month    = may,
  year     = {2017},
}

@Article{shpigelmanSpikernelsPredictingArm2005,
  author   = {Shpigelman, L. and Singer, Y. and Paz, R. and Vaadia, E.},
  title    = {Spikernels: Predicting Arm Movements by Embedding Population Spike Rate Patterns in Inner-Product Spaces},
  doi      = {10.1162/0899766053019944},
  issn     = {0899-7667 (Print) 0899-7667 (Linking)},
  number   = {3},
  pages    = {671--90},
  volume   = {17},
  abstract = {Inner-product operators, often referred to as kernels in statistical learning, define a mapping from some input space into a feature space. The focus of this letter is the construction of biologically motivated kernels for cortical activities. The kernels we derive, termed Spikernels, map spike count sequences into an abstract vector space in which we can perform various prediction tasks. We discuss in detail the derivation of Spikernels and describe an efficient algorithm for computing their value on any two sequences of neural population spike counts. We demonstrate the merits of our modeling approach by comparing the Spikernel to various standard kernels in the task of predicting hand movement velocities from cortical recordings. All of the kernels that we tested in our experiments outperform the standard scalar product used in linear regression, with the Spikernel consistently achieving the best performance.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/nda_kernelMethods/shpigelman2005spi.pdf},
  journal  = {Neural Comput},
  keywords = {*Models; Neurological,Action Potentials/*physiology,Algorithms,Animals,Arm/*physiology,Macaca mulatta,Motor Cortex/*physiology,Movement/*physiology,Psychomotor Performance/physiology,Regression (Psychology),Time Factors},
  month    = mar,
  year     = {2005},
}

@Article{breakspearDynamicModelsLargescale2017,
  author     = {Breakspear, M.},
  title      = {Dynamic Models of Large-Scale Brain Activity},
  doi        = {10.1038/nn.4497},
  issn       = {1546-1726 (Electronic) 1097-6256 (Linking)},
  language   = {en},
  number     = {3},
  pages      = {340--352},
  volume     = {20},
  abstract   = {Movement, cognition and perception arise from the collective activity of neurons within cortical circuits and across large-scale systems of the brain. While the causes of single neuron spikes have been understood for decades, the processes that support collective neural behavior in large-scale cortical systems are less clear and have been at times the subject of contention. Modeling large-scale brain activity with nonlinear dynamical systems theory allows the integration of experimental data from multiple modalities into a common framework that facilitates prediction, testing and possible refutation. This work reviews the core assumptions that underlie this computational approach, the methodological framework that fosters the translation of theory into the laboratory, and the emerging body of supporting evidence. While substantial challenges remain, evidence supports the view that collective, nonlinear dynamics are central to adaptive cortical activity. Likewise, aberrant dynamic processes appear to underlie a number of brain disorders.},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/brain/breakspear2017dyn.pdf},
  journal    = {Nat Neurosci},
  keywords   = {Dynamical systems; Computational models,r15,read,review},
  month      = feb,
  readstatus = {read},
  year       = {2017},
}

@Article{womelsdorfModulationNeuronalInteractions2007a,
  author   = {Womelsdorf, T. and Schoffelen, J. M. and Oostenveld, R. and Singer, W. and Desimone, R. and Engel, A. K. and Fries, P.},
  title    = {Modulation of Neuronal Interactions through Neuronal Synchronization},
  doi      = {10.1126/science.1139597},
  issn     = {1095-9203 (Electronic) 0036-8075 (Linking)},
  language = {eng},
  pages    = {1609--12},
  volume   = {316},
  abstract = {Brain processing depends on the interactions between neuronal groups. Those interactions are governed by the pattern of anatomical connections and by yet unknown mechanisms that modulate the effective strength of a given connection. We found that the mutual influence among neuronal groups depends on the phase relation between rhythmic activities within the groups. Phase relations supporting interactions between the groups preceded those interactions by a few milliseconds, consistent with a mechanistic role. These effects were specific in time, frequency, and space, and we therefore propose that the pattern of synchronization flexibly determines the pattern of neuronal interactions.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neuroprinciples/womelsdorf2007mod.pdf},
  journal  = {Science},
  keywords = {Action Potentials,Animals,Cats,Electrodes; Implanted,Electrophysiology,Macaca nemestrina,Male,Nerve Net/physiology,Neurons/*physiology,Parietal Lobe/anatomy \& histology/*physiology,Temporal Lobe/anatomy \& histology/*physiology,Visual Pathways princNeuro},
  month    = jun,
  year     = {2007},
}

@Article{balduzziQualiaGeometryIntegrated2009b,
  author   = {Balduzzi, D. and Tononi, G.},
  title    = {Qualia: The Geometry of Integrated Information},
  doi      = {10.1371/journal.pcbi.1000462},
  issn     = {1553-7358 (Electronic) 1553-734X (Linking)},
  number   = {8},
  pages    = {e1000462},
  volume   = {5},
  abstract = {According to the integrated information theory, the quantity of consciousness is the amount of integrated information generated by a complex of elements, and the quality of experience is specified by the informational relationships it generates. This paper outlines a framework for characterizing the informational relationships generated by such systems. Qualia space (Q) is a space having an axis for each possible state (activity pattern) of a complex. Within Q, each submechanism specifies a point corresponding to a repertoire of system states. Arrows between repertoires in Q define informational relationships. Together, these arrows specify a quale -- a shape that completely and univocally characterizes the quality of a conscious experience. Phi -- the height of this shape -- is the quantity of consciousness associated with the experience. Entanglement measures how irreducible informational relationships are to their component relationships, specifying concepts and modes. Several corollaries follow from these premises. The quale is determined by both the mechanism and state of the system. Thus, two different systems having identical activity patterns may generate different qualia. Conversely, the same quale may be generated by two systems that differ in both activity and connectivity. Both active and inactive elements specify a quale, but elements that are inactivated do not. Also, the activation of an element affects experience by changing the shape of the quale. The subdivision of experience into modalities and submodalities corresponds to subshapes in Q. In principle, different aspects of experience may be classified as different shapes in Q, and the similarity between experiences reduces to similarities between shapes. Finally, specific qualities, such as the "redness" of red, while generated by a local mechanism, cannot be reduced to it, but require considering the entire quale. Ultimately, the present framework may offer a principled way for translating qualitative properties of experience into mathematics.},
  file     = {/Users/ssafavi/Documents/libraries/EndnoteLib_fromWin407/EndnoteLib_MPIPClocal_20170723.Data/PDF/2343571883/Balduzzi-2009.pdf},
  journal  = {PLoS Comput Biol},
  keywords = {*Artificial Intelligence,*Information Theory,*Models; Theoretical princNeuro,Algorithms,Computational Biology/*methods,Consciousness,Databases; Factual},
  month    = aug,
  year     = {2009},
}
% == BibTeX quality report for maassRealTimeComputingStable2002:
% ? Title looks like it was stored in title-case in Zotero

@Article{maassSearchingPrinciplesBrain2016,
  author     = {Maass, W.},
  title      = {Searching for Principles of Brain Computation},
  doi        = {10.1016/j.cobeha.2016.06.003},
  issn       = {2352-1546},
  language   = {English},
  pages      = {81--92},
  volume     = {11},
  abstract   = {Experimental methods in neuroscience, such as calcium-imaging and recordings with multi-electrode arrays, are advancing at a rapid pace. They produce insight into the simultaneous activity of large numbers of neurons, and into plasticity processes in the brains of awake and behaving animals. These new data constrain models for neural computation and network plasticity that underlie perception, cognition, behavior, and learning. I will discuss in this short article four such constraints: inherent recurrent network activity and heterogeneous dynamic properties of neurons and synapses, stereotypical spatio-temporal activity patterns in networks of neurons, high trial-to-trial variability of network responses, and functional stability in spite of permanently ongoing changes in the network. I am proposing that these constraints provide hints to underlying principles of brain computation and learning.},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neuroprinciples/computation/maass2016sea.pdf},
  journal    = {Current Opinion in Behavioral Sciences},
  keywords   = {behavior,chaotic neural-networks,cortical microcircuit models,dynamics,memory traces,neocortex,prefrontal cortex,read,review,spiking neurons,synapses,synaptic plasticity},
  month      = oct,
  readstatus = {read},
  year       = {2016},
}

@Article{pittorinoChaosCorrelatedAvalanches2017,
  author   = {Pittorino, Fabrizio and {Ib{\'a}{\~n}ez-Berganza}, Miguel and {di Volo}, Matteo and Vezzani, Alessandro and Burioni, Raffaella},
  title    = {Chaos and {{Correlated Avalanches}} in {{Excitatory Neural Networks}} with {{Synaptic Plasticity}}},
  doi      = {10.1103/PhysRevLett.118.098102},
  number   = {9},
  pages    = {098102},
  volume   = {118},
  abstract = {A collective chaotic phase with power law scaling of activity events is observed in a disordered mean field network of purely excitatory leaky integrate-and-fire neurons with short-term synaptic plasticity. The dynamical phase diagram exhibits two transitions from quasisynchronous and asynchronous regimes to the nontrivial, collective, bursty regime with avalanches. In the homogeneous case without disorder, the system synchronizes and the bursty behavior is reflected into a period doubling transition to chaos for a two dimensional discrete map. Numerical simulations show that the bursty chaotic phase with avalanches exhibits a spontaneous emergence of persistent time correlations and enhanced Kolmogorov complexity. Our analysis reveals a mechanism for the generation of irregular avalanches that emerges from the combination of disorder and deterministic underlying chaotic dynamics.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/criticality/pittorino2017cha.pdf},
  journal  = {Physical Review Letters},
  month    = mar,
  year     = {2017},
}
% == BibTeX quality report for mitraNeuralSignalProcessing2008:
% ? Title looks like it was stored in title-case in Zotero

@Book{mitraObservedBrainDynamics2007,
  author    = {Mitra, Partha and Bokil, Hemant},
  title     = {Observed {{Brain Dynamics}}},
  isbn      = {0-19-517808-4},
  publisher = {{Oxford University Press, USA}},
  month     = dec,
  year      = {2007},
}
% == BibTeX quality report for sherfeyDynaSimMATLABToolbox2018:
% ? Title looks like it was stored in title-case in Zotero

@Article{sherfeyFlexibleResonancePrefrontal2018,
  author    = {Sherfey, Jason S. and Ardid, Salva and Hass, Joachim and Hasselmo, Michael E. and Kopell, Nancy J.},
  title     = {Flexible Resonance in Prefrontal Networks with Strong Feedback Inhibition},
  doi       = {10.1371/journal.pcbi.1006357},
  issn      = {1553-7358},
  language  = {en},
  number    = {8},
  pages     = {e1006357},
  volume    = {14},
  abstract  = {Oscillations are ubiquitous features of brain dynamics that undergo task-related changes in synchrony, power, and frequency. The impact of those changes on target networks is poorly understood. In this work, we used a biophysically detailed model of prefrontal cortex (PFC) to explore the effects of varying the spike rate, synchrony, and waveform of strong oscillatory inputs on the behavior of cortical networks driven by them. Interacting populations of excitatory and inhibitory neurons with strong feedback inhibition are inhibition-based network oscillators that exhibit resonance (i.e., larger responses to preferred input frequencies). We quantified network responses in terms of mean firing rates and the population frequency of network oscillation; and characterized their behavior in terms of the natural response to asynchronous input and the resonant response to oscillatory inputs. We show that strong feedback inhibition causes the PFC to generate internal (natural) oscillations in the beta/gamma frequency range ({$>$}15 Hz) and to maximize principal cell spiking in response to external oscillations at slightly higher frequencies. Importantly, we found that the fastest oscillation frequency that can be relayed by the network maximizes local inhibition and is equal to a frequency even higher than that which maximizes the firing rate of excitatory cells; we call this phenomenon population frequency resonance. This form of resonance is shown to determine the optimal driving frequency for suppressing responses to asynchronous activity. Lastly, we demonstrate that the natural and resonant frequencies can be tuned by changes in neuronal excitability, the duration of feedback inhibition, and dynamic properties of the input. Our results predict that PFC networks are tuned for generating and selectively responding to beta- and gamma-rhythmic signals due to the natural and resonant properties of inhibition-based oscillators. They also suggest strategies for optimizing transcranial stimulation and using oscillatory networks in neuromorphic engineering.},
  journal   = {PLOS Computational Biology},
  keywords  = {Action potentials,Computer networks,Network analysis,Neural networks,Prefrontal cortex,Resonance,Resonance frequency,Square waves},
  month     = aug,
  publisher = {{Public Library of Science}},
  year      = {2018},
}

@Article{olbrichSleepingBrainComplex2011b,
  author    = {Olbrich, Eckehard and Achermann, Peter and Wennekers, Thomas},
  title     = {The Sleeping Brain as a Complex System},
  doi       = {10.1098/rsta.2011.0199},
  number    = {1952},
  pages     = {3697--3707},
  volume    = {369},
  abstract  = {`Complexity science' is a rapidly developing research direction with applications in a multitude of fields that study complex systems consisting of a number of nonlinear elements with interesting dynamics and mutual interactions. This Theme Issue `The complexity of sleep' aims at fostering the application of complexity science to sleep research, because the brain in its different sleep stages adopts different global states that express distinct activity patterns in large and complex networks of neural circuits. This introduction discusses the contributions collected in the present Theme Issue. We highlight the potential and challenges of a complex systems approach to develop an understanding of the brain in general and the sleeping brain in particular. Basically, we focus on two topics: the complex networks approach to understand the changes in the functional connectivity of the brain during sleep, and the complex dynamics of sleep, including sleep regulation. We hope that this Theme Issue will stimulate and intensify the interdisciplinary communication to advance our understanding of the complex dynamics of the brain that underlies sleep and consciousness.},
  file      = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/brain/olbrich2011the2.pdf},
  journal   = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  month     = oct,
  publisher = {{Royal Society}},
  year      = {2011},
}

@Article{betzelMultiscaleBrainNetworks2017,
  author     = {Betzel, Richard F. and Bassett, Danielle S.},
  title      = {Multi-Scale Brain Networks},
  doi        = {10.1016/j.neuroimage.2016.11.006},
  issn       = {1053-8119},
  language   = {en},
  pages      = {73--83},
  series     = {Functional {{Architecture}} of the {{Brain}}},
  volume     = {160},
  abstract   = {The network architecture of the human brain has become a feature of increasing interest to the neuroscientific community, largely because of its potential to illuminate human cognition, its variation over development and aging, and its alteration in disease or injury. Traditional tools and approaches to study this architecture have largely focused on single scales\textemdash of topology, time, and space. Expanding beyond this narrow view, we focus this review on pertinent questions and novel methodological advances for the multi-scale brain. We separate our exposition into content related to multi-scale topological structure, multi-scale temporal structure, and multi-scale spatial structure. In each case, we recount empirical evidence for such structures, survey network-based methodological approaches to reveal these structures, and outline current frontiers and open questions. Although predominantly peppered with examples from human neuroimaging, we hope that this account will offer an accessible guide to any neuroscientist aiming to measure, characterize, and understand the full richness of the brain's multiscale network structure\textemdash irrespective of species, imaging modality, or spatial resolution.},
  journal    = {NeuroImage},
  keywords   = {Brain networks,Complex networks,Graph theory,Multi-layer,Multi-resolution,Multi-scale,Network neuroscience,read},
  month      = oct,
  readstatus = {read},
  year       = {2017},
}

@Article{wangHierarchicalConnectomeModes2019,
  author     = {Wang, Rong and Lin, Pan and Liu, Mianxin and Wu, Ying and Zhou, Tao and Zhou, Changsong},
  title      = {Hierarchical {{Connectome Modes}} and {{Critical State Jointly Maximize Human Brain Functional Diversity}}},
  doi        = {10.1103/PhysRevLett.123.038301},
  number     = {3},
  pages      = {038301},
  volume     = {123},
  abstract   = {The brain requires diverse segregated and integrated processing to perform normal functions in terms of anatomical structure and self-organized dynamics with critical features, but the fundamental relationships between the complex structural connectome, critical state, and functional diversity remain unknown. Herein, we extend the eigenmode analysis to investigate the joint contribution of hierarchical modular structural organization and critical state to brain functional diversity. We show that the structural modes inherent to the hierarchical modular structural connectome allow a nested functional segregation and integration across multiple spatiotemporal scales. The real brain hierarchical modular organization provides large structural capacity for diverse functional interactions, which are generated by sequentially activating and recruiting the hierarchical connectome modes, and the critical state can best explore the capacity to maximize the functional diversity. Our results reveal structural and dynamical mechanisms that jointly support a balanced segregated and integrated brain processing with diverse functional interactions, and they also shed light on dysfunctional segregation and integration in neurodegenerative diseases and neuropsychiatric disorders.},
  journal    = {Physical Review Letters},
  keywords   = {read},
  month      = jul,
  publisher  = {{American Physical Society}},
  readstatus = {read},
  year       = {2019},
}

@Book{khandakerNeuroinflammationSchizophrenia2020,
  author     = {Khandaker, Golam M and Meyer, Urs and Jones, Peter B},
  title      = {Neuroinflammation and Schizophrenia},
  isbn       = {978-3-030-39140-9},
  language   = {English},
  annotation = {OCLC: 1130902195},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/books/khandaker2020neu.epub;/home/ssafavi/Nextcloud/libraries/zoteroLib/books/khandaker2020neu.pdf},
  year       = {2020},
}

@Article{theodoniCorticalMicrocircuitDynamics2011a,
  author   = {Theodoni, P. and Panagiotaropoulos, T. I. and Kapoor, V. and Logothetis, N. K. and Deco, G.},
  title    = {Cortical Microcircuit Dynamics Mediating Binocular Rivalry: The Role of Adaptation in Inhibition},
  doi      = {10.3389/fnhum.2011.00145},
  issn     = {1662-5161 (Electronic) 1662-5161 (Linking)},
  language = {English},
  pages    = {145},
  volume   = {5},
  abstract = {Perceptual bistability arises when two conflicting interpretations of an ambiguous stimulus or images in binocular rivalry (BR) compete for perceptual dominance. From a computational point of view, competition models based on cross-inhibition and adaptation have shown that noise is a crucial force for rivalry, and operates in balance with adaptation. In particular, noise-driven transitions and adaptation-driven oscillations define two dynamical regimes and the system explains the observed alternations in perception when it operates near their boundary. In order to gain insights into the microcircuit dynamics mediating spontaneous perceptual alternations, we used a reduced recurrent attractor-based biophysically realistic spiking network, well known for working memory, attention, and decision making, where a spike-frequency adaptation mechanism is implemented to account for perceptual bistability. We thus derived a consistently reduced four-variable population rate model using mean-field techniques, and we tested it on BR data collected from human subjects. Our model accounts for experimental data parameters such as mean time dominance, coefficient of variation, and gamma distribution fit. In addition, we show that our model operates near the bifurcation that separates the noise-driven transitions regime from the adaptation-driven oscillations regime, and agrees with Levelt's second revised and fourth propositions. These results demonstrate for the first time that a consistent reduction of a biophysically realistic spiking network of leaky integrate-and-fire neurons with spike-frequency adaptation could account for BR. Moreover, we demonstrate that BR can be explained only through the dynamics of competing neuronal pools, without taking into account the adaptation of inhibitory interneurons. However, the adaptation of interneurons affects the optimal parametric space of the system by decreasing the overall adaptation necessary for the bifurcation to occur, and introduces oscillations in the spontaneous state.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/perception/multiStablePerception_msp/models/theodoni2011cor.pdf},
  journal  = {Front Hum Neurosci},
  keywords = {ambiguous patterns,binocular rivalry,computational modeling,decision-making,local circuit neurons,mean-field,network model,neuronal competition models,noise,perceptual bistability,prefrontal cortex,spike-frequency adaptation,spiking networks,spiking neurons,working-memory},
  month    = nov,
  year     = {2011},
}

@Article{zeitlerAssessingNeuronalCoherence2006,
  author   = {Zeitler, M. and Fries, P. and Gielen, S.},
  title    = {Assessing Neuronal Coherence with Single-Unit, Multi-Unit, and Local Field Potentials},
  doi      = {10.1162/neco.2006.18.9.2256},
  issn     = {0899-7667 (Print) 0899-7667 (Linking)},
  pages    = {2256--81},
  volume   = {18},
  abstract = {The purpose of this study was to obtain a better understanding of neuronal responses to correlated input, in particular focusing on the aspect of synchronization of neuronal activity. The first aim was to obtain an analytical expression for the coherence between the output spike train and correlated input and for the coherence between output spike trains of neurons with correlated input. For Poisson neurons, we could derive that the peak of the coherence between the correlated input and multi-unit activity increases proportionally with the square root of the number of neurons in the multi-unit recording. The coherence between two typical multi-unit recordings (2 to 10 single units) with partially correlated input increases proportionally with the number of units in the multi-unit recordings. The second aim of this study was to investigate to what extent the amplitude and signal-to-noise ratio of the coherence between input and output varied for single-unit versus multi-unit activity and how they are affected by the duration of the recording. The same problem was addressed for the coherence between two single-unit spike series and between two multi-unit spike series. The analytical results for the Poisson neuron and numerical simulations for the conductance-based leaky integrate-and-fire neuron and for the conductance-based Hodgkin-Huxley neuron show that the expectation value of the coherence function does not increase for a longer duration of the recording. The only effect of a longer duration of the spike recording is a reduction of the noise in the coherence function. The results of analytical derivations and computer simulations for model neurons show that the coherence for multi-unit activity is larger than that for single-unit activity. This is in agreement with the results of experimental data obtained from monkey visual cortex (V4). Finally, we show that multitaper techniques greatly contribute to a more accurate estimate of the coherence by reducing the bias and variance in the coherence estimate.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/unfiled/zeitler2006ass.pdf},
  journal  = {Neural Comput},
  keywords = {*Models; Neurological,Action Potentials/*physiology,Animals,Macaca mulatta,Male,Neurons/*physiology,Photic Stimulation/methods,Poisson Distribution,Visual Cortex/physiology},
  month    = sep,
  year     = {2006},
}

@Article{safaviNonmonotonicSpatialStructure2018,
  author    = {Safavi, Shervin and Dwarakanath, Abhilash and Kapoor, Vishal and Werner, Joachim and Hatsopoulos, Nicholas G. and Logothetis, Nikos K. and Panagiotaropoulos, Theofanis I.},
  title     = {Nonmonotonic Spatial Structure of Interneuronal Correlations in Prefrontal Microcircuits},
  doi       = {10.1073/pnas.1802356115},
  issn      = {0027-8424, 1091-6490},
  language  = {en},
  pages     = {201802356},
  abstract  = {Correlated fluctuations of single neuron discharges, on a mesoscopic scale, decrease as a function of lateral distance in early sensory cortices, reflecting a rapid spatial decay of lateral connection probability and excitation. However, spatial periodicities in horizontal connectivity and associational input as well as an enhanced probability of lateral excitatory connections in the association cortex could theoretically result in nonmonotonic correlation structures. Here, we show such a spatially nonmonotonic correlation structure, characterized by significantly positive long-range correlations, in the inferior convexity of the macaque prefrontal cortex. This functional connectivity kernel was more pronounced during wakefulness than anesthesia and could be largely attributed to the spatial pattern of correlated variability between functionally similar neurons during structured visual stimulation. These results suggest that the spatial decay of lateral functional connectivity is not a common organizational principle of neocortical microcircuits. A nonmonotonic correlation structure could reflect a critical topological feature of prefrontal microcircuits, facilitating their role in integrative processes.},
  copyright = {Copyright \textcopyright{} 2018 the Author(s). Published by PNAS.. This open access article is distributed under Creative Commons Attribution-NonCommercial-NoDerivatives License 4.0 (CC BY-NC-ND).},
  file      = {/home/ssafavi/Nextcloud/libraries/zoteroLib/safavi2018non.pdf},
  journal   = {Proceedings of the National Academy of Sciences},
  keywords  = {functional connectivity,long-range interactions,network structure,noise correlations,prefrontal cortex},
  month     = mar,
  year      = {2018},
}
% == BibTeX quality report for beggsBeingCriticalCriticality2012:
% ? Title looks like it was stored in title-case in Zotero

@Article{beggsCriticalityHypothesisHow2008,
  author   = {Beggs, J. M.},
  title    = {The Criticality Hypothesis: How Local Cortical Networks Might Optimize Information Processing},
  doi      = {DOI 10.1098/rsta.2007.2092},
  issn     = {1364-503X},
  language = {English},
  pages    = {329--343},
  volume   = {366},
  abstract = {Early theoretical and simulation work independently undertaken by Packard, Langton and Kauffman suggested that adaptability and computational power would be optimized in systems at the 'edge of chaos', at a critical point in a phase transition between total randomness and boring order. This provocative hypothesis has received much attention, but biological experiments supporting it have been relatively few. Here, we review recent experiments on networks of cortical neurons, showing that they appear to be operating near the critical point. Simulation studies capture the main features of these data and suggest that criticality may allow cortical networks to optimize information processing. These simulations lead to predictions that could be tested in the near future, possibly providing further experimental evidence for the criticality hypothesis.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/criticality/beggs2008the.pdf},
  journal  = {Philosophical Transactions of the Royal Society a-Mathematical Physical and Engineering Sciences},
  keywords = {avalanche,chaos,computation,cortex,criticality,cultured neurons,dynamics,edge,edge of chaos,neural network,neuronal avalanches,oscillations,power law,propagation,self-organized criticality,slice cultures},
  month    = feb,
  year     = {2008},
}
% == BibTeX quality report for rosenbaumEffectsPoolingSpike2011:
% ? Title looks like it was stored in title-case in Zotero

@Article{rosenbaumSpatialStructureCorrelated2017,
  author   = {Rosenbaum, R. and Smith, M. A. and Kohn, A. and Rubin, J. E. and Doiron, B.},
  title    = {The Spatial Structure of Correlated Neuronal Variability},
  doi      = {10.1038/nn.4433},
  issn     = {1546-1726 (Electronic) 1097-6256 (Linking)},
  language = {en},
  pages    = {107--114},
  volume   = {20},
  abstract = {Shared neural variability is ubiquitous in cortical populations. While this variability is presumed to arise from overlapping synaptic input, its precise relationship to local circuit architecture remains unclear. We combine computational models and in vivo recordings to study the relationship between the spatial structure of connectivity and correlated variability in neural circuits. Extending the theory of networks with balanced excitation and inhibition, we find that spatially localized lateral projections promote weakly correlated spiking, but broader lateral projections produce a distinctive spatial correlation structure: nearby neuron pairs are positively correlated, pairs at intermediate distances are negatively correlated and distant pairs are weakly correlated. This non-monotonic dependence of correlation on distance is revealed in a new analysis of recordings from superficial layers of macaque primary visual cortex. Our findings show that incorporating distance-dependent connectivity improves the extent to which balanced network theory can explain correlated neural variability.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/unfiled/rosenbaum2017the.pdf;/home/ssafavi/Zotero/storage/775QC63Q/Rosenbaum-20161.pdf;/home/ssafavi/Zotero/storage/7D4BJ6IJ/Rosenbaum-20162.pdf;/home/ssafavi/Zotero/storage/CSTEH7TV/nn.4433-S3.zip},
  journal  = {Nat Neurosci},
  keywords = {Neural circuits; Network models},
  month    = jan,
  pmcid    = {PMC5191923},
  year     = {2017},
}
% == BibTeX quality report for deglerisProvablyCorrectRobust2019:
% ? Possibly abbreviated journal title arXiv:1906.06899 [cs, math, stat]
% ? Title looks like it was stored in title-case in Zotero

@Article{degraafCorrelatesNeuralCorrelates2012,
  author   = {{de Graaf}, Tom A. and Hsieh, Po-Jang and Sack, Alexander T.},
  title    = {The 'correlates' in Neural Correlates of Consciousness},
  doi      = {10.1016/j.neubiorev.2011.05.012},
  issn     = {1873-7528},
  language = {eng},
  number   = {1},
  pages    = {191--197},
  volume   = {36},
  abstract = {In the search for neural correlates of consciousness (NCC), the concept of 'consciousness' remains problematic. We suggest that not only the 'consciousness' in neural correlates of consciousness is a confused term, but 'correlates' is as well. When brain events are found to covary with conscious experience, these brain events can be the neural substrates of the experience, as is often (implicitly) suggested, but they can also be neural prerequisites or neural consequences of the experience. We here disentangle these different sorts of brain processes conceptually. But we also propose a concrete multi-pronged research program that may, in near-future consciousness research, distinguish these brain processes empirically.},
  journal  = {Neuroscience and Biobehavioral Reviews},
  keywords = {Brain,Brain Mapping,Cognition,Consciousness,Humans,Neurons,Statistics as Topic},
  month    = jan,
  pmid     = {21651927},
  year     = {2012},
}
% == BibTeX quality report for browningRealizingClinicalPotential2019:
% Missing required field 'journal'
% ? Title looks like it was stored in title-case in Zotero

@TechReport{brownleeComplexAdaptiveSystems2007,
  author   = {Brownlee, Jason},
  title    = {Complex {{Adaptive Systems}}},
  number   = {070302A},
  abstract = {Abstract- The field of Complex Adaptive Systems (CAS) is approximately 20 years old, having been established by physicists, economists, and others studying complexity at the Santa Fe Institute in New Mexico, USA. The field has spawned much work, such as Holland's contributions of genetic algorithms, classifier systems, and his ecosystem simulator, which assisted in provoking the fields of evolutionary computation and artificial life. The framework of inducted principles derived from many natural and artificial examples of complex systems has assisted in the investigation in such diverse fields of study as psychology, anthropology, genetic evolution, ecology, and business management theory, although a unified theory of such complex systems still appears to be a long way off. This work reviews the principles of complex adaptive systems as a framework, providing a number of interpretations from eminent researches in the field. Many example works are cited, and the theory is used to phrase some ambiguus work in the field of artificial immune systems and artificial life. The methodology of using simulations of CAS as the starting point for models in the field of biological inspired computation is postulated as an important contribution of CAS to that field. Keywords- Complex Adaptive Systems, CSA, General Principles I.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/cas_ComplexAdaptiveSystems/brownlee2007com.pdf},
  year     = {2007},
}
% == BibTeX quality report for prokopenkoComplexityCriticalityComputation2018:
% ? Title looks like it was stored in title-case in Zotero

@Article{prokopenkoRelatingFisherInformation2011,
  author   = {Prokopenko, Mikhail and Lizier, Joseph T. and Obst, Oliver and Wang, X. Rosalind},
  title    = {Relating {{Fisher}} Information to Order Parameters},
  doi      = {10.1103/PhysRevE.84.041116},
  number   = {4},
  pages    = {041116},
  volume   = {84},
  abstract = {We study phase transitions and relevant order parameters via statistical estimation theory using the Fisher information matrix. The assumptions that we make limit our analysis to order parameters representable as a negative derivative of thermodynamic potential over some thermodynamic variable. Nevertheless, the resulting representation is sufficiently general and explicitly relates elements of the Fisher information matrix to the rate of change in the corresponding order parameters. The obtained relationships allow us to identify, in particular, second-order phase transitions via divergences of individual elements of the Fisher information matrix. A computational study of random Boolean networks supports the derived relationships, illustrating that Fisher information of the magnetization bias (that is, activity level) is peaked in finite-size networks at the critical points, and the maxima increase with the network size. The framework presented here reveals the basic thermodynamic reasons behind similar empirical observations reported previously. The study highlights the generality of Fisher information as a measure that can be applied to a broad range of systems, particularly those where the determination of order parameters is cumbersome.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/prokopenko2011rel.pdf},
  journal  = {Physical Review E},
  month    = oct,
  year     = {2011},
}

@Article{kandersAvalancheEdgeofchaosCriticality2017,
  author     = {Kanders, Karlis and Lorimer, Tom and Stoop, Ruedi},
  title      = {Avalanche and Edge-of-Chaos Criticality Do Not Necessarily Co-Occur in Neural Networks},
  doi        = {10.1063/1.4978998},
  issn       = {1054-1500},
  number     = {4},
  pages      = {047408},
  volume     = {27},
  abstract   = {There are indications that for optimizing neural computation, neural networks may operate at           criticality. Previous approaches have used distinct fingerprints of criticality, leaving           open the question whether the different notions would necessarily reflect different           aspects of one and the same instance of criticality, or whether they could potentially           refer to distinct instances of criticality. In this work, we choose avalanche criticality and           edge-of-chaos criticality and demonstrate for a recurrent spiking neural network that             avalanche           criticality does not necessarily entrain dynamical edge-of-chaos criticality. This           suggests that the different fingerprints may pertain to distinct phenomena.},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/criticality/kanders2017ava.pdf},
  journal    = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
  keywords   = {r3,read},
  month      = apr,
  readstatus = {read},
  year       = {2017},
}

@Article{breakspearGenerativeModelsCortical2010,
  author     = {Breakspear, Michael and Heitmann, Stewart and Daffertshofer, Andreas},
  title      = {Generative {{Models}} of {{Cortical Oscillations}}: {{Neurobiological Implications}} of the {{Kuramoto Model}}},
  doi        = {10.3389/fnhum.2010.00190},
  issn       = {1662-5161},
  language   = {English},
  volume     = {4},
  abstract   = {Understanding the fundamental mechanisms governing fluctuating oscilla- tions in large-scale cortical circuits is a crucial prelude to a proper knowl- edge of their role in both adaptive and pathological cortical processes. Neu- roscience research in this area has much to gain from understanding the Kuromoto model, a mathematical model that speaks to the very nature of coupled oscillating processes, and which has elucidated the core mechanisms of a range of biological and physical phenomena. In this paper, we provide a brief introduction to the Kuromoto model in its original, rather abstract, form and then focus on modifications that increase its neurobiological plau- sibility by incorporating topological properties of local cortical connectivity. The extended model elicits elaborate spatial patterns of synchronous oscil- lations that exhibit persistent dynamical instabilities reminiscent of cortical activity. We review how the Kuramoto model may be recast from an ordi- nary differential equation to a population level description using the nonlin- ear Fokker-Planck equation. We argue that such formulations are able to provide a mechanistic and unifying explanation of oscillatory phenomena in the human cortex, such as fluctuating beta oscillations, and their relation- ship to basic computational processes including multistability, criticality and information capacity.},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/criticality/breakspear2010gen.pdf},
  journal    = {Frontiers in Human Neuroscience},
  keywords   = {Computational models,cortical oscillations,Human Beta rhythm,Kuramoto model,Nonlinear Fokker Planck},
  publisher  = {{Frontiers}},
  shorttitle = {Generative {{Models}} of {{Cortical Oscillations}}},
  year       = {2010},
}

@Article{khandakerInflammationImmunitySchizophrenia2015,
  author     = {Khandaker, Golam M and Cousins, Lesley and Deakin, Julia and Lennox, Belinda R and Yolken, Robert and Jones, Peter B},
  title      = {Inflammation and Immunity in Schizophrenia: Implications for Pathophysiology and Treatment},
  doi        = {10.1016/S2215-0366(14)00122-9},
  issn       = {2215-0366},
  language   = {en},
  number     = {3},
  pages      = {258--270},
  volume     = {2},
  abstract   = {Complex interactions between the immune system and the brain might have important aetiological and therapeutic implications for neuropsychiatric brain disorders. A possible association between schizophrenia and the immune system was postulated over a century ago, and is supported by epidemiological and genetic studies pointing to links with infection and inflammation. Contrary to the traditional view that the brain is an immunologically privileged site shielded behind the blood\textendash brain barrier, studies in the past 20 years have noted complex interactions between the immune system, systemic inflammation, and the brain, which can lead to changes in mood, cognition, and behaviour. In this Review, we describe some of the important areas of research regarding innate and adaptive immune response in schizophrenia and related psychotic disorders that, we think, will be of interest to psychiatric clinicians and researchers. We discuss potential mechanisms and therapeutic implications of these findings, including studies of anti-inflammatory drugs in schizophrenia, describe areas for development, and offer testable hypotheses for future investigations.},
  journal    = {The Lancet Psychiatry},
  keywords   = {read,review},
  month      = mar,
  readstatus = {read},
  shorttitle = {Inflammation and Immunity in Schizophrenia},
  year       = {2015},
}

@Article{vandenheuvelSpotlightBridgingMicroscale2017,
  author     = {{van den Heuvel}, Martijn P. and Yeo, B. T. Thomas},
  title      = {A {{Spotlight}} on {{Bridging Microscale}} and {{Macroscale Human Brain Architecture}}},
  doi        = {10.1016/j.neuron.2017.02.048},
  issn       = {0896-6273},
  number     = {6},
  pages      = {1248--1251},
  volume     = {93},
  abstract   = {We place a spotlight on the emerging trend of jointly studying the micro- and macroscale organization of nervous systems. We discuss the pioneering studies of Ding et~al. (2016) and Glasser et~al. (2016) in the context of growing efforts to combine and integrate multiple features of brain organization into a multi-modal and multi-scale examination of the human brain.},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neuroprinciples/unifying/van_den_heuvel2017a.pdf;/home/ssafavi/Zotero/storage/7EZCHHYN/van den Heuvel and Yeo - 2017 - A Spotlight on Bridging Microscale and Macroscale .pdf},
  journal    = {Neuron},
  keywords   = {brain atlas,brain network,connectivity,connectome,diffusion MRI,functional MRI,histology,MRI,multimodal,multiscale,read},
  month      = mar,
  readstatus = {read},
  year       = {2017},
}
% == BibTeX quality report for mastrogiuseppeGeometricalAnalysisGlobal2019:
% ? Title looks like it was stored in title-case in Zotero

@Article{mastrogiuseppeLinkingConnectivityDynamics2018,
  author   = {Mastrogiuseppe, Francesca and Ostojic, Srdjan},
  title    = {Linking {{Connectivity}}, {{Dynamics}}, and {{Computations}} in {{Low}}-{{Rank Recurrent Neural Networks}}},
  doi      = {10.1016/j.neuron.2018.07.003},
  issn     = {0896-6273},
  language = {English},
  number   = {3},
  pages    = {609-623.e29},
  volume   = {99},
  abstract = {{$<$}h2{$>$}Summary{$<$}/h2{$><$}p{$>$}Large-scale neural recordings have established that the transformation of sensory stimuli into motor outputs relies on low-dimensional dynamics at the population level, while individual neurons exhibit complex selectivity. Understanding how low-dimensional computations on mixed, distributed representations emerge from the structure of the recurrent connectivity and inputs to cortical networks is a major challenge. Here, we study a class of recurrent network models in which the connectivity is a sum of a random part and a minimal, low-dimensional structure. We show that, in such networks, the dynamics are low dimensional and can be directly inferred from connectivity using a geometrical approach. We exploit this understanding to determine minimal connectivity required to implement specific computations and find that the dynamical range and computational capacity quickly increase with the dimensionality of the connectivity structure. This framework produces testable experimental predictions for the relationship between connectivity, low-dimensional dynamics, and computational features of recorded neurons.{$<$}/p{$>$}},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/DynamicCoding/mastrogiuseppe2018lin.pdf},
  journal  = {Neuron},
  month    = aug,
  pmid     = {30057201},
  year     = {2018},
}

@Article{parkKernelMethodsSpike2013a,
  author  = {Park, Il Memming and Seth, Sohan and Paiva, Antonio R. C. and Li, Lin and Principe, Jose C.},
  title   = {Kernel Methods on Spike Train Space for Neuroscience: A Tutorial},
  file    = {/home/ssafavi/Nextcloud/libraries/zoteroLib/dataAnalysis/nerualDataAnalysis_nda/park2013ker.pdf;/home/ssafavi/Nextcloud/libraries/zoteroLib/dataAnalysis/nerualDataAnalysis_nda/park2013ker.pdf},
  journal = {arXiv},
  month   = feb,
  year    = {2013},
}
% == BibTeX quality report for KuramotoModel2020:
% Missing required field 'author'

@InProceedings{kuramotoSelfentrainmentPopulationCoupled1975,
  author    = {Kuramoto, Yoshiki},
  booktitle = {International {{Symposium}} on {{Mathematical Problems}} in {{Theoretical Physics}}},
  title     = {Self-Entrainment of a Population of Coupled Non-Linear Oscillators},
  doi       = {10.1007/BFb0013365},
  editor    = {Araki, Huzihiro},
  isbn      = {978-3-540-37509-8},
  language  = {en},
  pages     = {420--422},
  publisher = {{Springer}},
  series    = {Lecture {{Notes}} in {{Physics}}},
  address   = {{Berlin, Heidelberg}},
  year      = {1975},
}

@Book{harrisTheoryBranchingProcesses1963,
  author    = {Harris, Theodore Edward},
  title     = {The {{Theory}} of {{Branching Processes}}},
  isbn      = {978-3-642-51868-3},
  language  = {en},
  publisher = {{Springer-Verlag}},
  series    = {Grundlehren Der Mathematischen {{Wissenschaften}}},
  abstract  = {It was about ninety years ago that GALTON and WATSON, in treating the problem of the extinction of family names, showed how probability theory could be applied to study the effects of chance on the development of families or populations. They formulated a mathematical model, which was neglected for many years after their original work, but was studied again in isolated papers in the twenties and thirties of this century. During the past fifteen or twenty years, the model and its general\- izations have been treated extensively, for their mathematical interest and as a theoretical basis for studies of populations of such objects as genes, neutrons, or cosmic rays. The generalizations of the GaIton\- Wa,tson model to be studied in this book can appropriately be called branching processes; the term has become common since its use in a more restricted sense in a paper by KOLMOGOROV and DMITRIEV in 1947 (see Chapter II). We may think of a branching process as a mathematical representation of the development of a population whose members reproduce and die, subject to laws of chance. The objects may be of different types, depending on their age, energy, position, or other factors. However, they must not interfere with one another. This assump\- tion, which unifies the mathematical theory, seems justified for some populations of physical particles such as neutrons or cosmic rays, but only under very restricted circumstances for biological populations.},
  address   = {{Berlin Heidelberg}},
  year      = {1963},
}

@Article{ermentroutRelatingNeuralDynamics2007c,
  author    = {Ermentrout, G. Bard and Gal{\'a}n, Roberto F. and Urban, Nathaniel N.},
  title     = {Relating {{Neural Dynamics}} to {{Neural Coding}}},
  doi       = {10.1103/PhysRevLett.99.248103},
  number    = {24},
  pages     = {248103},
  volume    = {99},
  abstract  = {We demonstrate that two key theoretical objects used widely in computational neuroscience, the phase-resetting curve (PRC) from dynamics and the spike triggered average (STA) from statistical analysis, are closely related when neurons fire in a nearly regular manner and the stimulus is sufficiently small. We prove that the STA due to injected noisy current is proportional to the derivative of the PRC. We compare these analytic results with numerical calculations for the Hodgkin-Huxley neuron and we apply the method to neurons in the olfactory bulb of mice. This observation allows us to relate the stimulus-response properties of a neuron to its dynamics, bridging the gap between dynamical and information theoretic approaches to understanding brain computations and facilitating the interpretation of changes in channels and other cellular properties as influencing the representation of stimuli.},
  journal   = {Physical Review Letters},
  month     = dec,
  publisher = {{American Physical Society}},
  year      = {2007},
}

@Book{bar-yamDynamicsComplexSystems2003,
  author    = {{Bar-Yam}, Yaneer},
  title     = {Dynamics of Complex Systems},
  isbn      = {978-0-8133-4121-7},
  publisher = {{Westview Press}},
  series    = {Studies in Nonlinearity},
  address   = {{Boulder, CO}},
  file      = {/home/ssafavi/Nextcloud/libraries/zoteroLib/books/bar-yam2003dyn.pdf},
  keywords  = {Biomathematics,System theory},
  lccn      = {QH323.5 .B358 2003},
  year      = {2003},
}
% == BibTeX quality report for lynnHumanInformationProcessing2019:
% ? Possibly abbreviated journal title arXiv:1906.00926 [physics, q-bio]

@Article{lynnHumanInformationProcessing2020,
  author    = {Lynn, Christopher W. and Papadopoulos, Lia and Kahn, Ari E. and Bassett, Danielle S.},
  title     = {Human Information Processing in Complex Networks},
  doi       = {10.1038/s41567-020-0924-7},
  issn      = {1745-2481},
  language  = {en},
  pages     = {1--9},
  abstract  = {Humans communicate using systems of interconnected stimuli or concepts\textemdash from language and music to literature and science\textemdash yet it remains unclear how, if at all, the structure of these networks supports the communication of information. Although information theory provides tools to quantify the information produced by a system, traditional metrics do not account for the inefficient ways that humans process this information. Here, we develop an analytical framework to study the information generated by a system as perceived by a human observer. We demonstrate experimentally that this perceived information depends critically on a system's network topology. Applying our framework to several real networks, we find that they communicate a large amount of information (having high entropy) and do so efficiently (maintaining low divergence from human expectations). Moreover, we show that such efficient communication arises in networks that are simultaneously heterogeneous, with high-degree hubs, and clustered, with tightly connected modules\textemdash the two defining features of hierarchical organization. Together, these results suggest that many communication networks are constrained by the pressures of information transmission, and that these pressures select for specific structural features.},
  copyright = {2020 The Author(s), under exclusive licence to Springer Nature Limited},
  journal   = {Nature Physics},
  month     = jun,
  publisher = {{Nature Publishing Group}},
  year      = {2020},
}

@Article{kochNeuralCorrelatesConsciousness2016,
  author     = {Koch, Christof and Massimini, Marcello and Boly, Melanie and Tononi, Giulio},
  title      = {Neural Correlates of Consciousness: Progress and Problems},
  doi        = {10.1038/nrn.2016.22},
  issn       = {1471-0048},
  language   = {en},
  number     = {5},
  pages      = {307--321},
  volume     = {17},
  abstract   = {The neuronal correlates of consciousness (NCC) are the minimum neuronal mechanisms jointly sufficient for any one specific conscious experience. It is important to distinguish full NCC (the neural substrate supporting experience in general, irrespective of its specific content), content-specific NCC (the neural substrate supporting a particular content of experience \textemdash{} for example, faces, whether seen, dreamt or imagined) and background conditions (factors that enable consciousness, but do not contribute directly to the content of experience \textemdash{} for example, arousal systems that ensure adequate excitability of the NCC).The no-report paradigm allows the NCC to be distinguished from events or processes \textemdash{} such as selective attention, memory and response preparation \textemdash{} that are associated with, precede or follow conscious experience. In such paradigms, trials with explicit reports are included along with trials without explicit reports, during which indirect physiological measures are used to infer what the participant is perceiving.The best candidates for full and content-specific NCC are located in the posterior cerebral cortex, in a temporo-parietal-occipital hot zone. The content-specific NCC may be any particular subset of neurons within this hot zone that supports specific phenomenological distinctions, such as faces.The two most widely used electrophysiological signatures of consciousness \textemdash{} gamma range oscillations and the P3b event-related potential \textemdash{} can be dissociated from conscious experiences and are more closely correlated with selective attention and novelty, respectively.New electroencephalography- or functional MRI-based variables that measure the extent to which neuronal activity is both differentiated and integrated across the cortical sheet allow the NCC to be identified more precisely. Moreover, a combined transcranial magnetic stimulation\textendash electroencephalography procedure can predict the presence or absence of consciousness in healthy people who are awake, deeply sleeping or under different types of anaesthesia, and in patients with disorders of consciousness, at the single-person level.Extending the NCC derived from studies in people who can speak about the presence and quality of consciousness to patients with severe brain injuries, fetuses and newborn infants, non-mammalian species and intelligent machines is more challenging. For these purposes, it is essential to combine experimental studies to identify the NCC with a theoretical approach that characterizes in a principled manner what consciousness is and what is required of its physical substrate.},
  copyright  = {2016 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  journal    = {Nature Reviews Neuroscience},
  month      = may,
  publisher  = {{Nature Publishing Group}},
  shorttitle = {Neural Correlates of Consciousness},
  year       = {2016},
}

@Article{einevollModellingAnalysisLocal2013,
  author   = {Einevoll, G. T. and Kayser, C. and Logothetis, N. K. and Panzeri, S.},
  title    = {Modelling and Analysis of Local Field Potentials for Studying the Function of Cortical Circuits},
  doi      = {10.1038/nrn3599},
  issn     = {1471-0048 (Electronic) 1471-003X (Linking)},
  language = {en},
  number   = {11},
  pages    = {770--85},
  volume   = {14},
  abstract = {The past decade has witnessed a renewed interest in cortical local field potentials (LFPs) - that is, extracellularly recorded potentials with frequencies of up to approximately 500 Hz. This is due to both the advent of multielectrodes, which has enabled recording of LFPs at tens to hundreds of sites simultaneously, and the insight that LFPs offer a unique window into key integrative synaptic processes in cortical populations. However, owing to its numerous potential neural sources, the LFP is more difficult to interpret than are spikes. Careful mathematical modelling and analysis are needed to take full advantage of the opportunities that this signal offers in understanding signal processing in cortical circuits and, ultimately, the neural basis of perception and cognition.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neurophysiology/lfp/einevoll2013mod.pdf},
  journal  = {Nat Rev Neurosci},
  keywords = {Computational models; Computational neuroscience; Sensory systems; Electrophysiology; Nature Reviews Neuroscience},
  month    = oct,
  year     = {2013},
}

@InCollection{frankLinkingLevelsComputation2015,
  author    = {Frank, Michael J.},
  booktitle = {An {{Introduction}} to {{Model}}-{{Based Cognitive Neuroscience}}},
  title     = {Linking {{Across Levels}} of {{Computation}} in {{Model}}-{{Based Cognitive Neuroscience}}},
  doi       = {10.1007/978-1-4939-2236-9_8},
  editor    = {Forstmann, Birte U. and Wagenmakers, Eric-Jan},
  isbn      = {978-1-4939-2236-9},
  language  = {en},
  pages     = {159--177},
  publisher = {{Springer}},
  abstract  = {Computational approaches to cognitive neuroscience encompass multiple levels of analysis, from detailed biophysical models of neural activity to abstract algorithmic or normative models of cognition, with several levels in between. Despite often strong opinions on the `right' level of modeling, there is no single panacea: attempts to link biological with higher level cognitive processes require a multitude of approaches. Here I argue that these disparate approaches should not be viewed as competitive, nor should they be accessible to only other researchers already endorsing the particular level of modeling. Rather, insights gained from one level of modeling should inform modeling endeavors at the level above and below it. One way to achieve this synergism is to link levels of modeling by quantitatively fitting the behavioral outputs of detailed mechanistic models with higher level descriptions. If the fits are reasonable (e.g., similar to those achieved when applying high level models to human behavior), one can then derive plausible links between mechanism and computation. Model-based cognitive neuroscience approaches can then be employed to manipulate or measure neural function motivated by the candidate mechanisms, and to test whether these are related to high level model parameters. I describe several examples of this approach in the domain of reward-based learning, cognitive control, and decision making and show how neural and algorithmic models have each informed or refined the other.},
  address   = {{New York, NY}},
  keywords  = {Algorithms,Basal ganglia,Computational models,Decision making,Dopamine,Neural networks,Prefrontal cortex,Reinforcement learning},
  year      = {2015},
}

@TechReport{nivPrimacyBehavioralResearch2020,
  author      = {Niv, Yael},
  institution = {{PsyArXiv}},
  title       = {The Primacy of Behavioral Research for Understanding the Brain},
  doi         = {10.31234/osf.io/y8mxe},
  abstract    = {Understanding the brain requires us to answer both what the brain does, and how it does it. Using a series of examples, I make the case that behavior is often more useful than neuroscientific measurements for answering the first question. Moreover, I show that even for ``how'' questions that pertain to neural mechanism, a well-crafted behavioral paradigm can offer deeper insight and stronger constraints on computational and mechanistic models than do many highly challenging (and very expensive) neural studies. I conclude that behavioral, rather than neuroscientific research, is essential for understanding the brain, contrary to the opinion of prominent funding bodies and scientific journals, who erroneously place neural data on a pedestal and consider behavior to be subsidiary.},
  file        = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neuroprinciples/behaviour/niv2020the.pdf},
  keywords    = {Animal Learning and Behavior,behavior,Behavioral Neuroscience,causality,Cognitive Neuroscience,Cognitive Psychology,Computational Neuroscience,neuroscience,Neuroscience,Psychiatry,read,Social and Behavioral Sciences},
  month       = oct,
  readstatus  = {read},
  year        = {2020},
}

@Article{bialekReadingNeuralCode1991,
  author    = {Bialek, W. and Rieke, F. and van Steveninck, RR de Ruyter and Warland, D.},
  title     = {Reading a Neural Code},
  doi       = {10.1126/science.2063199},
  issn      = {0036-8075, 1095-9203},
  language  = {en},
  number    = {5014},
  pages     = {1854--1857},
  volume    = {252},
  abstract  = {Traditional approaches to neural coding characterize the encoding of known stimuli in average neural responses. Organisms face nearly the opposite task--extracting information about an unknown time-dependent stimulus from short segments of a spike train. Here the neural code was characterized from the point of view of the organism, culminating in algorithms for real-time stimulus estimation based on a single example of the spike train. These methods were applied to an identified movement-sensitive neuron in the fly visual system. Such decoding experiments determined the effective noise level and fault tolerance of neural computation, and the structure of the decoding algorithms suggested a simple model for real-time analog signal processing with spiking neurons.},
  chapter   = {Reports},
  copyright = {\textcopyright{} 1991},
  journal   = {Science},
  month     = jun,
  pmid      = {2063199},
  publisher = {{American Association for the Advancement of Science}},
  year      = {1991},
}
% == BibTeX quality report for ellisHierarchyModularityDevelopment2017:
% Missing required field 'author'
% ? Title looks like it was stored in title-case in Zotero

@Book{ellisLanguageComplexAdaptive2009,
  author    = {Ellis, Nick C. and {Larsen-Freeman}, Diane},
  title     = {Language as a {{Complex Adaptive System}}},
  isbn      = {978-1-4443-3400-5},
  language  = {en},
  publisher = {{John Wiley \& Sons}},
  abstract  = {Explores a new approach to studying language as a complex adaptive system, illustrating its commonalities across many areas of language research Brings together a team of leading researchers in linguistics, psychology, and complex systems to discuss the groundbreaking significance of this perspective for their work Illustrates its application across a variety of subfields, including languages usage, language evolution, language structure, and first and second language acquisition  "What a breath of fresh air! As interesting a collection~of papers as you are likely to find on the evolution,~learning, and use of language from the point of~view of both cognitive underpinnings and communicative functions."~ Michael Tomasello, Max Planck Institute for~Evolutionary Anthropology},
  keywords  = {Language Arts \& Disciplines / General,Language Arts \& Disciplines / Linguistics / General},
  month     = dec,
  year      = {2009},
}

@Article{logothetisNeurophysiologicalInvestigationBasis2001,
  author   = {Logothetis, N. K. and Pauls, J. and Augath, M. and Trinath, T. and Oeltermann, A.},
  title    = {Neurophysiological Investigation of the Basis of the {{fMRI}} Signal},
  doi      = {10.1038/35084005},
  issn     = {0028-0836 (Print) 0028-0836 (Linking)},
  pages    = {150--7},
  volume   = {412},
  abstract = {Functional magnetic resonance imaging (fMRI) is widely used to study the operational organization of the human brain, but the exact relationship between the measured fMRI signal and the underlying neural activity is unclear. Here we present simultaneous intracortical recordings of neural signals and fMRI responses. We compared local field potentials (LFPs), single- and multi-unit spiking activity with highly spatio-temporally resolved blood-oxygen-level-dependent (BOLD) fMRI responses from the visual cortex of monkeys. The largest magnitude changes were observed in LFPs, which at recording sites characterized by transient responses were the only signal that significantly correlated with the haemodynamic response. Linear systems analysis on a trial-by-trial basis showed that the impulse response of the neurovascular system is both animal- and site-specific, and that LFPs yield a better estimate of BOLD responses than the multi-unit responses. These findings suggest that the BOLD contrast mechanism reflects the input and intracortical processing of a given area rather than its spiking output.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/multiModal/logothetis2001neu.pdf},
  journal  = {Nature},
  keywords = {*Magnetic Resonance Imaging,Action Potentials,Animals,Contrast Sensitivity,Electrodes,Electrophysiology,Hemodynamics,Macaca mulatta,Neurons/*physiology,Oxygen/blood,Photic Stimulation,Signal Processing; Computer-Assisted,Synaptic Transmission,Visual Cortex/*physiology},
  month    = jul,
  year     = {2001},
}

@Article{panagiotaropoulosSubjectiveVisualPerception2014a,
  author     = {Panagiotaropoulos, Theofanis I. and Kapoor, Vishal and Logothetis, Nikos K.},
  title      = {Subjective Visual Perception: From Local Processing to Emergent Phenomena of Brain Activity},
  doi        = {10.1098/rstb.2013.0534},
  number     = {1641},
  pages      = {20130534},
  volume     = {369},
  abstract   = {The combination of electrophysiological recordings with ambiguous visual stimulation made possible the detection of neurons that represent the content of subjective visual perception and perceptual suppression in multiple cortical and subcortical brain regions. These neuronal populations, commonly referred to as the neural correlates of consciousness, are more likely to be found in the temporal and prefrontal cortices as well as the pulvinar, indicating that the content of perceptual awareness is represented with higher fidelity in higher-order association areas of the cortical and thalamic hierarchy, reflecting the outcome of competitive interactions between conflicting sensory information resolved in earlier stages. However, despite the significant insights into conscious perception gained through monitoring the activities of single neurons and small, local populations, the immense functional complexity of the brain arising from correlations in the activity of its constituent parts suggests that local, microscopic activity could only partially reveal the mechanisms involved in perceptual awareness. Rather, the dynamics of functional connectivity patterns on a mesoscopic and macroscopic level could be critical for conscious perception. Understanding these emergent spatio-temporal patterns could be informative not only for the stability of subjective perception but also for spontaneous perceptual transitions suggested to depend either on the dynamics of antagonistic ensembles or on global intrinsic activity fluctuations that may act upon explicit neural representations of sensory stimuli and induce perceptual reorganization. Here, we review the most recent results from local activity recordings and discuss the potential role of effective, correlated interactions during perceptual awareness.},
  journal    = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  month      = may,
  publisher  = {{Royal Society}},
  shorttitle = {Subjective Visual Perception},
  year       = {2014},
}

@Article{bialekStatisticalMechanicsNatural2012,
  author   = {Bialek, W. and Cavagna, A. and Giardina, I. and Mora, T. and Silvestri, E. and Viale, M. and Walczak, A. M.},
  title    = {Statistical Mechanics for Natural Flocks of Birds},
  doi      = {10.1073/pnas.1118633109},
  issn     = {1091-6490 (Electronic) 0027-8424 (Linking)},
  pages    = {4786--91},
  volume   = {109},
  abstract = {Flocking is a typical example of emergent collective behavior, where interactions between individuals produce collective patterns on the large scale. Here we show how a quantitative microscopic theory for directional ordering in a flock can be derived directly from field data. We construct the minimally structured (maximum entropy) model consistent with experimental correlations in large flocks of starlings. The maximum entropy model shows that local, pairwise interactions between birds are sufficient to correctly predict the propagation of order throughout entire flocks of starlings, with no free parameters. We also find that the number of interacting neighbors is independent of flock density, confirming that interactions are ruled by topological rather than metric distance. Finally, by comparing flocks of different sizes, the model correctly accounts for the observed scale invariance of long-range correlations among the fluctuations in flight direction.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neuroprinciples/bialek2012sta.pdf},
  journal  = {Proc Natl Acad Sci U S A},
  keywords = {*Models; Biological,*Models; Statistical,Animals,Biomechanics,Entropy,Flight; Animal/*physiology,Starlings/*physiology princNeuro},
  month    = mar,
  year     = {2012},
}

@Article{imamogluChangesFunctionalConnectivity2012,
  author   = {Imamoglu, F. and Kahnt, T. and Koch, C. and Haynes, J. D.},
  title    = {Changes in Functional Connectivity Support Conscious Object Recognition},
  doi      = {10.1016/j.neuroimage.2012.07.056},
  issn     = {1095-9572 (Electronic) 1053-8119 (Linking)},
  language = {eng},
  number   = {4},
  pages    = {1909--17},
  volume   = {63},
  abstract = {What are the brain mechanisms that mediate conscious object recognition? To investigate this question, it is essential to distinguish between brain processes that cause conscious recognition of a stimulus from other correlates of its sensory processing. Previous fMRI studies have identified large-scale brain activity ranging from striate to high-level sensory and prefrontal regions associated with conscious visual perception or recognition. However, the possible role of changes in connectivity during conscious perception between these regions has only rarely been studied. Here, we used fMRI and connectivity analyses, together with 120 custom-generated, two-tone, Mooney images to directly assess whether conscious recognition of an object is accompanied by a dynamical change in the functional coupling between extrastriate cortex and prefrontal areas. We compared recognizing an object versus not recognizing it in 19 naive subjects using two different response modalities. We find that connectivity between the extrastriate cortex and the dorsolateral prefrontal cortex (DLPFC) increases when objects are consciously recognized. This interaction was independent of the response modality used to report conscious recognition. Furthermore, computing the difference in Granger causality between recognized and not recognized conditions reveals stronger feedforward connectivity than feedback connectivity when subjects recognized the objects. We suggest that frontal and visual brain regions are part of a functional network that supports conscious object recognition by changes in functional connectivity.},
  file     = {/Users/ssafavi/Documents/libraries/EndnoteLib_fromWin407/EndnoteLib_MPIPClocal_20170723.Data/PDF/0031250999/Imamoglu-2012.pdf},
  journal  = {Neuroimage},
  keywords = {Adult,Causality,Consciousness/*physiology,Female,Humans,Image Processing; Computer-Assisted,keypap,Magnetic Resonance Imaging,Male,Memory/physiology,Neural Pathways/*physiology,Photic Stimulation,Prefrontal Cortex/physiology,Psychomotor Performance/physiology,Reaction Time/physiology,Recognition (Psychology)/*physiology,Visual Cortex/physiology,Visual Perception/physiology,Young Adult},
  month    = dec,
  year     = {2012},
}

@Book{buzsakiRhythmsBrain2011,
  author    = {Buzsaki, Gyorgy},
  title     = {Rhythms of the {{Brain}}},
  isbn      = {0-19-982823-7},
  publisher = {{Oxford University Press}},
  address   = {{New York, USA}},
  month     = jun,
  year      = {2011},
}

@Article{nivReinforcementLearningBrain2009,
  author   = {Niv, Yael},
  title    = {Reinforcement Learning in the Brain},
  doi      = {10.1016/j.jmp.2008.12.005},
  issn     = {0022-2496},
  language = {en},
  number   = {3},
  pages    = {139--154},
  series   = {Special {{Issue}}: {{Dynamic Decision Making}}},
  volume   = {53},
  abstract = {A wealth of research focuses on the decision-making processes that animals and humans employ when selecting actions in the face of reward and punishment. Initially such work stemmed from psychological investigations of conditioned behavior, and explanations of these in terms of computational models. Increasingly, analysis at the computational level has drawn on ideas from reinforcement learning, which provide a normative framework within which decision-making can be analyzed. More recently, the fruits of these extensive lines of research have made contact with investigations into the neural basis of decision making. Converging evidence now links reinforcement learning to specific neural substrates, assigning them precise computational roles. Specifically, electrophysiological recordings in behaving animals and functional imaging of human decision-making have revealed in the brain the existence of a key reinforcement learning signal, the temporal difference reward prediction error. Here, we first introduce the formal reinforcement learning framework. We then review the multiple lines of evidence linking reinforcement learning to the function of dopaminergic neurons in the mammalian midbrain and to more recent data from human imaging experiments. We further extend the discussion to aspects of learning not associated with phasic dopamine signals, such as learning of goal-directed responding that may not be dopamine-dependent, and learning about the vigor (or rate) with which actions should be performed that has been linked to tonic aspects of dopaminergic signaling. We end with a brief discussion of some of the limitations of the reinforcement learning framework, highlighting questions for future research.},
  journal  = {Journal of Mathematical Psychology},
  keywords = {review},
  month    = jun,
  year     = {2009},
}

@Article{magnascoSelftunedCriticalAntiHebbian2009,
  author   = {Magnasco, M. O. and Piro, O. and Cecchi, G. A.},
  title    = {Self-Tuned Critical Anti-{{Hebbian}} Networks},
  issn     = {0031-9007 (Print) 0031-9007 (Linking)},
  pages    = {258102},
  volume   = {102},
  abstract = {It is widely recognized that balancing excitation and inhibition is important in the nervous system. When such a balance is sought by global strategies, few modes remain poised close to instability, and all other modes are strongly stable. Here we present a simple abstract model in which this balance is sought locally by units following "anti-Hebbian" evolution: all degrees of freedom achieve a close balance of excitation and inhibition and become "critical" in the dynamical sense. At long time scales, a complex "breakout" dynamics ensues in which different modes of the system oscillate between prominence and extinction; the model develops various long-tailed statistical behaviors and may become self-organized critical.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/unfiled/magnasco2009sel.pdf},
  journal  = {Phys Rev Lett},
  keywords = {*Models; Neurological,*Neural Networks (Computer),Neurons/*physiology},
  month    = jun,
  year     = {2009},
}

@Article{lengyelMatchingStorageRecall2005,
  author     = {Lengyel, M{\'a}t{\'e} and Kwag, Jeehyun and Paulsen, Ole and Dayan, Peter},
  title      = {Matching Storage and Recall: Hippocampal Spike Timing\textendash Dependent Plasticity and Phase Response Curves},
  doi        = {10.1038/nn1561},
  issn       = {1546-1726},
  language   = {en},
  number     = {12},
  pages      = {1677--1683},
  volume     = {8},
  abstract   = {Hippocampal area CA3 is widely considered to function as an autoassociative memory. However, it is insufficiently understood how it does so. In particular, the extensive experimental evidence for the importance of carefully regulated spiking times poses the question as to how spike timing\textendash based dynamics may support memory functions. Here, we develop a normative theory of autoassociative memory encompassing such network dynamics. Our theory specifies the way that the synaptic plasticity rule of a memory constrains the form of neuronal interactions that will retrieve memories optimally. If memories are stored by spike timing\textendash dependent plasticity, neuronal interactions should be formalized in terms of a phase response curve, indicating the effect of presynaptic spikes on the timing of postsynaptic spikes. We show through simulation that such memories are competent analog autoassociators and demonstrate directly that the attributes of phase response curves of CA3 pyramidal cells recorded in vitro qualitatively conform with the theory.},
  copyright  = {2005 Nature Publishing Group},
  journal    = {Nature Neuroscience},
  month      = dec,
  publisher  = {{Nature Publishing Group}},
  shorttitle = {Matching Storage and Recall},
  year       = {2005},
}

@Article{cavanaghCircuitMechanismIrrationalities2019,
  author     = {Cavanagh, Sean E. and Lam, Norman H. and Murray, John D. and Hunt, Laurence T. and Kennerley, Steven W.},
  title      = {A Circuit Mechanism for Irrationalities in Decision-Making and {{NMDA}} Receptor Hypofunction: Behaviour, Computational Modelling, and Pharmacology},
  doi        = {10.1101/826214},
  language   = {en},
  pages      = {826214},
  abstract   = {{$<$}h3{$>$}Abstract{$<$}/h3{$>$} {$<$}p{$>$}Decision-making biases can be systematic features of normal behaviour, or deficits underlying neuropsychiatric symptoms. We used behavioural psychophysics, spiking-circuit modelling and pharmacological manipulations to explore decision-making biases in health and disease. Monkeys performed an evidence integration task in which they showed a pro-variance bias (PVB): a preference to choose options with more variable evidence. The PVB was also present in a spiking circuit model, revealing a neural mechanism for this behaviour. Because NMDA receptor (NMDA-R) hypofunction is a leading hypothesis for neuropathology in schizophrenia, we simulated behavioural effects of NMDA-R hypofunction onto either excitatory or inhibitory neurons in the model. These were tested experimentally using the NMDA-R antagonist ketamine, yielding changes in decision-making consistent with lowered cortical excitation/inhibition balance from NMDA-R hypofunction onto excitatory neurons. These results provide a circuit-level mechanism that bridges across explanatory scales, from the synaptic to the behavioural, in neuropsychiatric disorders where decision-making biases are prominent.{$<$}/p{$><$}h3{$>$}Significance{$<$}/h3{$>$} {$<$}p{$>$}People can make apparently irrational decisions because of underlying features in their decision circuitry. Deficits in the same neural circuits may also underlie debilitating cognitive symptoms of neuropsychiatric patients. Here, we reveal a neural circuit mechanism explaining an irrationality frequently observed in healthy humans making binary choices \textendash{} the pro-variance bias. Our circuit model could be perturbed by introducing deficits in either excitatory or inhibitory neuron function. These two perturbations made specific, dissociable predictions for the types of irrational decisionmaking behaviour produced. We used the NMDA-R antagonist ketamine, an experimental model for schizophrenia, to test if these predictions were relevant to neuropsychiatric pathophysiology. The results were consistent with impaired excitatory neuron function, providing important new insights into the pathophysiology of schizophrenia.{$<$}/p{$>$}},
  chapter    = {New Results},
  copyright  = {\textcopyright{} 2019, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
  journal    = {bioRxiv},
  month      = oct,
  publisher  = {{Cold Spring Harbor Laboratory}},
  shorttitle = {A Circuit Mechanism for Irrationalities in Decision-Making and {{NMDA}} Receptor Hypofunction},
  year       = {2019},
}

@Article{kimLearningRecurrentDynamics2018,
  author     = {Kim, Christopher M and Chow, Carson C},
  title      = {Learning Recurrent Dynamics in Spiking Networks},
  doi        = {10.7554/eLife.37124},
  issn       = {2050-084X},
  pages      = {e37124},
  volume     = {7},
  abstract   = {Spiking activity of neurons engaged in learning and performing a task show complex spatiotemporal dynamics. While the output of recurrent network models can learn to perform various tasks, the possible range of recurrent dynamics that emerge after learning remains unknown. Here we show that modifying the recurrent connectivity with a recursive least squares algorithm provides sufficient flexibility for synaptic and spiking rate dynamics of spiking networks to produce a wide range of spatiotemporal activity. We apply the training method to learn arbitrary firing patterns, stabilize irregular spiking activity in a network of excitatory and inhibitory neurons respecting Dale's law, and reproduce the heterogeneous spiking rate patterns of cortical neurons engaged in motor planning and movement. We identify sufficient conditions for successful learning, characterize two types of learning errors, and assess the network capacity. Our findings show that synaptically-coupled recurrent spiking networks possess a vast computational capability that can support the diverse activity patterns in the brain.},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neuroprinciples/computation/kim2018lea.pdf},
  journal    = {eLife},
  keywords   = {learning,read,recurrent dynamics,spiking network,universal dynamics},
  month      = sep,
  readstatus = {read},
  year       = {2018},
}

@Article{mckennaBrainDynamicPhysical1994,
  author   = {McKenna, T. M. and McMullen, T. A. and Shlesinger, M. F.},
  title    = {The Brain as a Dynamic Physical System},
  doi      = {10.1016/0306-4522(94)90489-8},
  issn     = {0306-4522},
  language = {en},
  number   = {3},
  pages    = {587--605},
  volume   = {60},
  abstract = {The brain is a dynamic system that is non-linear at multiple levels of analysis. Characterization of its non-linear dynamics is fundamental to our understanding of brain function. Identifying families of attractors in phase space analysis, an approach which has proven valuable in describing non-linear mechanical and electrical systems, can prove valuable in describing a range of behaviors and associated neural activity including sensory and motor repertoires. Additionally, transitions between attractors may serve as useful descriptors for analysing state changes in neurons and neural ensembles. Recent observations of synchronous neural activity, and the emerging capability to record the spatiotemporal dynamics of neural activity by voltage-sensitive dyes and electrode arrays, provide opportunities for observing the population dynamics of neural ensembles within a dynamic systems context. New developments in the experimental physics of complex systems, such as the control of chaotic systems, selection of attractors, attractor switching and transient states, can be a source of powerful new analytical tools and insights into the dynamics of neural systems.},
  journal  = {Neuroscience},
  keywords = {EEG,IO,MEG,RF,SR},
  month    = jun,
  year     = {1994},
}
% == BibTeX quality report for douglasMappingMatrixWays2007:
% ? Title looks like it was stored in title-case in Zotero

@Article{douglasNeuronalCircuitsNeocortex2004,
  author    = {Douglas, Rodney J. and Martin, Kevan A.C.},
  title     = {Neuronal Circuits of the Neocortex},
  doi       = {10.1146/annurev.neuro.27.070203.144152},
  issn      = {0147-006X},
  number    = {1},
  pages     = {419--451},
  volume    = {27},
  abstract  = {We explore the extent to which neocortical circuits generalize, i.e., to what extent can neocortical neurons and the circuits they form be considered as canonical? We find that, as has long been suspected by cortical neuroanatomists, the same basic laminar and tangential organization of the excitatory neurons of the neocortex is evident wherever it has been sought. Similarly, the inhibitory neurons show characteristic morphology and patterns of connections throughout the neocortex. We offer a simple model of cortical processing that is consistent with the major features of cortical circuits: The superficial layer neurons within local patches of cortex, and within areas, cooperate to explore all possible interpretations of different cortical input and cooperatively select an interpretation consistent with their various cortical and subcortical inputs.},
  journal   = {Annual Review of Neuroscience},
  month     = jun,
  publisher = {{Annual Reviews}},
  year      = {2004},
}

@Article{blakeVisualCompetition2002a,
  author   = {Blake, R. and Logothetis, N.},
  title    = {Visual Competition},
  doi      = {10.1038/nrn701},
  issn     = {1471-003X (Print) 1471-003X (Linking)},
  language = {en},
  number   = {1},
  pages    = {13--21},
  volume   = {3},
  abstract = {Binocular rivalry--the alternations in perception that occur when different images are presented to the two eyes--has been the subject of intensive investigation for more than 160 years. The psychophysical properties of binocular rivalry have been well described, but newer imaging and electrophysiological techniques have not resolved the issue of where in the brain rivalry occurs. The most recent evidence supports a view of rivalry as a series of processes, each of which is implemented by neural mechanisms at different levels of the visual hierarchy. Although unanswered questions remain, this view of rivalry might allow us to resolve some of the controversies and apparent contradictions that have emerged from its study.},
  file     = {/Users/ssafavi/Documents/libraries/EndnoteLib_fromWin407/EndnoteLib_MPIPClocal_20170723.Data/PDF/3255651543/Blake-2002.pdf},
  journal  = {Nat Rev Neurosci},
  keywords = {Adaptation; Physiological,Animals,Brain/*physiology,Dominance; Ocular/*physiology,Electrophysiology,Evoked Potentials; Visual,Humans,Magnetic Resonance Imaging,Magnetoencephalography,Ocular Physiological Phenomena,Time Factors,Vision Tests,Visual Perception/*physiology},
  month    = jan,
  year     = {2002},
}
% == BibTeX quality report for kinouchiModelConsciousnessAttention2014:
% ? Title looks like it was stored in title-case in Zotero

@Article{kinouchiOptimalDynamicalRange2006,
  author   = {Kinouchi, O. and Copelli, M.},
  title    = {Optimal Dynamical Range of Excitable Networks at Criticality},
  doi      = {DOI 10.1038/nphys289},
  issn     = {1745-2473},
  language = {English},
  pages    = {348--352},
  volume   = {2},
  abstract = {A recurrent idea in the study of complex systems is that optimal information processing is to be found near phase transitions. However, this heuristic hypothesis has few ( if any) concrete realizations where a standard and biologically relevant quantity is optimized at criticality. Here we give a clear example of such a phenomenon: a network of excitable elements has its sensitivity and dynamic range maximized at the critical point of a non-equilibrium phase transition. Our results are compatible with the essential role of gap junctions in olfactory glomeruli and retinal ganglionar cell output. Synchronization and global oscillations also emerge from the network dynamics. We propose that the main functional role of electrical coupling is to provide an enhancement of dynamic range, therefore allowing the coding of information spanning several orders of magnitude. The mechanism could provide a microscopic neural basis for psychophysical laws.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/criticality/kinouchi2006opt.pdf},
  journal  = {Nature Physics},
  keywords = {cells,connexin36,expression,glomeruli,neuronal gap-junctions,olfactory-bulb,oscillations,retina,sensitivity,signals},
  month    = may,
  year     = {2006},
}

@PhdThesis{mayerOptimalImmuneSystems2017,
  author     = {Mayer, Andreas},
  title      = {Optimal Immune Systems : A Ressource Allocation and Information Processing View of Immune Defense},
  type       = {Theses},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/computation/bayesian/mayer2017opt.pdf},
  keywords   = {Biophysics,Biophysique,Evolution,Immunologie,Immunology,Physique statistique,Statistical physics},
  month      = jun,
  school     = {PSL Research University},
  shorttitle = {Optimal Immune Systems},
  year       = {2017},
}

@Book{gerstnerNeuronalDynamicsSingle2014,
  author    = {Gerstner, Wulfram and Kistler, Werner M. and Naud, Richard and Paninsk, Liam},
  title     = {Neuronal Dynamics, {{From Single Neurons}} to {{Networks}} and {{Models}} of {{Cognition}}},
  isbn      = {978-1-107-63519-7},
  publisher = {{Cambridge University Press}},
  address   = {{University Printing House, Cambridge CB2 8BS, United Kingdom}},
  file      = {/home/ssafavi/Nextcloud/libraries/zoteroLib/books/gerstner2014neu.pdf;/home/ssafavi/Nextcloud/libraries/zoteroLib/books/gerstner2014neu.txt},
  keywords  = {Cognitive neuroscience,Neural networks (Neurobiology),Neurobiology},
  year      = {2014},
}

@Article{bialekRandomSwitchingOptimal1995,
  author     = {Bialek, W. and DeWeese, M.},
  title      = {Random Switching and Optimal Processing in the Perception of Ambiguous Signals},
  doi        = {DOI 10.1103/PhysRevLett.74.3077},
  issn       = {1079-7114 (Electronic) 0031-9007 (Linking)},
  language   = {English},
  pages      = {3077--3080},
  volume     = {74},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/collectiveBehaviors/cognition/bialek1995ran.pdf;/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/bialek1995ran.pdf;/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/perception/multiStablePerception_msp/models/bialek1995ran.pdf;/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/perception/multiStablePerception_msp/models/bialek1995ran.pdf},
  journal    = {Phys Rev Lett},
  keywords   = {read,reversal},
  month      = apr,
  readstatus = {read},
  year       = {1995},
}

@Article{modhaNetworkArchitectureLongdistance2010,
  author   = {Modha, D. S. and Singh, R.},
  title    = {Network Architecture of the Long-Distance Pathways in the Macaque Brain},
  doi      = {10.1073/pnas.1008054107},
  issn     = {1091-6490 (Electronic) 0027-8424 (Linking)},
  language = {en},
  number   = {30},
  pages    = {13485--90},
  volume   = {107},
  abstract = {Understanding the network structure of white matter communication pathways is essential for unraveling the mysteries of the brain's function, organization, and evolution. To this end, we derive a unique network incorporating 410 anatomical tracing studies of the macaque brain from the Collation of Connectivity data on the Macaque brain (CoCoMac) neuroinformatic database. Our network consists of 383 hierarchically organized regions spanning cortex, thalamus, and basal ganglia; models the presence of 6,602 directed long-distance connections; is three times larger than any previously derived brain network; and contains subnetworks corresponding to classic corticocortical, corticosubcortical, and subcortico-subcortical fiber systems. We found that the empirical degree distribution of the network is consistent with the hypothesis of the maximum entropy exponential distribution and discovered two remarkable bridges between the brain's structure and function via network-theoretical analysis. First, prefrontal cortex contains a disproportionate share of topologically central regions. Second, there exists a tightly integrated core circuit, spanning parts of premotor cortex, prefrontal cortex, temporal lobe, parietal lobe, thalamus, basal ganglia, cingulate cortex, insula, and visual cortex, that includes much of the task-positive and task-negative networks and might play a special role in higher cognition and consciousness.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/brain/modha2010net.pdf;/home/ssafavi/Zotero/storage/5M5BXTNV/Modha-20101.pdf},
  journal  = {Proc Natl Acad Sci U S A},
  keywords = {*Models; Neurological,Animals,Brain Mapping,Brain/anatomy \& histology/*physiology,Databases; Factual,Macaca,Nerve Net/*physiology,Neural Pathways/anatomy \& histology/*physiology},
  month    = jul,
  year     = {2010},
}
% == BibTeX quality report for ArteRupestreOrigen2014:
% Missing required field 'author'
% Missing required field 'journal'

@Book{arthurEconomyEvolvingComplex1997,
  author      = {Arthur, W. Brian and Durlauf, Steven N. and Lane, David A. and Program, SFI Economics},
  title       = {The Economy as an Evolving Complex System {{II}}},
  isbn        = {978-0-201-95988-8},
  language    = {en},
  publisher   = {{Addison-Wesley}},
  abstract    = {A new view of the economy as an evolving, complex system has been pioneered at the Santa Fe Institute over the last ten years. This volume is a collection of articles that shape and define this view\textemdash a view of the economy as emerging from the interactions of individual agents whose behavior constantly evolves, whose strategies and actions are always adapting.The traditional framework in economics portrays economic activity within an equilibrium steady state. The interacting agents in the economy are typically homogenous, solve well-defined problems using perfect rationality, and act within given legal and social structures. The complexity approach, by contrast, sees economic activity as continually changing\textemdash continually in process. the interacting agents are typically heterogeneous, they must cognitively interpret the problems they face, and together they create the structures\textemdash markets, legal and social institutions, price patterns, expectations\textemdash to which they individually react. Such structures may never settle down. Agents may forever adapt and explore and evolve their behavior within structures that continually emerge and change and disappear\textemdash structures these behaviors co-create. This complexity approach does not replace the equilibrium one\textemdash it complements it.The papers collected here originated at a recent conference at the Santa Fe Institute, which was called to follow up the well-known 1987 conference organized by Philip Anderson, Kenneth Arrow, and David Pines. They survey the new study of complexity and the economy. They apply this approach to real economic problems and they show the extent to which the initial vision of the 1987 conference has come to fruition.The Economy as an Evolving Complex System II will fascinate economists of all types.},
  file        = {/home/ssafavi/Nextcloud/libraries/zoteroLib/books/arthur1997the.pdf},
  googlebooks = {2RK6AAAAIAAJ},
  keywords    = {Business \& Economics / Economics / General,Political Science / Public Policy / Economic Policy},
  year        = {1997},
}

@Article{amirCorticalHierarchyReflected1993,
  author     = {Amir, Y. and Harel, M. and Malach, Rafael},
  title      = {Cortical Hierarchy Reflected in the Organization of Intrinsic Connections in Macaque Monkey Visual Cortex},
  doi        = {10.1002/cne.903340103},
  issn       = {1096-9861},
  language   = {en},
  number     = {1},
  pages      = {19--46},
  volume     = {334},
  abstract   = {Neuronal response properties vary markedly at increasing levels of the cortical hierarchy. At present it is unclear how these variations are reflected in the organization of the intrinsic cortical circuitry. Here we analyze patterns of intrinsic horizontal connections at different hierarchical levels in the visual cortex of the macaque monkey. The connections were studied in tangential sections of flattened cortices, which were injected with the anterograde tracer biocytin. We directly compared the organization of connections in four cortical areas representing four different levels in the cortical hierarchy. The areas were visual areas 1, 2, 4 and Brodman's area 7a (V1, V2, V4 and 7a, respectively). In all areas studied, injections labeled numerous horizontally coursing axons that formed dense halos around the injection sites. Further away, the fibers tended to form separate clusters. Many fibers could be traced along the way from the injection sites to the target clusters. At progressively higher order areas, there was a striking increase in the spread of intrinsic connections: from a measured distance of 2.1 mm in area V1 to 9.0 mm in area 7a. Average interpatch distance also increased from 0.61 mm in area V1 to 1.56 mm in area 7a. In contrast, patch size changed far less at higher order areas, from an average width of 230 {\"m}M in area V1 to 310 {\"m}m in area 7a. Analysis of synaptic bouton distribution along axons revealed that average interbouton distance remained constant at 6.4 {\"m}m (median) in and out of the clusters and in the different cortical areas. Larger injections resulted in a marked increase in the number of labeled patches but only a minor increase in the spread of connections or in patch size. Thus, in line with the more global computational roles proposed for the higher order visual areas, the spread of intrinsic connections is increased with the hierarchy level. On the other hand, the clustered organization of the connections is preserved at higher order areas. These clusters may reflect the existence of cortical modules having blob-like dimensions throughout macaque monkey visual cortex. \textcopyright{} 1993 Wiley-Liss, Inc.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/cne.903340103},
  copyright  = {Copyright \textcopyright{} 1993 Wiley-Liss, Inc.},
  journal    = {Journal of Comparative Neurology},
  keywords   = {biocytin,cerebral cortex,cortical areas,tract-tracing,visual system},
  year       = {1993},
}

@Article{ngoPsychiatricGeneticStudies2011a,
  author     = {Ngo, Trung T. and Mitchell, Philip B. and Martin, Nicholas G. and Miller, Steven M.},
  title      = {Psychiatric and Genetic Studies of Binocular Rivalry: An Endophenotype for Bipolar Disorder?},
  doi        = {10.1111/j.1601-5215.2010.00510.x},
  issn       = {1601-5215, 0924-2708},
  language   = {en},
  number     = {1},
  pages      = {37--42},
  volume     = {23},
  abstract   = {//static.cambridge.org/content/id/urn\%3Acambridge.org\%3Aid\%3Aarticle\%3AS092427080002665X/resource/name/firstPage-S092427080002665Xa.jpg},
  journal    = {Acta Neuropsychiatrica},
  month      = feb,
  publisher  = {{Cambridge University Press}},
  shorttitle = {Psychiatric and Genetic Studies of Binocular Rivalry},
  year       = {2011},
}

@Article{carterPsilocybinSlowsBinocular,
  author   = {Carter, O and Pettigrew, J and Hasler, F and Wallis, G and Vollenweider, F},
  title    = {Psilocybin Slows Binocular Rivalry Switching through Serotonin Modulation.},
  language = {en},
  pages    = {1},
  abstract = {Hallucinogenic doses of the 5-HT1A/2A agonist psilocybin slows down the rate of rivalry switching \& the duration of the transition phase.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/perception/multiStablePerception_msp/observations/valueBased/carterpsi.pdf},
}
% == BibTeX quality report for zhangThetaAlphaOscillations2018:
% ? Title looks like it was stored in title-case in Zotero

@Article{zhangTopologicalPortraitsMultiscale2020,
  author   = {Zhang, Mengsen and Kalies, William D. and Kelso, J. A. Scott and Tognoli, Emmanuelle},
  title    = {Topological Portraits of Multiscale Coordination Dynamics},
  doi      = {10.1016/j.jneumeth.2020.108672},
  issn     = {0165-0270},
  language = {en},
  pages    = {108672},
  volume   = {339},
  abstract = {Living systems exhibit complex yet organized behavior on multiple spatiotemporal scales. To investigate the nature of multiscale coordination in living systems, one needs a meaningful and systematic way to quantify the complex dynamics, a challenge in both theoretical and empirical realms. The present work shows how integrating approaches from computational algebraic topology and dynamical systems may help us meet this challenge. In particular, we focus on the application of multiscale topological analysis to coordinated rhythmic processes. First, theoretical arguments are introduced as to why certain topological features and their scale-dependency are highly relevant to understanding complex collective dynamics. Second, we propose a method to capture such dynamically relevant topological information using persistent homology, which allows us to effectively construct a multiscale topological portrait of rhythmic coordination. Finally, the method is put to test in detecting transitions in real data from an experiment of rhythmic coordination in ensembles of interacting humans. The recurrence plots of topological portraits highlight collective transitions in coordination patterns that were elusive to more traditional methods. This sensitivity to collective transitions would be lost if the behavioral dynamics of individuals were treated as separate degrees of freedom instead of constituents of the topology that they collectively forge. Such multiscale topological portraits highlight collective aspects of coordination patterns that are irreducible to properties of individual parts. The present work demonstrates how the analysis of multiscale coordination dynamics can benefit from topological methods, thereby paving the way for further systematic quantification of complex, high-dimensional dynamics in living systems.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neuroprinciples/multiScale/zhang2020top.pdf},
  journal  = {Journal of Neuroscience Methods},
  keywords = {Complex systems,Coordination Dynamics,Metastability,Oscillators,Topological data analysis},
  month    = jun,
  year     = {2020},
}

@Article{korenRememberingImmunityNeuronal2020,
  author     = {Koren, Tamar and Krot, Maria and Boshnak, Nadia T. and Amer, Mariam and {Ben-Shaanan}, Tamar and {Azulay-Debby}, Hilla and Hajjo, Haitham and Avishai, Eden and Schiller, Maya and Haykin, Hedva and Korin, Ben and Farfara, Dorit and Hakim, Fahed and Rosenblum, Kobi and Rolls, Asya},
  title      = {Remembering Immunity: {{Neuronal}} Ensembles in the Insular Cortex Encode and Retrieve Specific Immune Responses},
  doi        = {10.1101/2020.12.03.409813},
  language   = {en},
  pages      = {2020.12.03.409813},
  abstract   = {{$<$}p{$>$}Increasing evidence indicates that the brain regulates peripheral immunity. Yet, it remains unclear whether and how the brain represents the state of the immune system. Here, we show that immune-related information is stored in the brain9s insular cortex (InsCtx). Using activity-dependent cell labeling in mice (FosTRAP), we captured neuronal ensembles in the InsCtx that were active under two different inflammatory conditions (DSS-induced colitis and Zymosan-induced peritonitis). Chemogenetic reactivation of these neuronal ensembles was sufficient to broadly retrieve the inflammatory state under which these neurons were captured. Thus, we show that the brain can encode and initiate specific immune responses, extending the classical concept of immunological memory to neuronal representations of immunity.{$<$}/p{$>$}},
  chapter    = {New Results},
  copyright  = {\textcopyright{} 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
  journal    = {bioRxiv},
  month      = dec,
  publisher  = {{Cold Spring Harbor Laboratory}},
  shorttitle = {Remembering Immunity},
  year       = {2020},
}

@Article{touboulPowerlawStatisticsUniversal2017,
  author   = {Touboul, Jonathan and Destexhe, Alain},
  title    = {Power-Law Statistics and Universal Scaling in the Absence of Criticality},
  doi      = {10.1103/PhysRevE.95.012413},
  number   = {1},
  pages    = {012413},
  volume   = {95},
  abstract = {Critical states are sometimes identified experimentally through power-law statistics or universal scaling functions. We show here that such features naturally emerge from networks in self-sustained irregular regimes away from criticality. In these regimes, statistical physics theory of large interacting systems predict a regime where the nodes have independent and identically distributed dynamics. We thus investigated the statistics of a system in which units are replaced by independent stochastic surrogates and found the same power-law statistics, indicating that these are not sufficient to establish criticality. We rather suggest that these are universal features of large-scale networks when considered macroscopically. These results put caution on the interpretation of scaling laws found in nature.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/criticality/touboul2017pow.pdf},
  journal  = {Physical Review E},
  month    = jan,
  year     = {2017},
}

@Book{amitModelingBrainFunction1992,
  author      = {Amit, D. J. and Amit, Daniel J.},
  title       = {Modeling {{Brain Function}}: {{The World}} of {{Attractor Neural Networks}}},
  isbn        = {978-0-521-42124-9},
  language    = {en},
  publisher   = {{Cambridge University Press}},
  abstract    = {Exploring one of the most exciting and potentially rewarding areas of scientific research, the study of the principles and mechanisms underlying brain function, this book introduces and explains the techniques brought from physics to the study of neural networks and the insights they have stimulated. Substantial progress in understanding memory, the learning process, and self-organization by studying the properties of models of neural networks have resulted in discoveries of important parallels between the properties of statistical, nonlinear cooperative systems in physics and neural networks. The author presents a coherent and clear, nontechnical view of all the basic ideas and results. More technical aspects are restricted to special sections and appendices in each chapter.},
  googlebooks = {fvLYch1yQncC},
  keywords    = {Medical / Neuroscience,Science / Life Sciences / Biophysics,Science / Life Sciences / Neuroscience},
  month       = jun,
  shorttitle  = {Modeling {{Brain Function}}},
  year        = {1992},
}
% == BibTeX quality report for zaretskayaDisruptingParietalFunction2010:
% ? Title looks like it was stored in title-case in Zotero

@Article{zaretskayaIntrospectionAttentionAwareness2014,
  author   = {Zaretskaya, N. and Narinyan, M.},
  title    = {Introspection, Attention or Awareness? {{The}} Role of the Frontal Lobe in Binocular Rivalry},
  doi      = {10.3389/fnhum.2014.00527},
  issn     = {1662-5161 (Electronic) 1662-5161 (Linking)},
  language = {English},
  pages    = {527},
  volume   = {8},
  abstract = {Bistable stimuli are one of the most popular approaches to studying the neural mechanism of conscious visual perception. Such stimuli contain conflicting information, which the visual system cannot...},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/perception/multiStablePerception_msp/zaretskaya2014int.pdf},
  journal  = {Front Hum Neurosci},
  keywords = {binocular rivalry,bistable perception,consciousness,fMRI,frontal lobe},
  pmcid    = {PMC4104467},
  year     = {2014},
}
% == BibTeX quality report for biessmannNonseparableSpatiotemporalBrain2012:
% Missing required field 'journal'

@Article{biessmannTemporalKernelCCA2009,
  author   = {Bie{\ss}mann, Felix and Meinecke, Frank C. and Gretton, Arthur and Rauch, Alexander and Rainer, Gregor and Logothetis, Nikos K. and M{\"u}ller, Klaus-Robert},
  title    = {Temporal Kernel {{CCA}} and Its Application in Multimodal Neuronal Data Analysis},
  doi      = {10.1007/s10994-009-5153-3},
  issn     = {0885-6125 1573-0565},
  language = {en},
  number   = {1-2},
  pages    = {5--27},
  volume   = {79},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/nda_kernelMethods/biemann2009tem.pdf},
  journal  = {Machine Learning},
  year     = {2009},
}

@Article{tsuchiyaNoReportParadigmsExtracting2015,
  author     = {Tsuchiya, Naotsugu and Wilke, Melanie and Fr{\"a}ssle, Stefan and Lamme, Victor A. F.},
  title      = {No-{{Report Paradigms}}: {{Extracting}} the {{True Neural Correlates}} of {{Consciousness}}},
  doi        = {10.1016/j.tics.2015.10.002},
  issn       = {1364-6613},
  language   = {en},
  number     = {12},
  pages      = {757--770},
  volume     = {19},
  abstract   = {The goal of consciousness research is to reveal the neural basis of phenomenal experience. To study phenomenology, experimenters seem obliged to ask reports from the subjects to ascertain what they experience. However, we argue that the requirement of reports has biased the search for the neural correlates of consciousness over the past decades. More recent studies attempt to dissociate neural activity that gives rise to consciousness from the activity that enables the report; in particular, no-report paradigms have been utilized to study conscious experience in the full absence of any report. We discuss the advantages and disadvantages of report-based and no-report paradigms, and ask how these jointly bring us closer to understanding the true neural basis of consciousness.},
  journal    = {Trends in Cognitive Sciences},
  keywords   = {access,attention,awareness,consciousness,introspection,report},
  month      = dec,
  shorttitle = {No-{{Report Paradigms}}},
  year       = {2015},
}

@Article{millerGeneticContributionIndividual2010,
  author     = {Miller, S. M. and Hansell, N. K. and Ngo, T. T. and Liu, G. B. and Pettigrew, J. D. and Martin, N. G. and Wright, M. J.},
  title      = {Genetic Contribution to Individual Variation in Binocular Rivalry Rate},
  doi        = {10.1073/pnas.0912149107},
  issn       = {0027-8424, 1091-6490},
  language   = {en},
  number     = {6},
  pages      = {2664--2668},
  volume     = {107},
  journal    = {Proceedings of the National Academy of Sciences},
  keywords   = {read},
  month      = feb,
  readstatus = {read},
  year       = {2010},
}

@Article{raschInferringSpikeTrains2008a,
  author   = {Rasch, M. J. and Gretton, A. and Murayama, Y. and Maass, W. and Logothetis, N. K.},
  title    = {Inferring Spike Trains from Local Field Potentials},
  doi      = {10.1152/jn.00919.2007},
  issn     = {0022-3077 (Print) 0022-3077 (Linking)},
  language = {en},
  number   = {3},
  pages    = {1461--76},
  volume   = {99},
  abstract = {We investigated whether it is possible to infer spike trains solely on the basis of the underlying local field potentials (LFPs). Using support vector machines and linear regression models, we found that in the primary visual cortex (V1) of monkeys, spikes can indeed be inferred from LFPs, at least with moderate success. Although there is a considerable degree of variation across electrodes, the low-frequency structure in spike trains (in the 100-ms range) can be inferred with reasonable accuracy, whereas exact spike positions are not reliably predicted. Two kinds of features of the LFP are exploited for prediction: the frequency power of bands in the high gamma-range (40-90 Hz) and information contained in low-frequency oscillations ({$<$}10 Hz), where both phase and power modulations are informative. Information analysis revealed that both features code (mainly) independent aspects of the spike-to-LFP relationship, with the low-frequency LFP phase coding for temporally clustered spiking activity. Although both features and prediction quality are similar during seminatural movie stimuli and spontaneous activity, prediction performance during spontaneous activity degrades much more slowly with increasing electrode distance. The general trend of data obtained with anesthetized animals is qualitatively mirrored in that of a more limited data set recorded in V1 of non-anesthetized monkeys. In contrast to the cortical field potentials, thalamic LFPs (e.g., LFPs derived from recordings in the dorsal lateral geniculate nucleus) hold no useful information for predicting spiking activity.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/projects/nnr/MT/rasch2008inf.pdf},
  journal  = {J Neurophysiol},
  keywords = {Action Potentials/*physiology,Animals,Electroencephalography/methods,Evoked Potentials; Visual/*physiology,Macaca mulatta,Neurons/*physiology,Photic Stimulation/methods,Predictive Value of Tests,Reference Values,Spectrum Analysis,Visual Cortex/*cytology/*physiology,Visual Fields/physiology,Visual Perception/physiology,Wakefulness},
  month    = mar,
  year     = {2008},
}

@Article{bairCorrelatedFiringMacaque2001a,
  author   = {Bair, W. and Zohary, E. and Newsome, W. T.},
  title    = {Correlated Firing in Macaque Visual Area {{MT}}: Time Scales and Relationship to Behavior},
  issn     = {1529-2401 (Electronic) 0270-6474 (Linking)},
  number   = {5},
  pages    = {1676--97},
  volume   = {21},
  abstract = {We studied the simultaneous activity of pairs of neurons recorded with a single electrode in visual cortical area MT while monkeys performed a direction discrimination task. Previously, we reported the strength of interneuronal correlation of spike count on the time scale of the behavioral epoch (2 sec) and noted its potential impact on signal pooling (Zohary et al., 1994). We have now examined correlation at longer and shorter time scales and found that pair-wise cross-correlation was predominantly short term (10-100 msec). Narrow, central peaks in the spike train cross-correlograms were largely responsible for correlated spike counts on the time scale of the behavioral epoch. Longer-term (many seconds to minutes) changes in the responsiveness of single neurons were observed in auto-correlations; however, these slow changes in time were on average uncorrelated between neurons. Knowledge of the limited time scale of correlation allowed the derivation of a more efficient metric for spike count correlation based on spike timing information, and it also revealed a potential relative advantage of larger neuronal pools for shorter integration times. Finally, correlation did not depend on the presence of the visual stimulus or the behavioral choice of the animal. It varied little with stimulus condition but was stronger between neurons with similar direction tuning curves. Taken together, our results strengthen the view that common input, common stimulus selectivity, and common noise are tightly linked in functioning cortical circuits.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neuralInteractions/PWcorrelations/bair2001cor.pdf},
  journal  = {J Neurosci},
  keywords = {Action Potentials/physiology,Animals,Behavior; Animal/*physiology,Choice Behavior/physiology,Conditioning; Operant/physiology,Data Display,Discrimination Learning/physiology,Electrodes; Implanted,Eye Movements/physiology,Female,Fixation; Ocular/physiology,Macaca mulatta,Male,Microelectrodes,Motion Perception/physiology,Neurons/*physiology,Photic Stimulation/methods,Reaction Time/*physiology,Sensory Thresholds,Signal Processing; Computer-Assisted,Visual Cortex/cytology/*physiology},
  month    = mar,
  year     = {2001},
}
% == BibTeX quality report for samuelgershmanPerceptualMultistabilityMarkov2014:
% ? Unsure about the formatting of the booktitle
% ? Title looks like it was stored in title-case in Zotero

@InProceedings{samuelgershmanPerceptualMultistabilityMarkov2014a,
  author    = {Samuel Gershman and Ed Vul and Joshua B. Tenenbaum},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  title     = {Perceptual {{Multistability}} as {{Markov Chain Monte Carlo Inference}}},
  pages     = {611--619},
  abstract  = {Eletronic Proceedings of Neural Information Processing Systems},
  file      = {/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/perception/multiStablePerception_msp/models/samuel_gershman2014per.pdf},
  year      = {2014},
}
% == BibTeX quality report for izhikevichDynamicalSystemsNeuroscience2010:
% ? Title looks like it was stored in title-case in Zotero

@Article{izhikevichLargescaleModelMammalian2008,
  author   = {Izhikevich, E. M. and Edelman, G. M.},
  title    = {Large-Scale Model of Mammalian Thalamocortical Systems},
  doi      = {10.1073/pnas.0712231105},
  issn     = {1091-6490 (Electronic) 0027-8424 (Linking)},
  number   = {9},
  pages    = {3593--8},
  volume   = {105},
  abstract = {The understanding of the structural and dynamic complexity of mammalian brains is greatly facilitated by computer simulations. We present here a detailed large-scale thalamocortical model based on experimental measures in several mammalian species. The model spans three anatomical scales. (i) It is based on global (white-matter) thalamocortical anatomy obtained by means of diffusion tensor imaging (DTI) of a human brain. (ii) It includes multiple thalamic nuclei and six-layered cortical microcircuitry based on in vitro labeling and three-dimensional reconstruction of single neurons of cat visual cortex. (iii) It has 22 basic types of neurons with appropriate laminar distribution of their branching dendritic trees. The model simulates one million multicompartmental spiking neurons calibrated to reproduce known types of responses recorded in vitro in rats. It has almost half a billion synapses with appropriate receptor kinetics, short-term plasticity, and long-term dendritic spike-timing-dependent synaptic plasticity (dendritic STDP). The model exhibits behavioral regimes of normal brain activity that were not explicitly built-in but emerged spontaneously as the result of interactions among anatomical and dynamic processes. We describe spontaneous activity, sensitivity to changes in individual neurons, emergence of waves and rhythms, and functional connectivity on different scales.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/c_onTabelPrince/izhikevich2008lar.pdf},
  journal  = {Proc Natl Acad Sci U S A},
  keywords = {*Models; Biological,*Models; Neurological,*Synapses,Action Potentials,Animals,Brain/*anatomy \& histology,Cats,Cerebral Cortex/anatomy \& histology,Computer Simulation,Humans,Mammals,Neurons,Thalamic Nuclei,Visual Cortex/anatomy \& histology},
  month    = mar,
  year     = {2008},
}

@Article{angelucciCircuitsLocalGlobal2002,
  author    = {Angelucci, Alessandra and Levitt, Jonathan B. and Walton, Emma J. S. and Hup{\'e}, Jean-Michel and Bullier, Jean and Lund, Jennifer S.},
  title     = {Circuits for {{Local}} and {{Global Signal Integration}} in {{Primary Visual Cortex}}},
  doi       = {10.1523/JNEUROSCI.22-19-08633.2002},
  issn      = {0270-6474, 1529-2401},
  language  = {en},
  number    = {19},
  pages     = {8633--8646},
  volume    = {22},
  abstract  = {Contrast-dependent changes in spatial summation and contextual modulation of primary visual cortex (V1) neuron responses to stimulation of their receptive field reveal long-distance integration of visual signals within V1, well beyond the classical receptive field (cRF) of single neurons. To identify the cortical circuits mediating these long-distance computations, we have used a combination of anatomical and physiological recording methods to determine the spatial scale and retinotopic logic of intra-areal V1 horizontal connections and inter-areal feedback connections to V1. We have then compared the spatial scales of these connectional systems to the spatial dimensions of the cRF, spatial summation field (SF), and modulatory surround field of macaque V1 neurons. We find that monosynaptic horizontal connections within area V1 are of an appropriate spatial scale to mediate interactions within the SF of V1 neurons and to underlie contrast-dependent changes in SF size. Contrary to common beliefs, these connections cannot fully account for the dimensions of the surround field. The spatial scale of feedback circuits from extrastriate cortex to V1 is, instead, commensurate with the full spatial range of center\textendash surround interactions. Thus these connections could represent an anatomical substrate for contextual modulation and global-to-local integration of visual signals. Feedback projections connect corresponding and equal-sized regions of the visual field in striate and extrastriate cortices and cover anisotropic parts of visual space, unlike V1 horizontal connections that are isotropic in the macaque. V1 isotropic connectivity demonstrates that anisotropic horizontal connections are not necessary to generate orientation selectivity. Anisotropic feedback connections may play a role in contour completion.},
  chapter   = {ARTICLE},
  copyright = {Copyright \textcopyright{} 2002 Society for Neuroscience},
  journal   = {Journal of Neuroscience},
  keywords  = {extrastriate cortex,feedback connections,lateral connections,macaque,primary visual cortex,surround modulation},
  month     = oct,
  pmid      = {12351737},
  publisher = {{Society for Neuroscience}},
  year      = {2002},
}

@Book{pesensonMultiscaleAnalysisNonlinear2013,
  title      = {Multiscale Analysis and Nonlinear Dynamics: From Genes to the Brain},
  editor     = {Pesenson, Misha Z.},
  isbn       = {978-3-527-41198-6},
  publisher  = {{Wiley-VCH Verlag GmbH \& Co. KGaA}},
  series     = {Reviews of Nonlinear Dynamics and Complexity},
  abstract   = {Since modeling multiscale phenomena in systems biology and neuroscience is a highly interdisciplinary task, the editor of the book invited experts in bio-engineering, chemistry, cardiology, neuroscience, computer science, and applied mathematics, to provide their perspectives. Each chapter is a window into the current state of the art in the areas of research discussed and the book is intended for advanced researchers interested in recent developments in these fields. While multiscale analysis is the major integrating theme of the book, its subtitle does not call for bridging the scales from genes to behavior, but rather stresses the unifying perspective offered by the concepts referred to in the title. It is believed that the interdisciplinary approach adopted here will be beneficial for all the above mentioned fields},
  address    = {{Weinheim, Germany}},
  annotation = {OCLC: ocn870508240},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/books/pesenson2013mul.pdf},
  keywords   = {Mathematical models,Multiscale modeling,Neurosciences,Nonlinear Dynamics,r15,read,Systems biology,Systems Biology},
  lccn       = {QH324.2 .M857 2013},
  readstatus = {read},
  shorttitle = {Multiscale Analysis and Nonlinear Dynamics},
  year       = {2013},
}

@Book{doyaBayesianBrainProbabilistic2007,
  author      = {Doya, Kenji and Ishii, Shin and Pouget, Alexandre and Rao, Rajesh P. N.},
  title       = {Bayesian {{Brain}}: {{Probabilistic Approaches}} to {{Neural Coding}}},
  isbn        = {978-0-262-04238-3},
  language    = {en},
  publisher   = {{MIT Press}},
  abstract    = {A Bayesian approach can contribute to an understanding of the brain on multiple levels, by giving normative predictions about how an ideal sensory system should combine prior knowledge and observation, by providing mechanistic interpretation of the dynamic functioning of the brain circuit, and by suggesting optimal ways of deciphering experimental data. Bayesian Brain brings together contributions from both experimental and theoretical neuroscientists that examine the brain mechanisms of perception, decision making, and motor control according to the concepts of Bayesian estimation.After an overview of the mathematical concepts, including Bayes' theorem, that are basic to understanding the approaches discussed, contributors discuss how Bayesian concepts can be used for interpretation of such neurobiological data as neural spikes and functional brain imaging. Next, contributors examine the modeling of sensory processing, including the neural coding of information about the outside world. Finally, contributors explore dynamic processes for proper behaviors, including the mathematics of the speed and accuracy of perceptual decisions and neural models of belief propagation.},
  googlebooks = {bsQMWXXHzrYC},
  keywords    = {Medical / Neuroscience},
  shorttitle  = {Bayesian {{Brain}}},
  year        = {2007},
}
% == BibTeX quality report for bullmoreGettingSurfaceBehavioral2020:
% ? Title looks like it was stored in title-case in Zotero

@Book{bullmoreInflamedMindRadical2018,
  author     = {Bullmore, Edward},
  title      = {The Inflamed Mind: A Radical New Approach to Depression},
  isbn       = {978-1-78072-350-1},
  language   = {English},
  abstract   = {Depression will be the single biggest cause of disability in the next 20 years. But treatment for it has not changed much in the last three decades. In the world of psychiatry, time has apparently stood still ... until now. In this game-changing book, world neuroscience expert Professor Edward Bullmore reveals the breakthrough new science on the link between depression and inflammation of the body and brain. He explains how and why we now know that mental disorders can have their root cause in the immune system, and outlines a future revolution in which treatments could be specifically targeted to break the vicious cycle of stress, inflammation and depression. The Inflamed Mind goes far beyond the clinic and the lab, representing a whole new way of looking at how mind, brain and body all work together in a sometimes misguided effort to help us survive in a hostile world. It offers insights into the story of Western medicine, how we have got it wrong as well as right in the past, and how we could start getting to grips with depression and other mental disorders much more effectively in the future.},
  annotation = {OCLC: 1055553361},
  shorttitle = {The Inflamed Mind},
  year       = {2018},
}
% == BibTeX quality report for bilginComplexbrainsNeurosciencePodcasts2020:
% ? Title looks like it was stored in lower-case in Zotero

@Article{billDistributedBayesianComputation2015,
  author   = {Bill, Johannes and Buesing, Lars and Habenschuss, Stefan and Nessler, Bernhard and Maass, Wolfgang and Legenstein, Robert},
  title    = {Distributed {{Bayesian Computation}} and {{Self}}-{{Organized Learning}} in {{Sheets}} of {{Spiking Neurons}} with {{Local Lateral Inhibition}}},
  doi      = {10.1371/journal.pone.0134356},
  issn     = {1932-6203},
  language = {en},
  number   = {8},
  pages    = {e0134356},
  volume   = {10},
  abstract = {During the last decade, Bayesian probability theory has emerged as a framework in cognitive science and neuroscience for describing perception, reasoning and learning of mammals. However, our understanding of how probabilistic computations could be organized in the brain, and how the observed connectivity structure of cortical microcircuits supports these calculations, is rudimentary at best. In this study, we investigate statistical inference and self-organized learning in a spatially extended spiking network model, that accommodates both local competitive and large-scale associative aspects of neural information processing, under a unified Bayesian account. Specifically, we show how the spiking dynamics of a recurrent network with lateral excitation and local inhibition in response to distributed spiking input, can be understood as sampling from a variational posterior distribution of a well-defined implicit probabilistic model. This interpretation further permits a rigorous analytical treatment of experience-dependent plasticity on the network level. Using machine learning theory, we derive update rules for neuron and synapse parameters which equate with Hebbian synaptic and homeostatic intrinsic plasticity rules in a neural implementation. In computer simulations, we demonstrate that the interplay of these plasticity rules leads to the emergence of probabilistic local experts that form distributed assemblies of similarly tuned cells communicating through lateral excitatory connections. The resulting sparse distributed spike code of a well-adapted network carries compressed information on salient input features combined with prior experience on correlations among them. Our theory predicts that the emergence of such efficient representations benefits from network architectures in which the range of local inhibition matches the spatial extent of pyramidal cells that share common afferent input.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neuroprinciples/computation/bill2015dis.pdf},
  journal  = {PLOS ONE},
  keywords = {Action potentials,Afferent neurons,Neural networks,Neuronal plasticity,Neuronal tuning,Neurons,Synapses,Synaptic plasticity},
  month    = aug,
  year     = {2015},
}

@Article{liTensorproductkernelFrameworkMultiscale2014a,
  author   = {Li, L. and Brockmeier, A. J. and Choi, J. S. and Francis, J. T. and Sanchez, J. C. and Principe, J. C.},
  title    = {A Tensor-Product-Kernel Framework for Multiscale Neural Activity Decoding and Control},
  doi      = {10.1155/2014/870160},
  issn     = {1687-5273 (Electronic)},
  pages    = {870160},
  volume   = {2014},
  abstract = {Brain machine interfaces (BMIs) have attracted intense attention as a promising technology for directly interfacing computers or prostheses with the brain's motor and sensory areas, thereby bypassing the body. The availability of multiscale neural recordings including spike trains and local field potentials (LFPs) brings potential opportunities to enhance computational modeling by enriching the characterization of the neural system state. However, heterogeneity on data type (spike timing versus continuous amplitude signals) and spatiotemporal scale complicates the model integration of multiscale neural activity. In this paper, we propose a tensor-product-kernel-based framework to integrate the multiscale activity and exploit the complementary information available in multiscale neural activity. This provides a common mathematical framework for incorporating signals from different domains. The approach is applied to the problem of neural decoding and control. For neural decoding, the framework is able to identify the nonlinear functional relationship between the multiscale neural responses and the stimuli using general purpose kernel adaptive filtering. In a sensory stimulation experiment, the tensor-product-kernel decoder outperforms decoders that use only a single neural data type. In addition, an adaptive inverse controller for delivering electrical microstimulation patterns that utilizes the tensor-product kernel achieves promising results in emulating the responses to natural stimulation.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/multiModal/neuroNetworkRelationship_nnr/methods/li2014a.pdf},
  journal  = {Comput Intell Neurosci},
  keywords = {*Models; Neurological,*Signal Processing; Computer-Assisted,Action Potentials/*physiology,Animals,Brain-Computer Interfaces,Brain/*cytology,Computer Simulation,Electric Stimulation,Evoked Potentials/physiology,Female,Fingers/innervation,Humans,Neurons/*physiology,Rats,Rats; Long-Evans,Touch},
  month    = jan,
  year     = {2014},
}

@Article{anastassiouEphapticCouplingCortical2011,
  author    = {Anastassiou, Costas A. and Perin, Rodrigo and Markram, Henry and Koch, Christof},
  title     = {Ephaptic Coupling of Cortical Neurons},
  doi       = {10.1038/nn.2727},
  issn      = {1546-1726},
  language  = {en},
  number    = {2},
  pages     = {217--223},
  volume    = {14},
  abstract  = {Ephaptic coupling is the feedback of extracellular fields onto the electrical potential across the neuronal membrane, independent of synapses. Here, the authors report that, under physiological conditions, endogenous brain activity can affect neural function through field effects.},
  copyright = {2011 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  journal   = {Nature Neuroscience},
  month     = feb,
  publisher = {{Nature Publishing Group}},
  year      = {2011},
}
% == BibTeX quality report for douglasCanonicalMicrocircuitNeocortex1989:
% ? Title looks like it was stored in title-case in Zotero

@Article{douglasMappingMatrixWays2007,
  author     = {Douglas, Rodney J. and Martin, Kevan A. C.},
  title      = {Mapping the {{Matrix}}: {{The Ways}} of {{Neocortex}}},
  doi        = {10.1016/j.neuron.2007.10.017},
  issn       = {0896-6273},
  language   = {en},
  number     = {2},
  pages      = {226--238},
  volume     = {56},
  abstract   = {While we know that the neocortex occupies 85\% of our brains and that its circuits allow an enormous flexibility and repertoire of behavior (not to mention unexplained phenomena like consciousness), a century after Cajal we have very little knowledge of the details of the cortical circuits or their mode of function. One simplifying hypothesis that has existed since Cajal is that the neocortex consists of repeated copies of the same fundamental circuit. However, finding that fundamental circuit has proved elusive, although partial drafts of a ``canonical circuit'' appear in many different guises of structure and function. Here, we review some critical stages in the history of this quest. In doing so, we consider the style of cortical computation in relation to the neuronal machinery that supports it. We conclude that the structure and function of cortex honors two major computational principles: ``just-enough'' and ``just-in-time.''},
  journal    = {Neuron},
  month      = oct,
  shorttitle = {Mapping the {{Matrix}}},
  year       = {2007},
}
% == BibTeX quality report for fevotteMajorizationminimizationAlgorithmSmooth2011:
% ? Unsure about the formatting of the booktitle

@Article{fevotteNonnegativeMatrixFactorization2009,
  author     = {F{\'e}votte, C. and Bertin, N. and Durrieu, J.},
  title      = {Nonnegative {{Matrix Factorization}} with the {{Itakura}}-{{Saito Divergence}}: {{With Application}} to {{Music Analysis}}},
  doi        = {10.1162/neco.2008.04-08-771},
  issn       = {0899-7667},
  number     = {3},
  pages      = {793--830},
  volume     = {21},
  abstract   = {This letter presents theoretical, algorithmic, and experimental results about nonnegative matrix factorization (NMF) with the Itakura-Saito (IS) divergence. We describe how IS-NMF is underlaid by a well-defined statistical model of superimposed gaussian components and is equivalent to maximum likelihood estimation of variance parameters. This setting can accommodate regularization constraints on the factors through Bayesian priors. In particular, inverse-gamma and gamma Markov chain priors are considered in this work. Estimation can be carried out using a space-alternating generalized expectation-maximization (SAGE) algorithm; this leads to a novel type of NMF algorithm, whose convergence to a stationary point of the IS cost function is guaranteed. We also discuss the links between the IS divergence and other cost functions used in NMF, in particular, the Euclidean distance and the generalized Kullback-Leibler (KL) divergence. As such, we describe how IS-NMF can also be performed using a gradient multiplicative algorithm (a standard algorithm structure in NMF) whose convergence is observed in practice, though not proven. Finally, we report a furnished experimental comparative study of Euclidean-NMF, KL-NMF, and IS-NMF algorithms applied to the power spectrogram of a short piano sequence recorded in real conditions, with various initializations and model orders. Then we show how IS-NMF can successfully be employed for denoising and upmix (mono to stereo conversion) of an original piece of early jazz music. These experiments indicate that IS-NMF correctly captures the semantics of audio and is better suited to the representation of music signals than NMF with the usual Euclidean and KL costs.},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/dataAnalysis/factorization/nmf/fvotte2009non.pdf},
  journal    = {Neural Computation},
  month      = mar,
  shorttitle = {Nonnegative {{Matrix Factorization}} with the {{Itakura}}-{{Saito Divergence}}},
  year       = {2009},
}

@PhdThesis{leptourgosDynamicalCircularInference2018,
  author     = {Leptourgos, Pantelis},
  title      = {Dynamical Circular Inference in the General Population and the Psychosis Spectrum : Insights from Perceptual Decision Making},
  type       = {Thesis},
  abstract   = {Nous \'evoluons dans un monde incertain. De ce fait, notre survie d\'epend de notre capacit\'e \`a prendre rapidement des d\'ecisions, et ce de mani\`ere fiable et adaptative. Il est possible de mieux comprendre cette capacit\'e en consid\'erant la perception comme un processus d'inf\'erence probabiliste au cours duquel les informations sensorielles sont combin\'ees \`a nos attentes pour produire une interpr\'etation plausible de notre environnement. Les th\'eories r\'ecentes de psychiatrie computationnelle sugg\`erent par ailleurs que la grande variabilit\'e des troubles psychiatriques, au rang desquelles figure la schizophr\'enie, pourrait r\'esulter d'une alt\'eration de ces m\^emes processifs pr\'edictifs. L'Inf\'erence Circulaire est l'une de ces th\'eories. Ce cadre de pens\'ee stipule qu'une propagation incontr\^ol\'ee d'information dans la hi\'erarchie corticale pourrait g\'en\'erer des percepts ou des croyances aberrantes. Afin d'explorer le r\^ole jou\'e par l'Inf\'erence Circulaire en condition normale ou pathologique, ce travail de th\`ese s'est appuy\'e sur des t\^aches de prise de d\'ecision en conditions perceptives ambig\"ues. Dans une premi\`ere partie, nous nous sommes int\'eress\'es au r\^ole jou\'e par la circularit\'e dans la perception bistable. Le ph\'enom\`ene de bistabilit\'e survient lorsque deux interpr\'etations se succ\`edent \`a intervalle r\'egulier pour un m\^eme percept. Nous pr\'esentons les r\'esultats d'une t\^ache conduite en population saine o\`u nous avons manipul\'e les informations sensorielles et \`a priori utilis\'ees par les participants lors de la visualisation d'un cube de Necker (article 1). Nous avons pu montrer un effet propre \`a chaque manipulation, mais \'egalement une interaction entre ces deux sources d'information, incompatible avec une int\'egration Bay\'esienne optimale. R\'esultat confirm\'e par la comparaison de divers mod\`eles computationnels ajust\'es aux donn\'ees, qui a pu mettre en \'evidence la sup\'eriorit\'e de l'Inf\'erence Circulaire sur les mod\`eles Bay\'esiens classiques. Nous avons ensuite voulu tester un mod\`ele fonctionnel de la bistabilit\'e (article 2). Nous avons donc d\'eriv\'e la dynamique du mod\`ele et montr\'e que la pr\'esence de boucles descendantes dans la hi\'erarchie corticale, transformait ce qui \'etait jusque l\`a un int\'egrateur imparfait du bruit sensoriel en mod\`ele \`a attracteur bistable. Ce mod\`ele ne reproduit pas seulement le ph\'enom\`ene de bistabilit\'e, mais \'egalement l'ensemble de ces caract\'eristiques ph\'enom\'enologiques. Dans un 3\`eme article, nous avons test\'e une pr\'ediction, notamment en cas de pr\'esentation discontinue d'un stimulus bistable. Deux exp\'eriences compl\'ementaires utilisant un paradigme de pr\'esentation intermittente du cube de Necker ont donc \'et\'e conduites en population g\'en\'erale. Nos r\'esultats \'etaient compatible avec les pr\'edictions faites par le mod\`ele de l'Inf\'erence Circulaire Dynamique, sugg\'erant que la circularit\'e puisse \^etre un m\'ecanisme g\'en\'erique \`a l'origine de notre fa\c{c}on de voir le monde. Dans la seconde partie de ce travail, nous avons \'etudi\'e l'Inf\'erence Circulaire en condition pathologique, notamment lors d'exp\'eriences psychotiques (schizophr\'enie, psych\'ed\'eliques). Nous avons utilis\'e la perception bistable pour explorer les m\'ecanismes computationnels \`a l'\oe uvre dans la schizophr\'enie (article 4,5). Nous avons compar\'e les performances de patients pr\'esentant des sympt\^omes psychotiques \`a des t\'emoins sains appari\'es lors d'une t\^ache de perception bistable. Nous avons pu montrer chez les patients une amplification des informations sensorielles combin\'ee \`a une surestimation de la volatilit\'e environnementale. Enfin nous terminons ce travail en proposant une approche transversale de l'effet des psych\'ed\'eliques (article 6), sur la base des r\'esultats pr\'ec\'edents et de la sp\'ecificit\'e clinique de ces exp\'eriences sensorielles cross-modales, afin de relier l'\'echelle macroscopique (i.e., comportement et ph\'enom\'enologie), m\'esoscopique (i.e., les boucles inf\'erentielles) et microscopique (i.e., les diff\'erents neurotransmetteurs impliqu\'es aboutissant \`a un microcircuit canonique).},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/psychiatry/cmpsy/objectives/leptourgos2018dyn.pdf},
  keywords   = {Bistable perception,Circular Inference,Cube de Necker,Inference Circulaire,Necker Cube,Neurosciences,Neurosciences et sciences cognitives,Perception bistable,Psychedelics,Psychedeliques,Psychose,Psychosis,Schizophrenia,Schizophrenie,Sciences cognitives},
  month      = nov,
  school     = {Paris Sciences et Lettres},
  shorttitle = {Dynamical Circular Inference in the General Population and the Psychosis Spectrum},
  year       = {2018},
}

@Book{malsburgMalsburgDynamicCoordination2010,
  author     = {Malsburg, Christoph Von Der and Phillips, William A. and Singer, W.},
  title      = {Malsburg, {{C}}: {{Dynamic Coordination}} in the {{Brain}} - {{From Neuron}}: {{From Neurons}} to {{Mind}}},
  edition    = {Illustrated edition},
  isbn       = {978-0-262-01471-7},
  language   = {English},
  publisher  = {{The MIT Press}},
  abstract   = {An examination of how widely distributed and specialized activities of the brain are flexibly and effectively coordinated.A fundamental shift is occurring in neuroscience and related disciplines. In the past, researchers focused on functional specialization of the brain, discovering complex processing strategies based on convergence and divergence in slowly adapting anatomical architectures. Yet for the brain to cope with ever-changing and unpredictable circumstances, it needs strategies with richer interactive short-term dynamics. Recent research has revealed ways in which the brain effectively coordinates widely distributed and specialized activities to meet the needs of the moment. This book explores these findings, examining the functions, mechanisms, and manifestations of distributed dynamical coordination in the brain and mind across different species and levels of organization. The book identifies three basic functions of dynamic coordination: contextual disambiguation, dynamic grouping, and dynamic routing. It considers the role of dynamic coordination in temporally structured activity and explores these issues at different levels, from synaptic and local circuit mechanisms to macroscopic system dynamics, emphasizing their importance for cognition, behavior, and psychopathology.ContributorsEvan Balaban, Gy\"orgy Buzs\'aki, Nicola S. Clayton, Maurizio Corbetta, Robert Desimone, Kamran Diba, Shimon Edelman, Andreas K. Engel, Yves Fregnac, Pascal Fries, Karl Friston, Ann Graybiel, Sten Grillner, Uri Grodzinski, John-Dylan Haynes, Laurent Itti, Erich D. Jarvis, Jon H. Kaas, J.A. Scott Kelso, Peter K\"onig, Nancy J. Kopell, Ilona Kov\'acs, Andreas Kreiter, Anders Lansner, Gilles Laurent, J\"org L\"ucke, Mikael Lundqvist, Angus MacDonald, Kevan Martin, Mayank Mehta, Lucia Melloni, Earl K. Miller, Bita Moghaddam, Hannah Monyer, Edvard I. Moser, May-Britt Moser, Danko Nikolic, William A. Phillips, Gordon Pipa, Constantin Rothkopf, Terrence J. Sejnowski, Steven M. Silverstein, Wolf Singer, Catherine Tallon-Baudry, Roger D. Traub, Jochen Triesch, Peter Uhlhaas, Christoph von der Malsburg, Thomas Weisswange, Miles Whittington, Matthew Wilson},
  address    = {{Cambridge, Mass}},
  month      = jul,
  shorttitle = {Malsburg, {{C}}},
  year       = {2010},
}
% == BibTeX quality report for hollandSignalsBoundariesBuilding2012a:
% ? Title looks like it was stored in title-case in Zotero

@Article{hollandStudyingComplexAdaptive2006,
  author   = {Holland, John H.},
  title    = {Studying {{Complex Adaptive Systems}}},
  doi      = {10.1007/s11424-006-0001-z},
  issn     = {1559-7067},
  language = {en},
  number   = {1},
  pages    = {1--8},
  volume   = {19},
  abstract = {Complex adaptive systems (cas) \textendash{} systems that involve many components that adapt or learn as they interact \textendash{} are at the heart of important contemporary problems. The study of cas poses unique challenges: Some of our most powerful mathematical tools, particularly methods involving fixed points, attractors, and the like, are of limited help in understanding the development of cas. This paper suggests ways to modify research methods and tools, with an emphasis on the role of computer-based models, to increase our understanding of cas.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/cas_ComplexAdaptiveSystems/holland2006stu.pdf},
  journal  = {Journal of Systems Science and Complexity},
  month    = mar,
  year     = {2006},
}
% == BibTeX quality report for safariSpikeLFPPhaseCoupling2019:
% ? Possibly abbreviated journal title arXiv:1903.00998 [cond-mat, physics:nlin]
% ? Title looks like it was stored in title-case in Zotero

@Article{safaviFrontalLobeInvolved2014,
  author    = {Safavi, Shervin and Kapoor, Vishal and Logothetis, Nikos K. and Panagiotaropoulos, Theofanis I.},
  title     = {Is the Frontal Lobe Involved in Conscious Perception?},
  doi       = {10.3389/fpsyg.2014.01063},
  issn      = {1664-1078},
  language  = {English},
  volume    = {5},
  abstract  = {Is the frontal lobe involved in conscious perception?},
  copyright = {All rights reserved},
  file      = {/home/ssafavi/Nextcloud/libraries/zoteroLib/safavi2014is.pdf},
  journal   = {Frontiers in Psychology},
  keywords  = {Binocular Rivalry,conscious visual perception,Electrophysiology,fMRI BOLD,Frontal Lobe,perceptual suppression,Prefrontal Cortex},
  year      = {2014},
}

@Article{lundComparisonIntrinsicConnectivity1993,
  author   = {Lund, Jennifer S. and Yoshioka, Takashi and Levitt, Jonathan B.},
  title    = {Comparison of {{Intrinsic Connectivity}} in {{Different Areas}} of {{Macaque Monkey Cerebral Cortex}}},
  doi      = {10.1093/cercor/3.2.148},
  issn     = {1047-3211, 1460-2199},
  language = {en},
  number   = {2},
  pages    = {148--162},
  volume   = {3},
  journal  = {Cerebral Cortex},
  year     = {1993},
}

@Article{dickeySingleUnitStabilityUsing2009,
  author    = {Dickey, Adam S. and Suminski, Aaron and Amit, Yali and Hatsopoulos, Nicholas G.},
  title     = {Single-{{Unit Stability Using Chronically Implanted Multielectrode Arrays}}},
  doi       = {10.1152/jn.90920.2008},
  issn      = {0022-3077},
  number    = {2},
  pages     = {1331--1339},
  volume    = {102},
  abstract  = {The use of chronic intracortical multielectrode arrays has become increasingly prevalent in neurophysiological experiments. However, it is not obvious whether neuronal signals obtained over multiple recording sessions come from the same or different neurons. Here, we develop a criterion to assess single-unit stability by measuring the similarity of 1) average spike waveforms and 2) interspike interval histograms (ISIHs). Neuronal activity was recorded from four Utah arrays implanted in primary motor and premotor cortices in three rhesus macaque monkeys during 10 recording sessions over a 15- to 17-day period. A unit was defined as stable through a given day if the stability criterion was satisfied on all recordings leading up to that day. We found that 57\% of the original units were stable through 7 days, 43\% were stable through 10 days, and 39\% were stable through 15 days. Moreover, stable units were more likely to remain stable in subsequent recording sessions (i.e., 89\% of the neurons that were stable through four sessions remained stable on the fifth). Using both waveform and ISIH data instead of just waveforms improved performance by reducing the number of false positives. We also demonstrate that this method can be used to track neurons across days, even during adaptation to a visuomotor rotation. Identifying a stable subset of neurons should allow the study of long-term learning effects across days and has practical implications for pooling of behavioral data across days and for increasing the effectiveness of brain\textendash machine interfaces.},
  journal   = {Journal of Neurophysiology},
  month     = aug,
  publisher = {{American Physiological Society}},
  year      = {2009},
}

@Article{bullmoreComplexBrainNetworks2009a,
  author   = {Bullmore, E. and Sporns, O.},
  title    = {Complex Brain Networks: Graph Theoretical Analysis of Structural and Functional Systems},
  doi      = {10.1038/nrn2575},
  issn     = {1471-0048 (Electronic) 1471-003X (Linking)},
  language = {en},
  number   = {3},
  pages    = {186--98},
  volume   = {10},
  abstract = {Recent developments in the quantitative analysis of complex networks, based largely on graph theory, have been rapidly translated to studies of brain network organization. The brain's structural and functional systems have features of complex networks--such as small-world topology, highly connected hubs and modularity--both at the whole-brain scale of human neuroimaging and at a cellular scale in non-human animals. In this article, we review studies investigating complex brain networks in diverse experimental modalities (including structural and functional MRI, diffusion tensor imaging, magnetoencephalography and electroencephalography in humans) and provide an accessible introduction to the basic principles of graph theory. We also highlight some of the technical challenges and key questions to be addressed by future developments in this rapidly moving field.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/brain/bullmore2009com.pdf},
  journal  = {Nat Rev Neurosci},
  keywords = {*Neural Networks (Computer),Animals,Brain Mapping/*methods,Brain/anatomy \& histology/*physiology,Computer Graphics/trends,Electroencephalography/methods,Humans,Image Processing; Computer-Assisted/*methods,Magnetic Resonance Imaging/methods,Magnetoencephalography/methods,Nerve Net/anatomy \& histology/*physiology,review},
  month    = mar,
  year     = {2009},
}

@Article{leopoldPrimaryVisualCortex2012,
  author     = {Leopold, David A.},
  title      = {Primary {{Visual Cortex}}: {{Awareness}} and {{Blindsight}}},
  doi        = {10.1146/annurev-neuro-062111-150356},
  number     = {1},
  pages      = {91--109},
  volume     = {35},
  abstract   = {The primary visual cortex (V1) is the principal telencephalic recipient of visual input in humans and monkeys. It is unique among cortical areas in that its destruction results in chronic blindness. However, certain patients with V1 damage, though lacking visual awareness, exhibit visually guided behavior: blindsight. This phenomenon, together with evidence from electrophysiological, neuroimaging, and psychophysical experiments, has led to speculation that V1 activity has a special or direct role in generating conscious perception. To explore this issue, this article reviews experiments that have used two powerful paradigms\textemdash stimulus-induced perceptual suppression and chronic V1 ablation\textemdash each of which disrupts the ability to perceive salient visual stimuli. Focus is placed on recent neurophysiological, behavioral, and functional imaging studies from the nonhuman primate that shed light on V1's role in conscious awareness. In addition, anatomical pathways that relay visual information to the cortex during normal vision and in blindsight are reviewed. Although the critical role of V1 in primate vision follows naturally from its position as a bottleneck of visual signals, little evidence supports its direct contribution to visual awareness.},
  annotation = {\_eprint: https://doi.org/10.1146/annurev-neuro-062111-150356},
  journal    = {Annual Review of Neuroscience},
  pmid       = {22715879},
  shorttitle = {Primary {{Visual Cortex}}},
  year       = {2012},
}
% == BibTeX quality report for NumericalTourData:
% ? Title looks like it was stored in title-case in Zotero

@Article{nurProbingSpatialInhomogeneity2019,
  author    = {Nur, Tazima and Gautam, Shree Hari and Stenken, Julie A. and Shew, Woodrow L.},
  title     = {Probing Spatial Inhomogeneity of Cholinergic Changes in Cortical State in Rat},
  doi       = {10.1038/s41598-019-45826-4},
  issn      = {2045-2322},
  language  = {En},
  number    = {1},
  pages     = {9387},
  volume    = {9},
  abstract  = {Acetylcholine (ACh) plays an essential role in cortical information processing. Cholinergic changes in cortical state can fundamentally change how the neurons encode sensory input and motor output. Traditionally, ACh distribution in cortex and associated changes in cortical state have been assumed to be spatially diffuse. However, recent studies demonstrate a more spatially inhomogeneous structure of cholinergic projections to cortex. Moreover, many experimental manipulations of ACh have been done at a single spatial location, which inevitably results in spatially non-uniform ACh distribution. Such non-uniform application of ACh across the spatial extent of a cortical microcircuit could have important impacts on how the firing of groups of neurons is coordinated, but this remains largely unknown. Here we describe a method for applying ACh at different spatial locations within a single cortical circuit and measuring the resulting differences in population neural activity. We use two microdialysis probes implanted at opposite ends of a microelectrode array in barrel cortex of anesthetized rats. As a demonstration of the method, we applied ACh or neostigmine in different spatial locations via the microdialysis probes while we concomitantly recorded neural activity at 32 locations with the microelectrode array. First, we show that cholinergic changes in cortical state can vary dramatically depending on where the ACh was applied. Second, we show that cholinergic changes in cortical state can vary dramatically depending on where the state-change is measured. These results suggests that previous work with single-site recordings or single-site ACh application should be interpreted with some caution, since the results could change for different spatial locations.},
  copyright = {2019 The Author(s)},
  file      = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/criticality/nur2019pro.pdf},
  journal   = {Scientific Reports},
  month     = jun,
  year      = {2019},
}

@InCollection{chowdhuryImmuneNetworkExample1999,
  author     = {Chowdhury, Debashish},
  booktitle  = {Artificial {{Immune Systems}} and {{Their Applications}}},
  title      = {Immune {{Network}}: {{An Example}} of {{Complex Adaptive Systems}}},
  doi        = {10.1007/978-3-642-59901-9_5},
  editor     = {Dasgupta, Dipankar},
  isbn       = {978-3-642-59901-9},
  language   = {en},
  pages      = {89--104},
  publisher  = {{Springer}},
  abstract   = {The phenomenon of immunological memory has been known for a long time. But, the unEnrlying mechanism is poorly unEnrstood. According to the theory of clonal selection the response to a specific invading antigen (e.g., bacteria) is offered by a specific clone of the cells. Some of the lymphocytes activated during the primary response remain dormant and keep circulating in the immune system for a long time carrying the memory of the encounter and, therefore, these long-lived cells are called memory cells. Proponents of the alternative network theory maintain that the immune response is offered by a ``network'' of clones in a collective manner. In recent years several possible scenarios of the ``structure'' and function of the immune network have been consiEnred. We have Enveloped mathematical Models for Enscribing the population dynamics of the immunocompetent cells in a unified manner. We have incorporated intra-clonal as well as inter-clonal interactions in a discrete formulation and also studied a continuum version of this Model.},
  address    = {{Berlin, Heidelberg}},
  keywords   = {Artificial Immune System,Clonal Selection,Complex Adaptive System,Discrete Model,Human Immunodeficiency Virus},
  shorttitle = {Immune {{Network}}},
  year       = {1999},
}

@Article{atwalStatisticalMechanicsMultistable2014a,
  author   = {Atwal, G. S.},
  title    = {Statistical Mechanics of Multistable Perception},
  doi      = {10.1101/008177},
  language = {en},
  abstract = {The stochastic dynamics of multistable perception poses an enduring challenge to our understanding of neural signal processing in the brain. We show that the emergence of perception switching and stability can be understood using principles of probabilistic Bayesian inference where the prior temporal expectations are matched to a scale-free power spectrum, characteristic of fluctuations in the natural environment. The optimal percept dynamics are inferred by an exact mapping of the statistical estimation problem to the motion of a dissipative quantum particle in a multi-well potential. In the bistable case the problem is further mapped to a long-ranged Ising model. Optimal inference in the presence of a 1/f noise prior leads to critical dynamics, exhibiting a dynamical phase transition from unstable perception to stable perception, as demonstrated in recent experiments. The effect of stimulus fluctuations and perception bias is also discussed.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/c_onTabelPrince/atwal2014sta.pdf},
  journal  = {BioRxiv},
  keywords = {princNeuro},
  month    = aug,
  year     = {2014},
}

@Article{lumerNeuralCorrelatesPerceptual1998,
  author   = {Lumer, E. D. and Friston, K. J. and Rees, G.},
  title    = {Neural Correlates of Perceptual Rivalry in the Human Brain},
  doi      = {10.1126/science.280.5371.1930},
  issn     = {0036-8075 (Print) 0036-8075 (Linking)},
  language = {en},
  number   = {5371},
  pages    = {1930--4},
  volume   = {280},
  abstract = {When dissimilar images are presented to the two eyes, perception alternates spontaneously between each monocular view, a phenomenon called binocular rivalry. Functional brain imaging in humans was used to study the neural basis of these subjective perceptual changes. Cortical regions whose activity reflected perceptual transitions included extrastriate areas of the ventral visual pathway, and parietal and frontal regions that have been implicated in spatial attention; whereas the extrastriate areas were also engaged by nonrivalrous perceptual changes, activity in the frontoparietal cortex was specifically associated with perceptual alternation only during rivalry. These results suggest that frontoparietal areas play a central role in conscious perception, biasing the content of visual awareness toward abstract internal representations of visual scenes, rather than simply toward space.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/perception/multiStablePerception_msp/lumer1998neu.pdf},
  journal  = {Science},
  keywords = {*Visual Perception,Brain Mapping,Brain/physiology,Frontal Lobe/*physiology,Humans,Magnetic Resonance Imaging,Neurons/physiology,Parietal Lobe/*physiology,Space Perception,Vision; Binocular,Visual Cortex/*physiology},
  month    = jun,
  year     = {1998},
}

@Article{harrisNeuralSignaturesCell2005a,
  author   = {Harris, K. D.},
  title    = {Neural Signatures of Cell Assembly Organization},
  doi      = {10.1038/nrn1669},
  issn     = {1471-003X (Print) 1471-003X (Linking)},
  language = {en},
  number   = {5},
  pages    = {399--407},
  volume   = {6},
  abstract = {Cortical neurons show irregular but structured spike trains. This has been interpreted as evidence for 'temporal coding', whereby stimuli are represented by precise spike-timing patterns. Here, we suggest an alternative interpretation based on the older concept of the cell assembly. The dynamic evolution of assembly sequences, which are steered but not deterministically controlled by sensory input, is the proposed substrate of psychological processes beyond simple stimulus-response associations. Accordingly, spike trains show a temporal structure that is stimulus-dependent and more variable than would be predicted by strict sensory control. We propose four signatures of assembly organization that can be experimentally tested. We argue that many observations that have been interpreted as evidence for temporal coding might instead reflect an underlying assembly structure.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/projects/nnr/MT/harris2005neu.pdf},
  journal  = {Nat Rev Neurosci},
  keywords = {Action Potentials/*physiology,Animals,Cerebral Cortex/cytology/physiology,Hippocampus/cytology/physiology,Humans,Nerve Net/cytology/*physiology,Neurons/cytology/*physiology},
  month    = may,
  year     = {2005},
}

@Article{herrerasLocalFieldPotentials2016,
  author   = {Herreras, O.},
  title    = {Local {{Field Potentials}}: {{Myths}} and {{Misunderstandings}}},
  doi      = {10.3389/fncir.2016.00101},
  issn     = {1662-5110 (Electronic) 1662-5110 (Linking)},
  pages    = {101},
  volume   = {10},
  abstract = {The intracerebral local field potential (LFP) is a measure of brain activity that reflects the highly dynamic flow of information across neural networks. This is a composite signal that receives contributions from multiple neural sources, yet interpreting its nature and significance may be hindered by several confounding factors and technical limitations. By and large, the main factor defining the amplitude of LFPs is the geometry of the current sources, over and above the degree of synchronization or the properties of the media. As such, similar levels of activity may result in potentials that differ in several orders of magnitude in different populations. The geometry of these sources has been experimentally inaccessible until intracerebral high density recordings enabled the co-activating sources to be revealed. Without this information, it has proven difficult to interpret a century's worth of recordings that used temporal cues alone, such as event or spike related potentials and frequency bands. Meanwhile, a collection of biophysically ill-founded concepts have been considered legitimate, which can now be corrected in the light of recent advances. The relationship of LFPs to their sources is often counterintuitive. For instance, most LFP activity is not local but remote, it may be larger further from rather than close to the source, the polarity does not define its excitatory or inhibitory nature, and the amplitude may increase when source's activity is reduced. As technological developments foster the use of LFPs, the time is now ripe to raise awareness of the need to take into account spatial aspects of these signals and of the errors derived from neglecting to do so.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neurophysiology/lfp/herreras2016loc.pdf},
  journal  = {Front Neural Circuits},
  keywords = {cell assembly,Eeg,local field potentials,network oscillations,neuronal circuits,spatial discrimination,spontaneous activity,volume-conduction},
  pmcid    = {PMC5156830},
  year     = {2016},
}

@Article{junFullyIntegratedSilicon2017a,
  author   = {Jun, J. J. and Steinmetz, N. A. and Siegle, J. H. and Denman, D. J. and Bauza, M. and Barbarits, B. and Lee, A. K. and Anastassiou, C. A. and Andrei, A. and Aydin, C. and Barbic, M. and Blanche, T. J. and Bonin, V. and Couto, J. and Dutta, B. and Gratiy, S. L. and Gutnisky, D. A. and Hausser, M. and Karsh, B. and Ledochowitsch, P. and Lopez, C. M. and Mitelut, C. and Musa, S. and Okun, M. and Pachitariu, M. and Putzeys, J. and Rich, P. D. and Rossant, C. and Sun, W. L. and Svoboda, K. and Carandini, M. and Harris, K. D. and Koch, C. and O'Keefe, J. and Harris, T. D.},
  title    = {Fully Integrated Silicon Probes for High-Density Recording of Neural Activity},
  doi      = {10.1038/nature24636},
  issn     = {1476-4687 (Electronic) 0028-0836 (Linking)},
  pages    = {232--236},
  volume   = {551},
  abstract = {Sensory, motor and cognitive operations involve the coordinated action of large neuronal populations across multiple brain regions in both superficial and deep structures. Existing extracellular probes record neural activity with excellent spatial and temporal (sub-millisecond) resolution, but from only a few dozen neurons per shank. Optical Ca2+ imaging offers more coverage but lacks the temporal resolution needed to distinguish individual spikes reliably and does not measure local field potentials. Until now, no technology compatible with use in unrestrained animals has combined high spatiotemporal resolution with large volume coverage. Here we design, fabricate and test a new silicon probe known as Neuropixels to meet this need. Each probe has 384 recording channels that can programmably address 960 complementary metal-oxide-semiconductor (CMOS) processing-compatible low-impedance TiN sites that tile a single 10-mm long, 70 x 20-mum cross-section shank. The 6 x 9-mm probe base is fabricated with the shank on a single chip. Voltage signals are filtered, amplified, multiplexed and digitized on the base, allowing the direct transmission of noise-free digital data from the probe. The combination of dense recording sites and high channel count yielded well-isolated spiking activity from hundreds of neurons per probe implanted in mice and rats. Using two probes, more than 700 well-isolated single neurons were recorded simultaneously from five brain structures in an awake mouse. The fully integrated functionality and small size of Neuropixels probes allowed large populations of neurons from several brain structures to be recorded in freely moving animals. This combination of high-performance electrode technology and scalable chip fabrication methods opens a path towards recording of brain-wide neural activity during behaviour.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/unfiled/jun2017ful.pdf},
  journal  = {Nature},
  month    = nov,
  year     = {2017},
}
% == BibTeX quality report for buzsakiEmergenceCognitionAction2015:
% ? Title looks like it was stored in title-case in Zotero

@Misc{buzsakiHighfrequencyNetworkOscillation1992,
  author   = {Buzsaki, G. and Horvath, Z. and Urioste, R. and Hetke, J. and Wise, K.},
  title    = {High-Frequency Network Oscillation in the Hippocampus},
  abstract = {Pyramidal cells in the CA1 hippocampal region displayed transient network oscillations (200 hertz) during behavioral immobility, consummatory behaviors, and slow-wave sleep. Simultaneous, multisite recordings revealed temporal and spatial coherence of neuronal activity during population oscillations. Participating pyramidal cells discharged at a rate lower than the frequency of the population oscillation, and their action potentials were phase locked to the negative phase of the simultaneously recorded oscillatory field potentials. In contrast, interneurons discharged at population frequency during the field oscillations. Thus, synchronous output of cooperating CA1 pyramidal cells may serve to induce synaptic enhancement in target structures of the hippocampus.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/unfiled/buzsaki1992hig.pdf},
  journal  = {Science},
  keywords = {Action Potentials,Animals,Behavior; Animal/physiology,Cell Membrane/physiology,Electrophysiology,Hippocampus/*physiology,Interneurons/physiology,Male,Neurons/physiology,Periodicity,Pyramidal Tracts/physiology,Rats,Sleep/physiology,Synapses/physiology},
  month    = may,
  year     = {1992},
}

@Article{crickConsciousnessNeuroscience1998,
  author   = {Crick, F. and Koch, C.},
  title    = {Consciousness and Neuroscience},
  issn     = {1047-3211 (Print) 1047-3211 (Linking)},
  number   = {2},
  pages    = {97--107},
  volume   = {8},
  file     = {/Users/ssafavi/Documents/libraries/EndnoteLib_fromWin407/EndnoteLib_MPIPClocal_20170723.Data/PDF/1147098900/Crick-1998.pdf},
  journal  = {Cereb Cortex},
  keywords = {*Neurosciences,*Philosophy,Animals,Brain/*physiology,Consciousness/*physiology,Humans},
  month    = mar,
  year     = {1998},
}
% == BibTeX quality report for vogelsteinGeneralApproachProgressive2020:
% ? Possibly abbreviated journal title arXiv:2004.12908 [cs, stat]

@Article{vogesModelerViewSpatial2010,
  author   = {Voges, Nicole and Sch{\"u}z, Almut and Aertsen, Ad and Rotter, Stefan},
  title    = {A Modeler's View on the Spatial Structure of Intrinsic Horizontal Connectivity in the Neocortex},
  doi      = {10.1016/j.pneurobio.2010.05.001},
  issn     = {0301-0082},
  language = {en},
  number   = {3},
  pages    = {277--292},
  volume   = {92},
  abstract = {Most current computational models of neocortical networks assume a homogeneous and isotropic arrangement of local synaptic couplings between neurons. Sparse, recurrent connectivity is typically implemented with simple statistical wiring rules. For spatially extended networks, however, such random graph models are inadequate because they ignore the traits of neuron geometry, most notably various distance dependent features of horizontal connectivity. It is to be expected that such non-random structural attributes have a great impact, both on the spatio-temporal activity dynamics and on the biological function of neocortical networks. Here we review the neuroanatomical literature describing long-range horizontal connectivity in the neocortex over distances of up to eight millimeters, in various cortical areas and mammalian species. We extract the main common features from these data to allow for improved models of large-scale cortical networks. Such models include, next to short-range neighborhood coupling, also long-range patchy connections. We show that despite the large variability in published neuroanatomical data it is reasonable to design a generic model which generalizes over different cortical areas and mammalian species. Later on, we critically discuss this generalization, and we describe some examples of how to specify the model in order to adapt it to specific properties of particular cortical areas or species.},
  journal  = {Progress in Neurobiology},
  keywords = {Cortical network,Distant synapses,Patchy projections},
  month    = nov,
  year     = {2010},
}
% == BibTeX quality report for hollandInductionProcessesInference1989:
% ? Title looks like it was stored in title-case in Zotero

@Book{hollandSignalsBoundariesBuilding2012a,
  author     = {Holland, John H.},
  title      = {Signals and {{Boundaries}}: {{Building Blocks}} for {{Complex Adaptive Systems}}},
  edition    = {Illustrated edition},
  isbn       = {978-0-262-52593-0},
  language   = {English},
  publisher  = {{The MIT Press}},
  abstract   = {An overarching framework for comparing and steering complex adaptive systems is developed through understanding the mechanisms that generate their intricate signal/boundary hierarchies.Complex adaptive systems (cas), including ecosystems, governments, biological cells, and markets, are characterized by intricate hierarchical arrangements of boundaries and signals. In ecosystems, for example, niches act as semi-permeable boundaries, and smells and visual patterns serve as signals; governments have departmental hierarchies with memoranda acting as signals; and so it is with other cas. Despite a wealth of data and descriptions concerning different cas, there remain many unanswered questions about "steering" these systems. In Signals and Boundaries, John Holland argues that understanding the origin of the intricate signal/border hierarchies of these systems is the key to answering such questions. He develops an overarching framework for comparing and steering cas through the mechanisms that generate their signal/boundary hierarchies.Holland lays out a path for developing the framework that emphasizes agents, niches, theory, and mathematical models. He discusses, among other topics, theory construction; signal-processing agents; networks as representations of signal/boundary interaction; adaptation; recombination and reproduction; the use of tagged urn models (adapted from elementary probability theory) to represent boundary hierarchies; finitely generated systems as a way to tie the models examined into a single framework; the framework itself, illustrated by a simple finitely generated version of the development of a multi-celled organism; and Markov processes.},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/books/holland2014sig.pdf},
  keywords   = {Computers / Intelligence (AI) \& Semantics,Computers / Neural Networks,read},
  readstatus = {read},
  shorttitle = {Signals and {{Boundaries}}},
  year       = {2012},
}

@Article{douglasCanonicalMicrocircuitNeocortex1989,
  author    = {Douglas, Rodney J. and Martin, Kevan A.C. and Whitteridge, David},
  title     = {A {{Canonical Microcircuit}} for {{Neocortex}}},
  doi       = {10.1162/neco.1989.1.4.480},
  issn      = {0899-7667},
  number    = {4},
  pages     = {480--488},
  volume    = {1},
  abstract  = {We have used microanatomy derived from single neurons, and in vivo intracellular recordings to develop a simplified circuit of the visual cortex. The circuit explains the intracellular responses to pulse stimulation in terms of the interactions between three basic populations of neurons, and reveals the following features of cortical processing that are important to computational theories of neocortex. First, inhibition and excitation are not separable events. Activation of the cortex inevitably sets in motion a sequence of excitation and inhibition in every neuron. Second, the thalamic input does not provide the major excitation arriving at any neuron. Instead the intracortical excitatory connections provide most of the excitation. Third, the time evolution of excitation and inhibition is far longer than the synaptic delays of the circuits involved. This means that cortical processing cannot rely on precise timing between individual synaptic inputs.},
  journal   = {Neural Computation},
  month     = dec,
  publisher = {{MIT Press}},
  year      = {1989},
}

@Article{stephanTranslationalPerspectivesComputational2015,
  author     = {Stephan, Klaas E. and Iglesias, Sandra and Heinzle, Jakob and Diaconescu, Andreea O.},
  title      = {Translational {{Perspectives}} for {{Computational Neuroimaging}}},
  doi        = {10.1016/j.neuron.2015.07.008},
  issn       = {0896-6273},
  language   = {en},
  number     = {4},
  pages      = {716--732},
  volume     = {87},
  abstract   = {Functional neuroimaging has made fundamental contributions to our understanding of brain function. It remains challenging, however, to translate these advances into diagnostic tools for psychiatry. Promising new avenues for translation are provided by computational modeling of neuroimaging data. This article reviews contemporary frameworks for computational neuroimaging, with a focus on forward models linking unobservable brain states to measurements. These approaches\textemdash biophysical network models, generative models, and model-based fMRI analyses of neuromodulation\textemdash strive to move beyond statistical characterizations and toward mechanistic explanations of neuroimaging data. Focusing on schizophrenia as a paradigmatic spectrum disease, we review applications of these models to psychiatric questions, identify methodological challenges, and highlight trends of convergence among computational neuroimaging approaches. We conclude by outlining a translational neuromodeling strategy, highlighting the importance of openly available datasets from prospective patient studies for evaluating the clinical utility of computational models.},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/psychiatry/cmpsy/stephan2015tra.pdf},
  journal    = {Neuron},
  keywords   = {read,review},
  month      = aug,
  readstatus = {read},
  year       = {2015},
}

@Article{sussilloNeuralCircuitsComputational2014,
  author     = {Sussillo, D.},
  title      = {Neural Circuits as Computational Dynamical Systems},
  doi        = {10.1016/j.conb.2014.01.008},
  issn       = {1873-6882 (Electronic) 0959-4388 (Linking)},
  language   = {English},
  pages      = {156--63},
  volume     = {25},
  abstract   = {Many recent studies of neurons recorded from cortex reveal complex temporal dynamics. How such dynamics embody the computations that ultimately lead to behavior remains a mystery. Approaching this issue requires developing plausible hypotheses couched in terms of neural dynamics. A tool ideally suited to aid in this question is the recurrent neural network (RNN). RNNs straddle the fields of nonlinear dynamical systems and machine learning and have recently seen great advances in both theory and application. I summarize recent theoretical and technological advances and highlight an example of how RNNs helped to explain perplexing high-dimensional neurophysiological data in the prefrontal cortex.},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/unfiled/sussillo2014neu.pdf},
  journal    = {Curr Opin Neurobiol},
  keywords   = {*Models; Neurological,*Neural Networks (Computer),Animals,Humans,Nerve Net/*physiology,Prefrontal Cortex/*physiology,read},
  month      = apr,
  readstatus = {read},
  year       = {2014},
}

@Article{tononiInformationIntegrationTheory2004,
  author   = {Tononi, G.},
  title    = {An Information Integration Theory of Consciousness},
  doi      = {10.1186/1471-2202-5-42},
  issn     = {1471-2202 (Electronic) 1471-2202 (Linking)},
  pages    = {42},
  volume   = {5},
  abstract = {BACKGROUND: Consciousness poses two main problems. The first is understanding the conditions that determine to what extent a system has conscious experience. For instance, why is our consciousness generated by certain parts of our brain, such as the thalamocortical system, and not by other parts, such as the cerebellum? And why are we conscious during wakefulness and much less so during dreamless sleep? The second problem is understanding the conditions that determine what kind of consciousness a system has. For example, why do specific parts of the brain contribute specific qualities to our conscious experience, such as vision and audition? PRESENTATION OF THE HYPOTHESIS: This paper presents a theory about what consciousness is and how it can be measured. According to the theory, consciousness corresponds to the capacity of a system to integrate information. This claim is motivated by two key phenomenological properties of consciousness: differentiation - the availability of a very large number of conscious experiences; and integration - the unity of each such experience. The theory states that the quantity of consciousness available to a system can be measured as the Phi value of a complex of elements. Phi is the amount of causally effective information that can be integrated across the informational weakest link of a subset of elements. A complex is a subset of elements with Phi{$>$}0 that is not part of a subset of higher Phi. The theory also claims that the quality of consciousness is determined by the informational relationships among the elements of a complex, which are specified by the values of effective information among them. Finally, each particular conscious experience is specified by the value, at any given time, of the variables mediating informational interactions among the elements of a complex. TESTING THE HYPOTHESIS: The information integration theory accounts, in a principled manner, for several neurobiological observations concerning consciousness. As shown here, these include the association of consciousness with certain neural systems rather than with others; the fact that neural processes underlying consciousness can influence or be influenced by neural processes that remain unconscious; the reduction of consciousness during dreamless sleep and generalized seizures; and the time requirements on neural interactions that support consciousness. IMPLICATIONS OF THE HYPOTHESIS: The theory entails that consciousness is a fundamental quantity, that it is graded, that it is present in infants and animals, and that it should be possible to build conscious artifacts.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/integratedInformationTheory_iit/tononi2004an.pdf},
  journal  = {BMC Neuroscience},
  keywords = {*Consciousness,*Information Theory,Afferent Pathways,Brain/*physiology,Humans,Motor Activity,Neurons/physiology,Systems Integration,Thalamus/physiology},
  month    = nov,
  year     = {2004},
}

@Article{varleyDifferentialEffectsPropofol2020,
  author    = {Varley, Thomas F. and Sporns, Olaf and Puce, Aina and Beggs, John},
  title     = {Differential {{Effects}} of {{Propofol}} and {{Ketamine}} on {{Critical Brain Dynamics}}},
  doi       = {10.1101/2020.03.27.012070},
  language  = {en},
  pages     = {2020.03.27.012070},
  abstract  = {{$<$}p{$>$}Whether the brain operates at a critical "tipping" point is a long standing scientific question, with evidence from both cellular and systems-scale studies suggesting that the brain does sit in, or near, a critical regime. Neuroimaging studies of humans in altered states of consciousness have prompted the suggestion that maintenance of critical dynamics is necessary for the emergence of consciousness and complex cognition, and that reduced or disorganized consciousness may be associated with deviations from criticality. Unfortunately, many of the cellular-level studies reporting signs of criticality were performed in non-conscious systems (in vitro neuronal cultures) or unconscious animals (e.g. anaesthetized rats). Here we attempted to address this knowledge gap by exploring critical brain dynamics in invasive ECoG recordings from multiple sessions with a single macaque as the animal transitioned from consciousness to unconsciousness under different anaesthetics (ketamine and propofol). We use a previously-validated test of criticality: avalanche dynamics to assess the differences in brain dynamics between normal consciousness and both drug-states. Propofol and ketamine were selected due to their differential effects on consciousness (ketamine, but not propofol, is known to induce an exotic state known as "dissociative anaesthesia"). Our analyses indicate that propofol dramatically restricted the size and duration of avalanches, while ketamine allowed for a more awake-like dynamic to persist. In addition, propofol, but not ketamine, triggered a large reduction in the complexity of brain dynamics. All states, however, showed some signs of persistent criticality when testing for exponent relations and universal shape-collapse. Further, maintenance of critical brain dynamics may be important for regulation and control of conscious awareness.{$<$}/p{$>$}},
  chapter   = {New Results},
  copyright = {\textcopyright{} 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
  journal   = {bioRxiv},
  month     = mar,
  publisher = {{Cold Spring Harbor Laboratory}},
  year      = {2020},
}

@Article{plenzOrganizingPrinciplesNeuronal2007,
  author     = {Plenz, D. and Thiagarajan, T. C.},
  title      = {The Organizing Principles of Neuronal Avalanches: Cell Assemblies in the Cortex?},
  doi        = {10.1016/j.tins.2007.01.005},
  issn       = {0166-2236 (Print) 0166-2236 (Linking)},
  language   = {English},
  pages      = {101--10},
  volume     = {30},
  abstract   = {Neuronal avalanches are spatiotemporal patterns of neuronal activity that occur spontaneously in superficial layers of the mammalian cortex under various experimental conditions. These patterns reflect fast propagation of local synchrony, display a rich spatiotemporal diversity and recur over several hours. The statistical organization of pattern sizes is invariant to the choice of spatial scale, demonstrating that the functional linking of cortical sites into avalanches occurs on all spatial scales with a fractal organization. These features suggest an underlying network of neuronal interactions that balances diverse representations with predictable recurrence, similar to what has been theorized for cell assembly formation. We propose that avalanches reflect the transient formation of cell assemblies in the cortex and discuss various models that provide mechanistic insights into the underlying dynamics, suggesting that they arise in a critical regime.},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/c_onTabelPrince/plenz2007the.pdf;/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neuralInteractions/plenz2007the.pdf},
  journal    = {Trends Neurosci},
  keywords   = {*Cortical Synchronization,Animals,Cell Communication/physiology,Cerebral Cortex/*cytology/*physiology,Humans,Models; Neurological,Neural Pathways/*cytology/physiology,Neurons/cytology/*physiology,r6,read,Signal Transduction/*physiology},
  month      = mar,
  readstatus = {read},
  year       = {2007},
}

@Article{chalkUnifiedTheoryEfficient2018,
  author   = {Chalk, Matthew and Marre, Olivier and Tka{\v c}ik, Ga{\v s}per},
  title    = {Toward a Unified Theory of Efficient, Predictive, and Sparse Coding},
  doi      = {10.1073/pnas.1711114115},
  issn     = {1091-6490},
  language = {eng},
  number   = {1},
  pages    = {186--191},
  volume   = {115},
  abstract = {A central goal in theoretical neuroscience is to predict the response properties of sensory neurons from first principles. To this end, "efficient coding" posits that sensory neurons encode maximal information about their inputs given internal constraints. There exist, however, many variants of efficient coding (e.g., redundancy reduction, different formulations of predictive coding, robust coding, sparse coding, etc.), differing in their regimes of applicability, in the relevance of signals to be encoded, and in the choice of constraints. It is unclear how these types of efficient coding relate or what is expected when different coding objectives are combined. Here we present a unified framework that encompasses previously proposed efficient coding models and extends to unique regimes. We show that optimizing neural responses to encode predictive information can lead them to either correlate or decorrelate their inputs, depending on the stimulus statistics; in contrast, at low noise, efficiently encoding the past always predicts decorrelation. Later, we investigate coding of naturalistic movies and show that qualitatively different types of visual motion tuning and levels of response sparsity are predicted, depending on whether the objective is to recover the past or predict the future. Our approach promises a way to explain the observed diversity of sensory neural responses, as due to multiple functional goals and constraints fulfilled by different cell types and/or circuits.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neuroprinciples/chalk2018tow_si.pdf;/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neuroprinciples/chalk2018tow.pdf},
  journal  = {Proceedings of the National Academy of Sciences of the United States of America},
  keywords = {efficient coding,information theory,neural coding,prediction,sparse coding},
  month    = jan,
  pmcid    = {PMC5776796},
  pmid     = {29259111},
  year     = {2018},
}

@Article{castellanoNonequilibriumPhaseTransition2000,
  author    = {Castellano, Claudio and Marsili, Matteo and Vespignani, Alessandro},
  title     = {Nonequilibrium {{Phase Transition}} in a {{Model}} for {{Social Influence}}},
  doi       = {10.1103/PhysRevLett.85.3536},
  number    = {16},
  pages     = {3536--3539},
  volume    = {85},
  abstract  = {We present extensive numerical simulations of the Axelrod's model for social influence, aimed at understanding the formation of cultural domains. This is a nonequilibrium model with short range interactions and a remarkably rich dynamical behavior. We study the phase diagram of the model and uncover a nonequilibrium phase transition separating an ordered (culturally polarized) phase from a disordered (culturally fragmented) one. The nature of the phase transition can be continuous or discontinuous depending on the model parameters. At the transition, the size of cultural regions is power-law distributed.},
  journal   = {Physical Review Letters},
  month     = oct,
  publisher = {{American Physical Society}},
  year      = {2000},
}
% == BibTeX quality report for marcenkoDistributionEigenvaluesSets1967:
% ? Title looks like it was stored in title-case in Zotero

@Article{marcenkoDistributionEigenvaluesSets1967a,
  author  = {Mar{\v c}enko, V A and Pastur, L A},
  title   = {Distribution of Eigenvalues for Some Sets of Random Matrices},
  doi     = {10.1070/SM1967v001n04ABEH001994},
  issn    = {0025-5734},
  number  = {4},
  pages   = {457--483},
  volume  = {1},
  journal = {Mathematics of the USSR-Sbornik},
  month   = apr,
  year    = {1967},
}

@Article{siegelmannComplexSystemsScience2010,
  author   = {Siegelmann, H. T.},
  title    = {Complex Systems Science and Brain Dynamics},
  doi      = {10.3389/fncom.2010.00007},
  issn     = {1662-5188 (Electronic) 1662-5188 (Linking)},
  language = {English},
  volume   = {4},
  abstract = {Brain systems with their complex and temporally intricate dynamics have been difficult to unravel and comprehend. While great advances have been made in understanding genetics, neural behavior, gra...},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/brain/siegelmann2010com.pdf},
  journal  = {Front Comput Neurosci},
  keywords = {Brain Dynamics,complex systems science},
  year     = {2010},
}

@Article{einevollScientificCaseBrain2019,
  author   = {Einevoll, Gaute T. and Destexhe, Alain and Diesmann, Markus and Gr{\"u}n, Sonja and Jirsa, Viktor and de Kamps, Marc and Migliore, Michele and Ness, Torbj{\o}rn V. and Plesser, Hans E. and Sch{\"u}rmann, Felix},
  title    = {The {{Scientific Case}} for {{Brain Simulations}}},
  doi      = {10.1016/j.neuron.2019.03.027},
  issn     = {0896-6273},
  language = {English},
  number   = {4},
  pages    = {735--744},
  volume   = {102},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/simulation/einevoll2019the.pdf},
  journal  = {Neuron},
  keywords = {brain simulation,model,network,neuron,simulation,simulator},
  month    = may,
  pmid     = {31121126},
  year     = {2019},
}
% == BibTeX quality report for munozColloquiumCriticalityDynamical2017:
% ? Possibly abbreviated journal title arXiv:1712.04499 [cond-mat, physics:nlin, physics:physics, q-bio]

@Article{munozColloquiumCriticalityDynamical2018,
  author     = {Mu{\~n}oz, Miguel A.},
  title      = {Colloquium: {{Criticality}} and Dynamical Scaling in Living Systems},
  doi        = {10.1103/RevModPhys.90.031001},
  number     = {3},
  pages      = {031001},
  volume     = {90},
  abstract   = {A celebrated and controversial hypothesis suggests that some biological systems\textemdash parts, aspects, or groups of them\textemdash may extract important functional benefits from operating at the edge of instability, halfway between order and disorder, i.e., in the vicinity of the critical point of a phase transition. Criticality has been argued to provide biological systems with an optimal balance between robustness against perturbations and flexibility to adapt to changing conditions as well as to confer on them optimal computational capabilities, large dynamical repertoires, unparalleled sensitivity to stimuli, etc. Criticality, with its concomitant scale invariance, can be conjectured to emerge in living systems as the result of adaptive and evolutionary processes that, for reasons to be fully elucidated, select for it as a template upon which further layers of complexity can rest. This hypothesis is suggestive as it proposes that criticality could constitute a general and common organizing strategy in biology stemming from the physics of phase transitions. However, despite its implications, this is still in its infancy state as a well-founded theory and, as such, it has elicited some skepticism. From the experimental side, the advent of high-throughput technologies has created new prospects in the exploration of biological systems, and empirical evidence in favor of criticality has proliferated, with examples ranging from endogenous brain activity and gene-expression patterns to flocks of birds and insect-colony foraging, to name but a few. Some pieces of evidence are quite remarkable, while in some other cases empirical data are limited, incomplete, or not fully convincing. More stringent experimental setups and theoretical analyses are certainly needed to fully clarify the picture. In any case, the time seems ripe for bridging the gap between this theoretical conjecture and its empirical validation. Given the profound implications of shedding light on this issue, it is both pertinent and timely to review the state of the art and to discuss future strategies and perspectives.},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/criticality/muoz2018col.pdf},
  journal    = {Reviews of Modern Physics},
  keywords   = {read,review},
  month      = jul,
  readstatus = {read},
  shorttitle = {Colloquium},
  year       = {2018},
}
% == BibTeX quality report for heinAlgorithmicApproachNatural2020:
% ? Title looks like it was stored in title-case in Zotero

@Article{heineTransdiagnosticHippocampalDamage2020,
  author   = {Heine, Josephine and Pr{\"u}{\ss}, Harald and Scheel, Michael and Brandt, Alexander U. and Gold, Stefan M. and Bartsch, Thorsten and Paul, Friedemann and Finke, Carsten},
  title    = {Transdiagnostic Hippocampal Damage Patterns in Neuroimmunological Disorders},
  doi      = {10.1016/j.nicl.2020.102515},
  issn     = {2213-1582},
  language = {en},
  pages    = {102515},
  volume   = {28},
  abstract = {Hippocampal damage and associated cognitive deficits are frequently observed in neuroimmunological disorders, but comparative analyses to identify shared hippocampal damage patterns are missing. Here, we adopted a transdiagnostic analytical approach and investigated hippocampal shape deformations and associated cognitive deficits in four neuroimmunological diseases. We studied 120 patients (n~=~30 in each group), including patients with multiple sclerosis (MS), neuromyelitis optica spectrum disorder (NMOSD), anti-NMDAR and anti-LGI1 encephalitis. A control group was matched to each patient sample from a pool of 79 healthy participants. We performed an MRI-based vertex-wise hippocampal shape analysis, extracted hippocampal volume estimates and scalar projection values as a measure of surface displacement. Cognitive testing included assessment of verbal memory and semantic fluency performance. Our cross-sectional analyses revealed characteristic patterns of bilateral inward deformations covering up to 32\% of the hippocampal surface in MS, anti-NMDAR encephalitis, and anti-LGI1 encephalitis, whereas NMOSD patients showed no deformations compared to controls. Significant inversions were noted mainly on the hippocampal head, were accompanied by volume loss, and correlated with semantic fluency scores and verbal episodic memory in autoimmune encephalitis and MS. A deformation overlap analysis across disorders revealed a convergence zone on the left anterior hippocampus that corresponds to the CA1 subfield. This convergence zone indicates a shared downstream substrate of immune-mediated damage that appears to be particularly vulnerable to neuroinflammatory processes. Our transdiagnostic morphological view sheds light on mutual pathophysiologic pathways of cognitive deficits in neuroimmunological diseases and stimulates further research into the mechanisms of increased susceptibility of the hippocampus to autoimmunity.},
  journal  = {NeuroImage: Clinical},
  keywords = {Autoimmune encephalitis,Hippocampal shape,Memory disorders,Multiple sclerosis,Neuroinflammation,Neuromyelitis optica spectrum disorder},
  month    = jan,
  year     = {2020},
}

@Article{zareiIntroducingComprehensiveFramework2018,
  author   = {Zarei, Mohammad and Jahed, Mehran and Daliri, Mohammad Reza},
  title    = {Introducing a {{Comprehensive Framework}} to {{Measure Spike}}-{{LFP Coupling}}},
  doi      = {10.3389/fncom.2018.00078},
  issn     = {1662-5188},
  language = {English},
  volume   = {12},
  abstract = {Measuring the coupling of single neuron's spiking activities to the local field potentials (LFPs) is a method to investigate neuronal synchronization. The most important synchronization measures are phase locking value (PLV), spike field coherence (SFC) and pairwise phase consistency (PPC). Synchronization is generally quantified using the PLV and SFC. PLV and SFC methods are either biased on the spike rates or the number of trials. To solve these problems the PPC measure has been introduced. However, there are some shortcomings associated to the PPC measure. PPC is unbiased only for very high spike rates while measuring spike-LFP phase coupling (SPC) in short trials or for low number of spikes is considered a critical phenomenon in many studies. This study proposes a new framework for predicting a more reliable SPC by modeling and introducing appropriate machine learning algorithms for neurons with low spike rates. The results show that this framework significantly enhances the accuracy and provides a bias-free basis for small number of spikes for SPC as compared to the conventional methods such as PLV method. As such, it has the general ability to correct for the bias on number of spike rates.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/multiModal/neuroNetworkRelationship_nnr/methods/zarei2018int.pdf},
  journal  = {Frontiers in Computational Neuroscience},
  keywords = {Local Field Potentials,pairwise phase consistency,Phase Locking Value,spike field coherence,Spike-LFP Phase Coupling},
  year     = {2018},
}

@Book{quianquirogaPrinciplesNeuralCoding2013,
  title     = {Principles of Neural Coding},
  editor    = {Quian Quiroga, Rodrigo and Panzeri, Stefano},
  isbn      = {978-1-4398-5330-6},
  publisher = {{CRC Press}},
  address   = {{Boca Raton}},
  keywords  = {Models; Neurological,Nerve Net,Neurons,physiology,Synaptic Transmission},
  lccn      = {QP356.25 .P75 2013},
  year      = {2013},
}

@Article{johnsonSinglecellMembranePotential2019,
  author    = {Johnson, James K. and Wright, Nathaniel C. and Xia, Ji and Wessel, Ralf},
  title     = {Single-Cell Membrane Potential Fluctuations Evince Network Scale-Freeness and Quasicriticality},
  doi       = {10.1523/JNEUROSCI.3163-18.2019},
  issn      = {0270-6474, 1529-2401},
  language  = {en},
  pages     = {3163--18},
  abstract  = {What information single neurons receive about general neural circuit activity is a fundamental question for neuroscience. Somatic membrane potential fluctuations are driven by the convergence of synaptic inputs from a diverse cross-section of upstream neurons. Furthermore, neural activity is often scale-free implying that some measurements should be the same, whether taken at large or small scales. Together, convergence and scale-freeness support the hypothesis that single membrane potential recordings carry useful information about high-dimensional cortical activity. Conveniently, the theory of ``critical branching networks'' (one purported explanation for scale-freeness) provides testable predictions about scale-free measurements which are readily applied to membrane potential fluctuations. To investigate, we obtained whole-cell current clamp recordings of pyramidal neurons in visual cortex of turtles with unknown genders. We isolated fluctuations in membrane potential below the firing threshold and analyzed them by adapting the definition of ``neuronal avalanches'' (spurts of population spiking). The membrane potential fluctuations we analyzed were scale-free and consistent with critical branching. These findings recapitulated results from large-scale cortical population data obtained separately in complementary experiments using microelectrode arrays (previously published (Shew et al., 2015)). Simultaneously recorded single-unit local field potential did not provide a good match, demonstrating the specific utility of membrane potential. Modeling shows that estimation of dynamical network properties from neuronal inputs is most accurate when networks are structured as critical branching networks. In conclusion, these findings extend evidence of critical phenomena while also establishing subthreshold pyramidal neuron membrane potential fluctuations as an informative gauge of high-dimensional cortical population activity. SIGNIFICANCE STATEMENT The relationship between membrane potential dynamics of single neurons and population dynamics is indispensable to understanding cortical circuits. Just as important to the biophysics of computation are emergent properties such as scale-freeness, where critical branching networks offer insight. This report makes progress on both fronts by comparing statistics from single-neuron whole-cell recordings to population statistics obtained with microelectrode arrays. Not only are fluctuations of somatic membrane potential scale-free, they match fluctuations of population activity. Thus, our results demonstrate appropriation of the brain's own subsampling method (convergence of synaptic inputs), while extending the range of fundamental evidence for critical phenomena in neural systems from the previously observed mesoscale (fMRI, LFP, population spiking) to the microscale, namely, membrane potential fluctuations.},
  copyright = {Copyright \textcopyright{} 2019 the authors},
  file      = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/criticality/johnson2019sin.pdf},
  journal   = {Journal of Neuroscience},
  keywords  = {balanced networks,membrane potential,neural computation,neuronal avalanches,renormalization group,scale-free},
  month     = apr,
  pmid      = {30952810},
  year      = {2019},
}

@Article{fukushimaStudyingBrainFunctions2015,
  author     = {Fukushima, Makoto and Chao, Zenas C and Fujii, Naotaka},
  title      = {Studying Brain Functions with Mesoscopic Measurements: {{Advances}} in Electrocorticography for Non-Human Primates},
  doi        = {10.1016/j.conb.2015.03.015},
  issn       = {0959-4388},
  pages      = {124--131},
  series     = {Large-{{Scale Recording Technology}} (32)},
  volume     = {32},
  abstract   = {Our brain is organized in a modular structure. Information in different modalities is processed within distinct cortical areas. However, individual cortical areas cannot enable complex cognitive functions without interacting with other cortical areas. Electrocorticography (ECoG) has recently become an important tool for studying global network activity across cortical areas in animal models. With stable recordings of electrical field potentials from multiple cortical areas, ECoG provides an opportunity to systematically study large-scale cortical activity at a mesoscopic spatiotemporal resolution under various experimental conditions. Recent developments in thin, flexible ECoG electrodes permit recording field potentials from not only gyral but intrasulcal cortical surfaces. Our review here focuses on the recent advances of ECoG applications to non-human primates.},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neurophysiology/largeScaleRecording/fukushima2015stu.pdf},
  journal    = {Current Opinion in Neurobiology},
  month      = jun,
  shorttitle = {Studying Brain Functions with Mesoscopic Measurements},
  year       = {2015},
}

@Article{isslerDeterminingRoleMicroRNAs2015,
  author    = {Issler, Orna and Chen, Alon},
  title     = {Determining the Role of {{microRNAs}} in Psychiatric Disorders},
  doi       = {10.1038/nrn3879},
  issn      = {1471-0048},
  language  = {en},
  number    = {4},
  pages     = {201--212},
  volume    = {16},
  abstract  = {Accumulating studies have revealed that patients with psychiatric disorders have altered microRNA (miRNA) expression profiles in the circulation and in relevant brain tissues. Furthermore, animal studies have shown that manipulating the levels of particular miRNAs in the brain can alter behaviour.The expression levels of some miRNAs change following certain behavioural or pharmacological challenges, thus facilitating a subsequent change in the expression of target genes, which are putatively needed in order to direct certain behavioural outcomes. It is also possible that miRNAs can serve as 'buffers' to keep levels of their protein targets stable and to avoid them being upregulated to pathological levels in response to a challenge.We discuss the pros and cons of the available molecular, biochemical, cellular and behavioural experimental approaches in both humans and rodents that are used for studying the role of miRNAs in psychiatric disorders. We also highlight example studies.We discuss future directions for studies examining the role of miRNAs in psychiatric disorders, emphasizing the importance of studies on both sexes, the need for utilizing proteomics analysis methods, the need for spatiotemporal expression maps of endogenous miRNAs in the developing and adult brain, and the need for testing miRNAs in specific cell types, circuits and subcellular fractions.Shedding light on the role of miRNAs in psychiatric disorders could lead to a better understanding of the molecular pathways that are disrupted in these disorders and possibly promote the much needed development of new therapeutic and diagnostic approaches.},
  copyright = {2015 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  journal   = {Nature Reviews Neuroscience},
  month     = apr,
  publisher = {{Nature Publishing Group}},
  year      = {2015},
}

@Book{lizierLocalInformationDynamics2013,
  author     = {Lizier, Joseph T.},
  title      = {The Local Information Dynamics of Distributed Computation in Complex Systems},
  isbn       = {978-3-642-32952-4 978-3-642-32951-7},
  language   = {eng},
  publisher  = {{Springer}},
  series     = {Springer Theses},
  address    = {{Berlin}},
  annotation = {OCLC: 842386534},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/books/lizier2013the.pdf;/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/lizier2013the.pdf},
  keywords   = {read},
  readstatus = {read},
  year       = {2013},
}
% == BibTeX quality report for tanakaPracticalSSVEPBasedAlgorithm2018:
% ? Title looks like it was stored in title-case in Zotero

@Article{tanakaRecurrentInfomaxGenerates2008,
  author     = {Tanaka, Takuma and Kaneko, Takeshi and Aoyagi, Toshio},
  title      = {Recurrent {{Infomax Generates Cell Assemblies}}, {{Neuronal Avalanches}}, and {{Simple Cell}}-{{Like Selectivity}}},
  doi        = {10.1162/neco.2008.03-08-727},
  issn       = {0899-7667},
  number     = {4},
  pages      = {1038--1067},
  volume     = {21},
  abstract   = {Recently multineuronal recording has allowed us to observe patterned firings, synchronization, oscillation, and global state transitions in the recurrent networks of central nervous systems. We propose a learning algorithm based on the process of information maximization in a recurrent network, which we call recurrent infomax (RI). RI maximizes information retention and thereby minimizes information loss through time in a network. We find that feeding in external inputs consisting of information obtained from photographs of natural scenes into an RI-based model of a recurrent network results in the appearance of Gabor-like selectivity quite similar to that existing in simple cells of the primary visual cortex. We find that without external input, this network exhibits cell assembly\textendash like and synfire chain\textendash like spontaneous activity as well as a critical neuronal avalanche. In addition, we find that RI embeds externally input temporal firing patterns to the network so that it spontaneously reproduces these patterns after learning. RI provides a simple framework to explain a wide range of phenomena observed in in vivo and in vitro neuronal networks, and it will provide a novel understanding of experimental results for multineuronal activity and plasticity from an information-theoretic point of view.},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/coding/tanaka2008rec.pdf},
  journal    = {Neural Computation},
  keywords   = {r18,read},
  month      = oct,
  readstatus = {read},
  year       = {2008},
}

@Article{deneveBayesianSpikingNeurons2008,
  author   = {Deneve, S.},
  title    = {Bayesian Spiking Neurons {{II}}: Learning},
  doi      = {10.1162/neco.2008.20.1.118},
  issn     = {0899-7667 (Print) 0899-7667 (Linking)},
  language = {en},
  pages    = {118--45},
  volume   = {20},
  abstract = {In the companion letter in this issue ("Bayesian Spiking Neurons I: Inference"), we showed that the dynamics of spiking neurons can be interpreted as a form of Bayesian integration, accumulating evidence over time about events in the external world or the body. We proceed to develop a theory of Bayesian learning in spiking neural networks, where the neurons learn to recognize temporal dynamics of their synaptic inputs. Meanwhile, successive layers of neurons learn hierarchical causal models for the sensory input. The corresponding learning rule is local, spike-time dependent, and highly nonlinear. This approach provides a principled description of spiking and plasticity rules maximizing information transfer, while limiting the number of costly spikes, between successive layers of neurons.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/computation/bayesian/bayesianNeuralSystems/deneve2008bay.pdf},
  journal  = {Neural Comput},
  keywords = {Action Potentials/*physiology,Algorithms,Animals,Bayes Theorem,Central Nervous System/*physiology,Computer Simulation,Humans,Learning/*physiology,Markov Chains,Nerve Net/*physiology,Neural Networks (Computer),Neuronal Plasticity/physiology,Neurons/*physiology,Nonlinear Dynamics,Poisson Distribution,Synaptic Transmission/physiology,Time Perception/physiology},
  month    = jan,
  year     = {2008},
}

@Article{braunAttractorsNoiseTwin2010,
  author   = {Braun, J. and Mattia, M.},
  title    = {Attractors and Noise: {{Twin}} Drivers of Decisions and Multistability},
  doi      = {DOI 10.1016/j.neuroimage.2009.12.126},
  issn     = {1053-8119},
  language = {English},
  pages    = {740--751},
  volume   = {52},
  abstract = {Perceptual decisions are made not only during goal-directed behavior such as choice tasks, but also occur spontaneously while multistable stimuli are being viewed. In both contexts, the formation of a perceptual decision is best captured by noisy attractor dynamics. Noise-driven attractor transitions can accommodate a wide range of timescales and a hierarchical arrangement with "nested attractors" harbors even more dynamical possibilities. The attractor framework seems particularly promising for understanding higher-level mental states that combine heterogeneous information from a distributed set of brain areas. (C) 2010 Elsevier Inc. All rights reserved.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/braun2010att.pdf},
  journal  = {Neuroimage},
  keywords = {attractor neuronal networks,binocular-rivalry,developing oculomotor commands,distributed neuronal coding,lateral geniculate-nucleus,motion-induced blindness,multistable perception,neural-networks,neuronal avalanches,noise-driven transitions,perceptual decision,perceptual decisions,primary visual-cortex,spontaneous cortical activity,subjective sensory experience,temporal hierarchies},
  month    = sep,
  year     = {2010},
}
% == BibTeX quality report for csibraGammaOscillationsObject2000:
% ? Title looks like it was stored in title-case in Zotero

@Article{csicsvariEnsemblePatternsHippocampal2000,
  author   = {Csicsvari, Jozsef and Hirase, Hajime and Mamiya, Akira and Buzs{\'a}ki, Gy{\"o}rgy},
  title    = {Ensemble {{Patterns}} of {{Hippocampal CA3}}-{{CA1 Neurons}} during {{Sharp Wave}}\textendash{{Associated Population Events}}},
  doi      = {10.1016/S0896-6273(00)00135-5},
  issn     = {0896-6273},
  language = {en},
  number   = {2},
  pages    = {585--594},
  volume   = {28},
  abstract = {Transfer of neuronal patterns from the CA3 to CA1 region was studied by simultaneous recording of neuronal ensembles in the behaving rat. A nonlinear interaction among pyramidal neurons was observed during sharp wave (SPW)\textendash related population bursts, with stronger synchrony associated with more widespread spatial coherence. SPW bursts emerged in the CA3a-b subregions and spread to CA3c before invading the CA1 area. Synchronous discharge of {$>$}10\% of the CA3 within a 100 ms window was required to exert a detectable influence on CA1 pyramidal cells. Activity of some CA3 pyramidal neurons differentially predicted the ripple-related discharge of circumscribed groups of CA1 pyramidal cells. We suggest that, in SPW behavioral state, the coherent discharge of a small group of CA3 cells is the primary cause of spiking activity in CA1 pyramidal neurons.},
  journal  = {Neuron},
  month    = nov,
  year     = {2000},
}

@Article{tanigawaOrganizationHorizontalAxons2005,
  author   = {Tanigawa, Hisashi and Wang, QuanXin and Fujita, Ichiro},
  title    = {Organization of {{Horizontal Axons}} in the {{Inferior Temporal Cortex}} and {{Primary Visual Cortex}} of the {{Macaque Monkey}}},
  doi      = {10.1093/cercor/bhi067},
  issn     = {1047-3211},
  number   = {12},
  pages    = {1887--1899},
  volume   = {15},
  abstract = {We investigated the organization of horizontal connections at two distinct hierarchical levels in the ventral visual cortical pathway of the monkey, the inferior temporal (TE) and primary visual (V1) cortices. After injections of anterograde tracers into layers 2 and 3, clusters of terminals (`patches') of labeled horizontal collaterals in TE appeared at various distances up to 8 mm from the injection site, while in V1 clear patches were distributed only within 2 mm. The size and spacing of these patches in TE were larger and more irregular than those observed in V1. The labeling intensity of patches in V1 declined sharply with distance from the injection site. This tendency was less obvious in TE; a number of densely labeled patches existed at distant sites beyond weakly labeled patches. While injections into both areas resulted in an elongated pattern of patches, the anisotropy was greater in TE than in V1 for injections of a similar size. Dual tracer injections and larger-sized injections further revealed that the adjacent sites in TE had spatially distinct horizontal projections, compared to those in V1. These area-specific characteristics of the horizontal connections may contribute to the differences in visual information processing of TE and V1.},
  journal  = {Cerebral Cortex},
  month    = dec,
  year     = {2005},
}

@Article{sejnowskiPuttingBigData2014,
  author    = {Sejnowski, Terrence J. and Churchland, Patricia S. and Movshon, J. Anthony},
  title     = {Putting Big Data to Good Use in Neuroscience},
  doi       = {10.1038/nn.3839},
  issn      = {1546-1726},
  language  = {en},
  number    = {11},
  pages     = {1440--1441},
  volume    = {17},
  abstract  = {Neuroscience is poised to collect Big Data sets. In this Commentary, the authors argue that, to exploit its full potential, there need to be ways to standardize, integrate and synthesize diverse types of data and that this will require a cultural shift to a central role for theorists in neuroscience research.},
  copyright = {2014 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  journal   = {Nature Neuroscience},
  month     = nov,
  publisher = {{Nature Publishing Group}},
  year      = {2014},
}

@Book{andersonIntroductionRandomMatrices2010,
  author     = {Anderson, Greg W and Guionnet, Alice and Zeitouni, Ofer},
  title      = {An Introduction to Random Matrices},
  isbn       = {978-0-511-78780-5 978-0-511-80133-4 978-0-511-78666-2 978-1-282-72491-4},
  language   = {English},
  publisher  = {{Cambridge University Press}},
  abstract   = {A rigorous introduction to the basic theory of random matrices designed for graduate students with a background in probability theory.},
  address    = {{Cambridge; New York}},
  annotation = {OCLC: 651601511},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/books/anderson2010an.pdf},
  year       = {2010},
}

@Article{baarsGlobalWorkspaceTheory2005,
  author     = {Baars, Bernard J.},
  title      = {Global Workspace Theory of Consciousness: Toward a Cognitive Neuroscience of Human Experience},
  doi        = {10.1016/S0079-6123(05)50004-9},
  issn       = {0079-6123},
  language   = {eng},
  pages      = {45--53},
  volume     = {150},
  abstract   = {Global workspace (GW) theory emerged from the cognitive architecture tradition in cognitive science. Newell and co-workers were the first to show the utility of a GW or "blackboard" architecture in a distributed set of knowledge sources, which could cooperatively solve problems that no single constituent could solve alone. The empirical connection with conscious cognition was made by Baars (1988, 2002). GW theory generates explicit predictions for conscious aspects of perception, emotion, motivation, learning, working memory, voluntary control, and self systems in the brain. It has similarities to biological theories such as Neural Darwinism and dynamical theories of brain functioning. Functional brain imaging now shows that conscious cognition is distinctively associated with wide spread of cortical activity, notably toward frontoparietal and medial temporal regions. Unconscious comparison conditions tend to activate only local regions, such as visual projection areas. Frontoparietal hypometabolism is also implicated in unconscious states, including deep sleep, coma, vegetative states, epileptic loss of consciousness, and general anesthesia. These findings are consistent with the GW hypothesis, which is now favored by a number of scientists and philosophers.},
  journal    = {Progress in Brain Research},
  keywords   = {Cognition,Consciousness,Humans,Models; Psychological,Neurosciences},
  pmid       = {16186014},
  shorttitle = {Global Workspace Theory of Consciousness},
  year       = {2005},
}

@Book{christofkochConsciousnessConfessionsRomantic2012,
  author    = {Christof Koch},
  title     = {Consciousness: {{Confessions}} of a {{Romantic Reductionist}}},
  isbn      = {0-262-01749-0},
  publisher = {{The MIT Press}},
  month     = mar,
  year      = {2012},
}

@Article{zeldenrustEfficientRobustCoding2019,
  author     = {Zeldenrust, Fleur and Gutkin, Boris and Den{\'e}ve, Sophie},
  title      = {Efficient and Robust Coding in Heterogeneous Recurrent Networks},
  doi        = {10.1101/804864},
  language   = {en},
  pages      = {804864},
  abstract   = {{$<$}p{$>$}Cortical networks show a large heterogeneity of neuronal properties. However, traditional coding models have focused on homogeneous populations of excitatory and inhibitory neurons. Here, we analytically derive a class of recurrent networks of spiking neurons that close to optimally track a continuously varying input online, based on two assumptions: 1) every spike is decoded linearly and 2) the network aims to reduce the mean-squared error between the input and the estimate. From this we derive a class of predictive coding networks, that unifies encoding and decoding and in which we can investigate the difference between homogeneous networks and heterogeneous networks, in which each neurons represents different features and has different spike-generating properties. We find that in this framework, `type 1' and `type 2' neurons arise naturally and networks consisting of a heterogeneous population of different neuron types are both more efficient and more robust against correlated noise. We make two experimental predictions: 1) we predict that integrators show strong correlations with other integrators and resonators are correlated with resonators, whereas the correlations are much weaker between neurons with different coding properties and 2) that `type 2' neurons are more coherent with the overall network activity than `type 1' neurons.{$<$}/p{$>$}},
  copyright  = {\textcopyright{} 2019, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/coding/Efficient_Optimal/zeldenrust2019eff.pdf},
  journal    = {bioRxiv},
  keywords   = {read},
  month      = oct,
  readstatus = {read},
  year       = {2019},
}

@Article{dehaeneExperimentalTheoreticalApproaches2011,
  author   = {Dehaene, S. and Changeux, J. P.},
  title    = {Experimental and Theoretical Approaches to Conscious Processing},
  doi      = {10.1016/j.neuron.2011.03.018},
  issn     = {1097-4199 (Electronic) 0896-6273 (Linking)},
  number   = {2},
  pages    = {200--27},
  volume   = {70},
  abstract = {Recent experimental studies and theoretical models have begun to address the challenge of establishing a causal link between subjective conscious experience and measurable neuronal activity. The present review focuses on the well-delimited issue of how an external or internal piece of information goes beyond nonconscious processing and gains access to conscious processing, a transition characterized by the existence of a reportable subjective experience. Converging neuroimaging and neurophysiological data, acquired during minimal experimental contrasts between conscious and nonconscious processing, point to objective neural measures of conscious access: late amplification of relevant sensory activity, long-distance cortico-cortical synchronization at beta and gamma frequencies, and "ignition" of a large-scale prefronto-parietal network. We compare these findings to current theoretical models of conscious processing, including the Global Neuronal Workspace (GNW) model according to which conscious access occurs when incoming information is made globally available to multiple brain systems through a network of neurons with long-range axons densely distributed in prefrontal, parieto-temporal, and cingulate cortices. The clinical implications of these results for general anesthesia, coma, vegetative state, and schizophrenia are discussed.},
  file     = {/Users/ssafavi/Documents/libraries/EndnoteLib_fromWin407/EndnoteLib_MPIPClocal_20170723.Data/PDF/3899001701/Dehaene-2011.pdf},
  journal  = {Neuron},
  keywords = {*Consciousness,*Models; Biological,Animals,Attention/physiology,Brain Mapping,Brain/blood supply/cytology/*physiology,Humans,keypap,Magnetic Resonance Imaging/methods,Nerve Net/physiology,Neural Pathways/physiology,Neurons/*physiology},
  month    = apr,
  year     = {2011},
}

@Article{hohwyPredictiveCodingExplains2008a,
  author   = {Hohwy, J. and Roepstorff, A. and Friston, K.},
  title    = {Predictive Coding Explains Binocular Rivalry: An Epistemological Review},
  doi      = {10.1016/j.cognition.2008.05.010},
  issn     = {0010-0277 (Print) 0010-0277 (Linking)},
  number   = {3},
  pages    = {687--701},
  volume   = {108},
  abstract = {Binocular rivalry occurs when the eyes are presented with different stimuli and subjective perception alternates between them. Though recent years have seen a number of models of this phenomenon, the mechanisms behind binocular rivalry are still debated and we still lack a principled understanding of why a cognitive system such as the brain should exhibit this striking kind of behaviour. Furthermore, psychophysical and neurophysiological (single cell and imaging) studies of rivalry are not unequivocal and have proven difficult to reconcile within one framework. This review takes an epistemological approach to rivalry that considers the brain as engaged in probabilistic unconscious perceptual inference about the causes of its sensory input. We describe a simple empirical Bayesian framework, implemented with predictive coding, which seems capable of explaining binocular rivalry and reconciling many findings. The core of the explanation is that selection of one stimulus, and subsequent alternation between stimuli in rivalry occur when: (i) there is no single model or hypothesis about the causes in the environment that enjoys both high likelihood and high prior probability and (ii) when one stimulus dominates, the bottom-up, driving signal for that stimulus is explained away while, crucially, the bottom-up signal for the suppressed stimulus is not, and remains as an unexplained but explainable prediction error signal. This induces instability in perceptual dynamics that can give rise to perceptual transitions or alternations during rivalry.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/perception/multiStablePerception_msp/models/hohwy2008pre.pdf},
  journal  = {Cognition},
  keywords = {*Knowledge,Attention/*physiology,Awareness/physiology,Bayes Theorem,Brain/physiology,Dominance; Cerebral/physiology,Humans,Motion Perception/physiology,Probability,Psychophysics,Vision Disparity/*physiology,Visual Pathways/physiology,Visual Perception/*physiology},
  month    = sep,
  year     = {2008},
}
% == BibTeX quality report for kunzMesoscopicNeuralRepresentations2019:
% ? Title looks like it was stored in title-case in Zotero

@Book{kuramotoChemicalOscillationsWaves2003,
  author      = {Kuramoto, Yoshiki},
  title       = {Chemical {{Oscillations}}, {{Waves}}, and {{Turbulence}}},
  isbn        = {978-0-486-42881-9},
  language    = {en},
  publisher   = {{Courier Corporation}},
  abstract    = {This highly respected, frequently cited book addresses two exciting fields: pattern formation and synchronization of oscillators. It systematically develops the dynamics of many-oscillator systems of dissipative type, with special emphasis on oscillating reaction-diffusion systems. The author applies the reductive perturbation method and the phase description method to the onset of collective rhythms, the formation of wave patterns, and diffusion-induced chemical turbulence. This two-part treatment starts with a section on methods, defining and exploring the reductive perturbation method \textemdash{} oscillators versus fields of oscillators, the Stuart-Landau equation, onset of oscillations in distributed systems, and the Ginzburg-Landau equations. It further examines methods of phase description, including systems of weakly coupled oscillators, one-oscillator problems, nonlinear phase diffusion equations, and representation by the Floquet eigenvectors. Additional methods include systematic perturbation expansion, generalization of the nonlinear phase diffusion equation, and the dynamics of both slowly varying wavefronts and slowly phase-modulated periodic waves. The second part illustrates applications, from mutual entrainment to chemical waves and chemical turbulence. The text concludes with a pair of convenient appendixes.},
  googlebooks = {4ADt7smO5Q8C},
  keywords    = {Science / Chemistry / General,Science / Chemistry / Physical \& Theoretical,Science / System Theory,Science / Waves \& Wave Mechanics},
  month       = jan,
  year        = {2003},
}
% == BibTeX quality report for redinbaughThalamusModulatesConsciousness2020:
% ? Title looks like it was stored in title-case in Zotero

@Book{redishComputationalPsychiatryNew2016,
  title      = {Computational Psychiatry: New Perspectives on Mental Illness},
  editor     = {Redish, A. David and Gordon, Joshua A.},
  isbn       = {978-0-262-03542-2},
  publisher  = {{The MIT Press}},
  series     = {Str\"ungmann {{Forum}} Reports},
  address    = {{Cambridge, Massachusetts}},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/books/redish2016com.pdf},
  keywords   = {Computational Biology,DL,Mental Disorders,methods,Neurosciences},
  lccn       = {RC455.2.D38 C66 2016},
  shorttitle = {Computational Psychiatry},
  year       = {2016},
}
% == BibTeX quality report for izenmanRandomMatrixTheory:
% Missing required field 'journal'
% Missing required field 'year'
% ? Title looks like it was stored in title-case in Zotero

@Book{izhikevichDynamicalSystemsNeuroscience2010,
  author    = {Izhikevich, Eugene M.},
  title     = {Dynamical {{Systems}} in {{Neuroscience}}: {{The Geometry}} of {{Excitability}} and {{Bursting}} ({{Computational Neuroscience}})},
  isbn      = {0-262-51420-6},
  language  = {en},
  publisher = {{The MIT Press}},
  address   = {{Cambrige, Massachusetts, USA}},
  month     = jan,
  year      = {2010},
}
% == BibTeX quality report for abregoIntegratedInformationMeasure2019:
% ? Title looks like it was stored in title-case in Zotero

@Article{acebronKuramotoModelSimple2005,
  author     = {Acebr{\'o}n, Juan A. and Bonilla, L. L. and P{\'e}rez Vicente, Conrad J. and Ritort, F{\'e}lix and Spigler, Renato},
  title      = {The {{Kuramoto}} Model: {{A}} Simple Paradigm for Synchronization Phenomena},
  doi        = {10.1103/RevModPhys.77.137},
  number     = {1},
  pages      = {137--185},
  volume     = {77},
  abstract   = {Synchronization phenomena in large populations of interacting elements are the subject of intense research efforts in physical, biological, chemical, and social systems. A successful approach to the problem of synchronization consists of modeling each member of the population as a phase oscillator. In this review, synchronization is analyzed in one of the most representative models of coupled phase oscillators, the Kuramoto model. A rigorous mathematical treatment, specific numerical methods, and many variations and extensions of the original model that have appeared in the last few years are presented. Relevant applications of the model in different contexts are also included.},
  journal    = {Reviews of Modern Physics},
  keywords   = {review},
  month      = apr,
  publisher  = {{American Physical Society}},
  shorttitle = {The {{Kuramoto}} Model},
  year       = {2005},
}

@Article{panagiotaropoulosNeuronalDischargesGamma2012,
  author   = {Panagiotaropoulos, T. I. and Deco, G. and Kapoor, V. and Logothetis, N. K.},
  title    = {Neuronal Discharges and Gamma Oscillations Explicitly Reflect Visual Consciousness in the Lateral Prefrontal Cortex},
  doi      = {10.1016/j.neuron.2012.04.013},
  issn     = {1097-4199 (Electronic) 0896-6273 (Linking)},
  number   = {5},
  pages    = {924--35},
  volume   = {74},
  abstract = {Neuronal discharges in the primate temporal lobe, but not in the striate and extrastriate cortex, reliably reflect stimulus awareness. However, it is not clear whether visual consciousness should be uniquely localized in the temporal association cortex. Here we used binocular flash suppression to investigate whether visual awareness is also explicitly reflected in feature-selective neural activity of the macaque lateral prefrontal cortex (LPFC), a cortical area reciprocally connected to the temporal lobe. We show that neuronal discharges in the majority of single units and recording sites in the LPFC follow the phenomenal perception of a preferred stimulus. Furthermore, visual awareness is reliably reflected in the power modulation of high-frequency ({$>$}50 Hz) local field potentials in sites where spiking activity is found to be perceptually modulated. Our results suggest that the activity of neuronal populations in at least two association cortical areas represents the content of conscious visual perception.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/perception/multiStablePerception_msp/panagiotaropoulos2012neu.pdf;/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/perception/multiStablePerception_msp/panagiotaropoulos2012neu.pdf},
  journal  = {Neuron},
  keywords = {Action Potentials/*physiology,Analysis of Variance,Animals,Attention/physiology,Brain Mapping,Consciousness/*physiology,Evoked Potentials; Visual/*physiology,Functional Laterality,Macaca mulatta,Neural Inhibition/physiology,Neurons/*physiology,Photic Stimulation,Prefrontal Cortex/*cytology/*physiology,Visual Perception/physiology},
  month    = jun,
  year     = {2012},
}
% == BibTeX quality report for dwarakanathNeuralCorrelatesConscious2020:
% Missing required field 'school'

@Article{dwarakanathPrefrontalStateFluctuations2020,
  author    = {Dwarakanath, Abhilash and Kapoor, Vishal and Werner, Joachim and Safavi, Shervin and Fedorov, Leonid A. and Logothetis, Nikos K. and Panagiotaropoulos, Theofanis I.},
  title     = {Prefrontal State Fluctuations Control Access to Consciousness},
  doi       = {10.1101/2020.01.29.924928},
  language  = {en},
  pages     = {2020.01.29.924928},
  abstract  = {{$<$}h3{$>$}Abstract{$<$}/h3{$>$} {$<$}p{$>$}In perceptual multistability, the content of consciousness alternates spontaneously between different interpretations of unchanged sensory input. The source of these internally driven transitions in conscious perception is unknown. Here we show that transient, low frequency (1-9 Hz) perisynaptic bursts in the macaque lateral prefrontal cortex precede spontaneous perceptual transitions in a no-report binocular motion rivalry task. These low-frequency transients suppress 20-40 Hz oscillatory bursts that selectively synchronise the discharge activity of neuronal ensembles signalling conscious content. Similar ongoing state changes, with dynamics resembling the temporal structure of spontaneous perceptual alternations during rivalry, dominate the prefrontal cortex during resting-state, thus pointing to their default, endogenous nature. Our results suggest that prefrontal state fluctuations control access to consciousness through a reorganisation in the activity of feature-specific neuronal ensembles.{$<$}/p{$><$}h3{$>$}One sentence summary{$<$}/h3{$>$} {$<$}p{$>$}Prefrontal state transitions precede spontaneous transitions in the content of consciousness.{$<$}/p{$>$}},
  chapter   = {New Results},
  copyright = {\textcopyright{} 2020, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
  file      = {/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/perception/multiStablePerception_msp/observations/dwarakanath2020pre.pdf},
  journal   = {bioRxiv},
  month     = feb,
  publisher = {{Cold Spring Harbor Laboratory}},
  year      = {2020},
}
% == BibTeX quality report for aruCouplingStateContents2019:
% ? Title looks like it was stored in title-case in Zotero

@Article{aruDistillingNeuralCorrelates2012,
  author   = {Aru, Jaan and Bachmann, Talis and Singer, Wolf and Melloni, Lucia},
  title    = {Distilling the Neural Correlates of Consciousness},
  doi      = {10.1016/j.neubiorev.2011.12.003},
  issn     = {0149-7634},
  language = {en},
  number   = {2},
  pages    = {737--746},
  volume   = {36},
  abstract = {Solving the problem of consciousness remains one of the biggest challenges in modern science. One key step towards understanding consciousness is to empirically narrow down neural processes associated with the subjective experience of a particular content. To unravel these neural correlates of consciousness (NCC) a common scientific strategy is to compare perceptual conditions in which consciousness of a particular content is present with those in which it is absent, and to determine differences in measures of brain activity (the so called ``contrastive analysis''). However, this comparison appears not to reveal exclusively the NCC, as the NCC proper can be confounded with prerequisites for and consequences of conscious processing of the particular content. This implies that previous results cannot be unequivocally interpreted as reflecting the neural correlates of conscious experience. Here we review evidence supporting this conjecture and suggest experimental strategies to untangle the NCC from the prerequisites and consequences of conscious experience in order to further develop the otherwise valid and valuable contrastive methodology.},
  journal  = {Neuroscience \& Biobehavioral Reviews},
  keywords = {Conscious perception,Contrastive analysis,Neural correlates of consciousness},
  month    = feb,
  year     = {2012},
}

@Article{borstInformationTheoryNeural1999,
  author    = {Borst, Alexander and Theunissen, Fr{\'e}d{\'e}ric E.},
  title     = {Information Theory and Neural Coding},
  doi       = {10.1038/14731},
  issn      = {1546-1726},
  language  = {en},
  number    = {11},
  pages     = {947--957},
  volume    = {2},
  abstract  = {Information theory quantifies how much information a neural response carries about the stimulus. This can be compared to the information transferred in particular models of the stimulus\textendash response function and to maximum possible information transfer. Such comparisons are crucial because they validate assumptions present in any neurophysiological analysis. Here we review information-theory basics before demonstrating its use in neural coding. We show how to use information theory to validate simple stimulus\textendash response models of neural coding of dynamic stimuli. Because these models require specification of spike timing precision, they can reveal which time scales contain information in neural coding. This approach shows that dynamic stimuli can be encoded efficiently by single neurons and that each spike contributes to information transmission. We argue, however, that the data obtained so far do not suggest a temporal code, in which the placement of spikes relative to each other yields additional information.},
  copyright = {1999 Nature America Inc.},
  journal   = {Nature Neuroscience},
  month     = nov,
  publisher = {{Nature Publishing Group}},
  year      = {1999},
}

@Article{buzsakiLargescaleRecordingNeuronal2004,
  author    = {Buzs{\'a}ki, Gy{\"o}rgy},
  title     = {Large-Scale Recording of Neuronal Ensembles},
  doi       = {10.1038/nn1233},
  issn      = {1546-1726},
  language  = {en},
  number    = {5},
  pages     = {446--451},
  volume    = {7},
  abstract  = {How does the brain orchestrate perceptions, thoughts and actions from the spiking activity of its neurons? Early single-neuron recording research treated spike pattern variability as noise that needed to be averaged out to reveal the brain's representation of invariant input. Another view is that variability of spikes is centrally coordinated and that this brain-generated ensemble pattern in cortical structures is itself a potential source of cognition. Large-scale recordings from neuronal ensembles now offer the opportunity to test these competing theoretical frameworks. Currently, wire and micro-machined silicon electrode arrays can record from large numbers of neurons and monitor local neural circuits at work. Achieving the full potential of massively parallel neuronal recordings, however, will require further development of the neuron\textendash electrode interface, automated and efficient spike-sorting algorithms for effective isolation and identification of single neurons, and new mathematical insights for the analysis of network properties.},
  copyright = {2004 Nature Publishing Group},
  file      = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neurophysiology/largeScaleRecording/buzski2004lar.pdf},
  journal   = {Nature Neuroscience},
  month     = may,
  year      = {2004},
}

@Article{smithSpatialTemporalScales2008a,
  author   = {Smith, M. A. and Kohn, A.},
  title    = {Spatial and Temporal Scales of Neuronal Correlation in Primary Visual Cortex},
  doi      = {10.1523/JNEUROSCI.2929-08.2008},
  issn     = {1529-2401 (Electronic) 0270-6474 (Linking)},
  number   = {48},
  pages    = {12591--603},
  volume   = {28},
  abstract = {The spiking activity of cortical neurons is correlated. For instance, trial-to-trial fluctuations in response strength are shared between neurons, and spikes often occur synchronously. Understanding the properties and mechanisms that generate these forms of correlation is critical for determining their role in cortical processing. We therefore investigated the spatial extent and functional specificity of correlated spontaneous and evoked activity. Because feedforward, recurrent, and feedback pathways have distinct extents and specificity, we reasoned that these measurements could elucidate the contribution of each type of input. We recorded single unit activity with microelectrode arrays which allowed us to measure correlation in many hundreds of pairings, across a large range of spatial scales. Our data show that correlated evoked activity is generated by two mechanisms that link neurons with similar orientation preferences on different spatial scales: one with high temporal precision and a limited spatial extent (approximately 3 mm), and a second that gives rise to correlation on a slow time scale and extends as far as we were able to measure (10 mm). The former is consistent with common input provided by horizontal connections; the latter likely involves feedback from extrastriate cortex. Spontaneous activity was correlated over a similar spatial extent, but approximately twice as strongly as evoked activity. Visual stimuli thus caused a substantial decrease in correlation, particularly at response onset. These properties and the circuit mechanism they imply provide new constraints on the functional role that correlation may play in visual processing.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neuralInteractions/PWcorrelations/smith2008spa.pdf;/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neuralInteractions/PWcorrelations/smith2008spa2.pdf;/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neuralInteractions/PWcorrelations/smith2008spa3.pdf},
  journal  = {J Neurosci},
  keywords = {Action Potentials/*physiology,Animals,Electrophysiology/instrumentation/methods,Evoked Potentials; Visual/*physiology,Feedback/physiology,Macaca fascicularis,Macaca nemestrina,Male,Microelectrodes/standards,Nerve Net/physiology,Neural Pathways/physiology,Neurons/*physiology,Neuropsychological Tests,Orientation/physiology,Photic Stimulation,Reaction Time/physiology,Signal Processing; Computer-Assisted,Time Factors,Visual Cortex/*physiology,Visual Pathways/physiology,Visual Perception/*physiology},
  month    = nov,
  year     = {2008},
}

@Book{fredriekeSpikesExploringNeural1999,
  author    = {Fred Rieke and David Warland and {Rob de de Ruyter van Steveninck} and William Bialek},
  title     = {Spikes: {{Exploring}} the {{Neural Code}}},
  isbn      = {0-262-68108-0},
  publisher = {{A Bradford Book}},
  month     = jun,
  year      = {1999},
}
% == BibTeX quality report for bialekShouldYouBelieve2005:
% Missing required field 'journal'

@Article{bialekSocialInteractionsDominate2014,
  author   = {Bialek, W. and Cavagna, A. and Giardina, I. and Mora, T. and Pohl, O. and Silvestri, E. and Viale, M. and Walczak, A. M.},
  title    = {Social Interactions Dominate Speed Control in Poising Natural Flocks near Criticality},
  doi      = {10.1073/pnas.1324045111},
  issn     = {1091-6490 (Electronic) 0027-8424 (Linking)},
  pages    = {7212--7},
  volume   = {111},
  abstract = {Flocks of birds exhibit a remarkable degree of coordination and collective response. It is not just that thousands of individuals fly, on average, in the same direction and at the same speed, but that even the fluctuations around the mean velocity are correlated over long distances. Quantitative measurements on flocks of starlings, in particular, show that these fluctuations are scale-free, with effective correlation lengths proportional to the linear size of the flock. Here we construct models for the joint distribution of velocities in the flock that reproduce the observed local correlations between individuals and their neighbors, as well as the variance of flight speeds across individuals, but otherwise have as little structure as possible. These minimally structured or maximum entropy models provide quantitative, parameter-free predictions for the spread of correlations throughout the flock, and these are in excellent agreement with the data. These models are mathematically equivalent to statistical physics models for ordering in magnets, and the correct prediction of scale-free correlations arises because the parameters--completely determined by the data--are in the critical regime. In biological terms, criticality allows the flock to achieve maximal correlation across long distances with limited speed fluctuations.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/unfiled/bialek2014soc.pdf},
  journal  = {Proc Natl Acad Sci U S A},
  keywords = {*Social Behavior,Animals,Behavior; Animal,Entropy,Flight; Animal/*physiology,Models; Theoretical,Movement,Starlings/*physiology},
  month    = may,
  year     = {2014},
}

@Article{paivaReproducingKernelHilbert2009b,
  author   = {Paiva, A. R. and Park, I. and Principe, J. C.},
  title    = {A Reproducing Kernel {{Hilbert}} Space Framework for Spike Train Signal Processing},
  doi      = {10.1162/neco.2008.09-07-614},
  issn     = {0899-7667 (Print) 0899-7667 (Linking)},
  language = {eng},
  number   = {2},
  pages    = {424--49},
  volume   = {21},
  abstract = {This letter presents a general framework based on reproducing kernel Hilbert spaces (RKHS) to mathematically describe and manipulate spike trains. The main idea is the definition of inner products to allow spike train signal processing from basic principles while incorporating their statistical description as point processes. Moreover, because many inner products can be formulated, a particular definition can be crafted to best fit an application. These ideas are illustrated by the definition of a number of spike train inner products. To further elicit the advantages of the RKHS framework, a family of these inner products, the cross-intensity (CI) kernels, is analyzed in detail. This inner product family encapsulates the statistical description from the conditional intensity functions of spike trains. The problem of their estimation is also addressed. The simplest of the spike train kernels in this family provide an interesting perspective to others' work, as will be demonstrated in terms of spike train distance measures. Finally, as an application example, the RKHS framework is used to derive a clustering algorithm for spike trains from simple principles.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/nda_kernelMethods/paiva2009a.pdf},
  journal  = {Neural Comput},
  keywords = {*Models; Neurological,*Neural Networks (Computer),*Signal Processing; Computer-Assisted,Action Potentials/*physiology,Algorithms,Cluster Analysis,Computer Simulation,Neurons/*physiology,Time Factors},
  month    = feb,
  year     = {2009},
}

@Article{sheheitliMathematicalModelEphaptic2020,
  author     = {Sheheitli, Hiba and Jirsa, Viktor K.},
  title      = {A Mathematical Model of Ephaptic Interactions in Neuronal Fiber Pathways: {{Could}} There Be More than Transmission along the Tracts?},
  doi        = {10.1162/netn_a_00134},
  number     = {3},
  pages      = {595--610},
  volume     = {4},
  abstract   = {While numerous studies of ephaptic interactions have focused on either axons of peripheral nerves or on cortical structures, no attention has been given to the possibility of ephaptic interactions in white matter tracts. Inspired by the highly organized, tightly packed geometry of axons in fiber pathways, we aim to investigate the potential effects of ephaptic interactions along these structures that are resilient to experimental probing. We use axonal cable theory to derive a minimal model of a sheet of N ephaptically coupled axons. Numerical solutions of the proposed model are explored as ephaptic coupling is varied. We demonstrate that ephaptic interactions can lead to local phase locking between adjacent traveling impulses and that, as coupling is increased, traveling impulses trigger new impulses along adjacent axons, resulting in finite size traveling fronts. For strong enough coupling, impulses propagate laterally and backwards, resulting in complex spatiotemporal patterns. While common large-scale brain network models often model fiber pathways as simple relays of signals between different brain regions, our work calls for a closer reexamination of the validity of such a view. The results suggest that in the presence of significant ephaptic interactions, the brain fiber tracts can act as a dynamic active medium.},
  journal    = {Network Neuroscience},
  month      = jan,
  publisher  = {{MIT Press}},
  shorttitle = {A Mathematical Model of Ephaptic Interactions in Neuronal Fiber Pathways},
  year       = {2020},
}

@Article{siettosMultiscaleModelingBrain2016,
  author     = {Siettos, Constantinos and Starke, Jens},
  title      = {Multiscale Modeling of Brain Dynamics: From Single Neurons and Networks to Mathematical Tools},
  doi        = {10.1002/wsbm.1348},
  issn       = {1939-005X},
  language   = {eng},
  number     = {5},
  pages      = {438--458},
  volume     = {8},
  abstract   = {The extreme complexity of the brain naturally requires mathematical modeling approaches on a large variety of scales; the spectrum ranges from single neuron dynamics over the behavior of groups of neurons to neuronal network activity. Thus, the connection between the microscopic scale (single neuron activity) to macroscopic behavior (emergent behavior of the collective dynamics) and vice versa is a key to understand the brain in its complexity. In this work, we attempt a review of a wide range of approaches, ranging from the modeling of single neuron dynamics to machine learning. The models include biophysical as well as data-driven phenomenological models. The discussed models include Hodgkin-Huxley, FitzHugh-Nagumo, coupled oscillators (Kuramoto oscillators, R\"ossler oscillators, and the Hindmarsh-Rose neuron), Integrate and Fire, networks of neurons, and neural field equations. In addition to the mathematical models, important mathematical methods in multiscale modeling and reconstruction of the causal connectivity are sketched. The methods include linear and nonlinear tools from statistics, data analysis, and time series analysis up to differential equations, dynamical systems, and bifurcation theory, including Granger causal connectivity analysis, phase synchronization connectivity analysis, principal component analysis (PCA), independent component analysis (ICA), and manifold learning algorithms such as ISOMAP, and diffusion maps and equation-free techniques. WIREs Syst Biol Med 2016, 8:438-458. doi: 10.1002/wsbm.1348 For further resources related to this article, please visit the WIREs website.},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neuroprinciples/multiScale/siettos2016mul.pdf},
  journal    = {Wiley Interdisciplinary Reviews. Systems Biology and Medicine},
  keywords   = {Algorithms,Brain,Humans,Models; Neurological,Models; Theoretical,Neurons,Nonlinear Dynamics,read,review},
  month      = sep,
  pmid       = {27340949},
  readstatus = {read},
  shorttitle = {Multiscale Modeling of Brain Dynamics},
  year       = {2016},
}

@Article{badimonNegativeFeedbackControl2020,
  author     = {Badimon, Ana and Strasburger, Hayley J. and Ayata, Pinar and Chen, Xinhong and Nair, Aditya and Ikegami, Ako and Hwang, Philip and Chan, Andrew T. and Graves, Steven M. and Uweru, Joseph O. and Ledderose, Carola and Kutlu, Munir Gunes and Wheeler, Michael A. and Kahan, Anat and Ishikawa, Masago and Wang, Ying-Chih and Loh, Yong-Hwee E. and Jiang, Jean X. and Surmeier, D. James and Robson, Simon C. and Junger, Wolfgang G. and Sebra, Robert and Calipari, Erin S. and Kenny, Paul J. and Eyo, Ukpong B. and Colonna, Marco and Quintana, Francisco J. and Wake, Hiroaki and Gradinaru, Viviana and Schaefer, Anne},
  title      = {Negative Feedback Control of Neuronal Activity by Microglia},
  doi        = {10.1038/s41586-020-2777-8},
  issn       = {1476-4687},
  language   = {en},
  pages      = {1--7},
  abstract   = {Microglia, the brain's resident macrophages, help to regulate brain function by removing dying neurons, pruning non-functional synapses, and producing ligands that support neuronal survival1. Here we show that microglia are also critical modulators of neuronal activity and associated behavioural responses in mice. Microglia respond to neuronal activation by suppressing neuronal activity, and ablation of microglia amplifies and synchronizes the activity of neurons, leading to seizures. Suppression of neuronal activation by microglia occurs in a highly region-specific fashion and depends on the ability of microglia to sense and catabolize extracellular ATP, which is released upon neuronal activation by neurons and astrocytes. ATP triggers the recruitment of microglial protrusions and is converted by the microglial ATP/ADP hydrolysing ectoenzyme CD39 into AMP; AMP is then converted into adenosine by CD73, which is expressed on microglia as well as other brain cells. Microglial sensing of ATP, the ensuing microglia-dependent production of adenosine, and the adenosine-mediated suppression of neuronal responses via the adenosine receptor A1R are essential for the regulation of neuronal activity and animal behaviour. Our findings suggest that this microglia-driven negative feedback mechanism operates similarly to inhibitory neurons and is essential for protecting the brain from excessive activation in health and disease.},
  copyright  = {2020 The Author(s), under exclusive licence to Springer Nature Limited},
  journal    = {Nature},
  keywords   = {r18,read},
  month      = sep,
  publisher  = {{Nature Publishing Group}},
  readstatus = {read},
  year       = {2020},
}
% == BibTeX quality report for safaviUncoveringOrganizationNeural2020a:
% ? Title looks like it was stored in title-case in Zotero

@Article{safaviUnivariateMultivariateCoupling2020,
  author        = {Safavi, Shervin and Logothetis, Nikos K. and Besserve, Michel},
  title         = {From Univariate to Multivariate Coupling between Continuous Signals and Point Processes: A Mathematical Framework},
  eprint        = {2005.04034},
  eprinttype    = {arxiv},
  abstract      = {Time series datasets often contain heterogeneous signals, composed of both continuously changing quantities and discretely occurring events. The coupling between these measurements may provide insights into key underlying mechanisms of the systems under study. To better extract this information, we investigate the asymptotic statistical properties of coupling measures between continuous signals and point processes. We first introduce martingale stochastic integration theory as a mathematical model for a family of statistical quantities that include the Phase Locking Value, a classical coupling measure to characterize complex dynamics. Based on the martingale Central Limit Theorem, we can then derive the asymptotic Gaussian distribution of estimates of such coupling measure, that can be exploited for statistical testing. Second, based on multivariate extensions of this result and Random Matrix Theory, we establish a principled way to analyze the low rank coupling between a large number of point processes and continuous signals. For a null hypothesis of no coupling, we establish sufficient conditions for the empirical distribution of squared singular values of the matrix to converge, as the number of measured signals increases, to the well-known Marchenko-Pastur (MP) law, and the largest squared singular value converges to the upper end of the MPs support. This justifies a simple thresholding approach to assess the significance of multivariate coupling. Finally, we illustrate with simulations the relevance of our univariate and multivariate results in the context of neural time series, addressing how to reliably quantify the interplay between multi channel Local Field Potential signals and the spiking activity of a large population of neurons.},
  archiveprefix = {arXiv},
  copyright     = {All rights reserved},
  journal       = {arXiv:2005.04034 [q-bio, stat]},
  keywords      = {Quantitative Biology - Neurons and Cognition,Statistics - Applications,Statistics - Methodology},
  month         = may,
  primaryclass  = {q-bio, stat},
  shorttitle    = {From Univariate to Multivariate Coupling between Continuous Signals and Point Processes},
  year          = {2020},
}

@Book{schroederIntroductionThermalPhysics1999,
  author    = {Schroeder, Daniel V.},
  title     = {An {{Introduction}} to {{Thermal Physics}}},
  edition   = {1st edition},
  isbn      = {978-0-201-38027-9},
  language  = {English},
  publisher = {{Pearson}},
  abstract  = {This text looks at thermodynamics and statistical mechanics. Part I introduces concepts of thermodynamics and statistical mechanics from a unified view. Parts II and III explore further applications of classical thermodynamics and statistical mechanics. Throughout, the emphasis is on real-world applications. ~ Table of Contents: ~  I. FUNDAMENTALS. 1. Energy in Thermal Physics.  2. The Second Law.  3. Interactions and Implications.  II. THERMODYNAMICS. 4. Engines and Refrigerators.  5. Free Energy and Chemical Thermodynamics.  III. STATISTICAL MECHANICS. 6. Boltzmann Statistics.  7. Quantum Statistics.  8. Systems of Interacting Particles.  Appendix A. Elements of Quantum Mechanics.  Appendix B. Mathematical Results.  Reference Data.  Suggested Reading.},
  address   = {{San Francisco, CA}},
  month     = aug,
  year      = {1999},
}

@Article{hippOscillatorySynchronizationLargescale2011a,
  author   = {Hipp, J. F. and Engel, A. K. and Siegel, M.},
  title    = {Oscillatory Synchronization in Large-Scale Cortical Networks Predicts Perception},
  doi      = {10.1016/j.neuron.2010.12.027},
  issn     = {1097-4199 (Electronic) 0896-6273 (Linking)},
  pages    = {387--96},
  volume   = {69},
  abstract = {Normal brain function requires the dynamic interaction of functionally specialized but widely distributed cortical regions. Long-range synchronization of oscillatory signals has been suggested to mediate these interactions within large-scale cortical networks, but direct evidence is sparse. Here we show that oscillatory synchronization is organized in such large-scale networks. We implemented an analysis approach that allows for imaging synchronized cortical networks and applied this technique to EEG recordings in humans. We identified two networks: beta-band synchronization (\textasciitilde 20 Hz) in a fronto-parieto-occipital network and gamma-band synchronization (\textasciitilde 80 Hz) in a centro-temporal network. Strong perceptual correlates support their functional relevance: the strength of synchronization within these networks predicted the subjects' perception of an ambiguous audiovisual stimulus as well as the integration of auditory and visual information. Our results provide evidence that oscillatory neuronal synchronization mediates neuronal communication within frequency-specific, large-scale cortical networks.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/oscillations/neural/hipp2011osc.pdf},
  journal  = {Neuron},
  keywords = {Adult,Brain Mapping/methods,Cerebral Cortex/*physiology,Cortical Synchronization/*physiology,Electroencephalography/methods,Female,Humans,Male,Perception/*physiology},
  month    = jan,
  year     = {2011},
}

@Article{shamirEmergingPrinciplesPopulation2014,
  author   = {Shamir, M.},
  title    = {Emerging Principles of Population Coding: In Search for the Neural Code},
  doi      = {10.1016/j.conb.2014.01.002},
  issn     = {1873-6882 (Electronic) 0959-4388 (Linking)},
  pages    = {140--148},
  volume   = {25C},
  abstract = {Population coding theory aims to provide quantitative tests for hypotheses concerning the neural code. Over the last two decades theory has focused on analyzing the ways in which various parameters that characterize neuronal responses to external stimuli affect the information content of these responses. This article reviews and provides an intuitive explanation for the major effects of noise correlations and neuronal heterogeneity, and discusses their implications for our ability to investigate the neural code. It is argued that to test neural code hypotheses further, additional constraints are required, including relating trial-to-trial variation in neuronal population responses to behavioral decisions and specifying how information is decoded by downstream networks.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neuralInteractions/shamir2014eme.pdf},
  journal  = {Current Opinion in Neurobiology},
  month    = apr,
  year     = {2014},
}
% == BibTeX quality report for moraAreBiologicalSystems2011:
% ? Title looks like it was stored in title-case in Zotero

@Article{moraAreBiologicalSystems2011a,
  author   = {Mora, Thierry and Bialek, William},
  title    = {Are {{Biological Systems Poised}} at {{Criticality}}?},
  doi      = {10.1007/s10955-011-0229-4},
  issn     = {0022-4715 1572-9613},
  pages    = {268--302},
  volume   = {144},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/criticality/mora2011are.pdf;/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/criticality/mora2011are.pdf},
  journal  = {Journal of Statistical Physics},
  keywords = {princNeuro},
  year     = {2011},
}

@Article{friesRhythmsCognitionCommunication2015,
  author   = {Fries, P.},
  title    = {Rhythms for {{Cognition}}: {{Communication}} through {{Coherence}}},
  doi      = {10.1016/j.neuron.2015.09.034},
  issn     = {1097-4199 (Electronic) 0896-6273 (Linking)},
  pages    = {220--35},
  volume   = {88},
  abstract = {I propose that synchronization affects communication between neuronal groups. Gamma-band (30-90 Hz) synchronization modulates excitation rapidly enough that it escapes the following inhibition and activates postsynaptic neurons effectively. Synchronization also ensures that a presynaptic activation pattern arrives at postsynaptic neurons in a temporally coordinated manner. At a postsynaptic neuron, multiple presynaptic groups converge, e.g., representing different stimuli. If a stimulus is selected by attention, its neuronal representation shows stronger and higher-frequency gamma-band synchronization. Thereby, the attended stimulus representation selectively entrains postsynaptic neurons. The entrainment creates sequences of short excitation and longer inhibition that are coordinated between pre- and postsynaptic groups to transmit the attended representation and shut out competing inputs. The predominantly bottom-up-directed gamma-band influences are controlled by predominantly top-down-directed alpha-beta-band (8-20 Hz) influences. Attention itself samples stimuli at a 7-8 Hz theta rhythm. Thus, several rhythms and their interplay render neuronal communication effective, precise, and selective.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/unfiled/fries2015rhy.pdf},
  journal  = {Neuron},
  month    = oct,
  year     = {2015},
}

@Article{cohenDynamicalModelingMultiscale2019,
  author     = {Cohen, Benjamin P. and Chow, Carson C. and Vattikuti, Shashaank},
  title      = {Dynamical Modeling of Multi-Scale Variability in Neuronal Competition},
  doi        = {10.1038/s42003-019-0555-7},
  issn       = {2399-3642},
  language   = {en},
  number     = {1},
  pages      = {1--11},
  volume     = {2},
  abstract   = {Benjamin P Cohen, Carson C Chow, and Shashaank Vattikuti show that dynamical mutual inhibition models can explain variability during neuronal competition at two scales: neuronal spiking activity and perceptual rivalry variability. These models make predictions for how spiking and perceptual variability will change with stimulus conditions.},
  copyright  = {2019 This is a U.S. government work and not under copyright protection in the U.S.; foreign copyright protection may apply},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/perception/multiStablePerception_msp/models/cohen2019dyn.pdf},
  journal    = {Communications Biology},
  keywords   = {read},
  month      = aug,
  readstatus = {read},
  year       = {2019},
}

@Article{zerbiRapidReconfigurationFunctional2019,
  author   = {Zerbi, Valerio and {Floriou-Servou}, Amalia and Markicevic, Marija and Vermeiren, Yannick and Sturman, Oliver and Privitera, Mattia and {von Ziegler}, Lukas and Ferrari, Kim David and Weber, Bruno and De Deyn, Peter Paul and Wenderoth, Nicole and Bohacek, Johannes},
  title    = {Rapid {{Reconfiguration}} of the {{Functional Connectome}} after {{Chemogenetic Locus Coeruleus Activation}}},
  doi      = {10.1016/j.neuron.2019.05.034},
  issn     = {0896-6273},
  number   = {4},
  pages    = {702-718.e5},
  volume   = {103},
  abstract = {Summary The locus coeruleus (LC) supplies norepinephrine (NE) to the entire forebrain and regulates many fundamental brain functions. Studies in humans have suggested that strong LC activation might shift network connectivity to favor salience processing. To causally test this hypothesis, we use a mouse model to study the effect of LC stimulation on large-scale functional connectivity by combining chemogenetic activation of the LC with resting-state fMRI, an approach we term ``chemo-connectomics.'' We show that LC activation rapidly interrupts ongoing behavior and strongly increases brain-wide connectivity, with the most profound effects in the salience and amygdala networks. Functional connectivity changes strongly correlate with transcript levels of alpha-1 and beta-1 adrenergic receptors across the brain, and functional network connectivity correlates with NE turnover within select brain regions. We propose that these changes in large-scale network connectivity are critical for optimizing neural processing in the context of increased vigilance and threat detection.},
  journal  = {Neuron},
  keywords = {anxiety,chemogenetics,DREADDs,functional connectivity,noradrenaline,resting-state functional magnetic resonance imaging,rs-fMRI,salience,stress},
  month    = aug,
  year     = {2019},
}
% == BibTeX quality report for a.bartelsTheoryMultistageIntegration1998:
% Missing required field 'journal'

@Book{aalenSurvivalEventHistory2008,
  author     = {Aalen, Odd O. and Borgan, {\O}rnulf and Gjessing, H{\aa}kon K.},
  title      = {Survival and Event History Analysis: A Process Point of View},
  isbn       = {978-0-387-68560-1 978-0-387-20287-7},
  language   = {eng},
  publisher  = {{Springer}},
  series     = {Statistics for Biology and Health},
  address    = {{New York, NY}},
  annotation = {OCLC: 254319944},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/books/aalen2008sur.pdf},
  ids        = {aalenVis2008},
  shorttitle = {Survival and Event History Analysis},
  year       = {2008},
}

@Article{churchlandPerspectivesCognitiveNeuroscience1988,
  author    = {Churchland, P. S. and Sejnowski, T. J.},
  title     = {Perspectives on Cognitive Neuroscience},
  doi       = {10.1126/science.3055294},
  issn      = {0036-8075, 1095-9203},
  language  = {en},
  number    = {4879},
  pages     = {741--745},
  volume    = {242},
  abstract  = {How is it that we can perceive, learn and be aware of the world? The development of new techniques for studying large-scale brain activity, together with insights from computational modeling and a better understanding of cognitive processes, have opened the door for collaborative research that could lead to major advances in our understanding of ourselves.},
  chapter   = {Articles},
  copyright = {\textcopyright{} 1988},
  journal   = {Science},
  month     = nov,
  pmid      = {3055294},
  publisher = {{American Association for the Advancement of Science}},
  year      = {1988},
}

@Article{chenComputingModulatingSpontaneous2019,
  author     = {Chen, Guozhang and Gong, Pulin},
  title      = {Computing by Modulating Spontaneous Cortical Activity Patterns as a Mechanism of Active Visual Processing},
  doi        = {10.1038/s41467-019-12918-8},
  issn       = {2041-1723},
  language   = {en},
  number     = {1},
  pages      = {1--15},
  volume     = {10},
  abstract   = {The brain's cortex shows complex activity patterns in the absence of sensory inputs. Here, using computational modelling, the authors demonstrate that cortical spontaneous activity is modulated by sensory input and that this modulation process underlies active visual processing.},
  copyright  = {2019 The Author(s)},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/criticality/chen2019com_supp.pdf;/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/criticality/chen2019com.pdf},
  journal    = {Nature Communications},
  keywords   = {read},
  month      = oct,
  readstatus = {read},
  year       = {2019},
}

@Article{dubreuilComplementaryRolesDimensionality2020,
  author    = {Dubreuil, Alexis M. and Valente, Adrian and Beiran, Manuel and Mastrogiuseppe, Francesca and Ostojic, Srdjan},
  title     = {Complementary Roles of Dimensionality and Population Structure in Neural Computations},
  doi       = {10.1101/2020.07.03.185942},
  language  = {en},
  pages     = {2020.07.03.185942},
  abstract  = {{$<$}p{$>$}Neural computations are currently investigated using two competing approaches: sorting neurons into functional classes, or examining the low-dimensional dynamics of collective activity. Whether and how these two aspects interact to shape computations is currently unclear. Using a novel approach to extract computational mechanisms from networks trained with machine-learning tools on neuroscience tasks, here we show that the dimensionality of the dynamics and cell-class structure play fundamentally complementary roles. While various tasks can be implemented by increasing the dimensionality in networks consisting of a single global population, flexible input-output mappings instead required networks to be organized into several sub-populations. Our analyses revealed that the subpopulation structure enabled flexible computations through a mechanism based on gain-controlled modulations that flexibly shape the dynamical landscape of collective dynamics. Our results lead to task-specific predictions for the structure of neural selectivity and inactivation experiments.{$<$}/p{$>$}},
  chapter   = {New Results},
  copyright = {\textcopyright{} 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
  journal   = {bioRxiv},
  month     = jul,
  publisher = {{Cold Spring Harbor Laboratory}},
  year      = {2020},
}

@Article{alamiaAlphaOscillationsTraveling2019,
  author     = {Alamia, Andrea and VanRullen, Rufin},
  title      = {Alpha Oscillations and Traveling Waves: {{Signatures}} of Predictive Coding?},
  doi        = {10.1371/journal.pbio.3000487},
  issn       = {1545-7885},
  language   = {en},
  number     = {10},
  pages      = {e3000487},
  volume     = {17},
  abstract   = {Predictive coding is a key mechanism to understand the computational processes underlying brain functioning: in a hierarchical network, higher levels predict the activity of lower levels, and the unexplained residuals (i.e., prediction errors) are passed back to higher layers. Because of its recursive nature, we wondered whether predictive coding could be related to brain oscillatory dynamics. First, we show that a simple 2-level predictive coding model of visual cortex, with physiological communication delays between levels, naturally gives rise to alpha-band rhythms, similar to experimental observations. Then, we demonstrate that a multilevel version of the same model can explain the occurrence of oscillatory traveling waves across levels, both forward (during visual stimulation) and backward (during rest). Remarkably, the predictions of our model are matched by the analysis of 2 independent electroencephalography (EEG) datasets, in which we observed oscillatory traveling waves in both directions.},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/computation/bayesian/bayesianNeuralSystems/implementations/alamia2019alp.pdf},
  journal    = {PLOS Biology},
  keywords   = {Coding mechanisms,Electroencephalography,Luminance,Simulation and modeling,Traveling waves,Vision,Wave propagation,Waves},
  month      = oct,
  shorttitle = {Alpha Oscillations and Traveling Waves},
  year       = {2019},
}

@Book{reedEncounteringWorldEcological1996,
  author     = {Reed, Edward S.},
  title      = {Encountering the {{World}}: {{Toward}} an {{Ecological Psychology}}},
  edition    = {1 edition},
  isbn       = {978-0-19-507301-0},
  language   = {English},
  publisher  = {{Oxford University Press}},
  abstract   = {Encountering the World reorients modern psychology by finding a viable middle ground between the study of nerve cells and cultural analysis. The emerging field of ecological psychology focuses on the "human niche" and our uniquely evolved modes of action and interaction. Rejecting both mechanistic cognitive science and reductionistic neuroscience, the author offers a new psychology that combines ecological and experimental methods to help us better understand the ways in which people and animals make their way through the world. The book provides a comprehensive treatment of ecological psychology and a unique synthesis of the work of Darwin, neural Darwinism, and modern ecologists with James Gibson's approach to perception. The author presents detailed discussions on communication, sociality, cognition, and language--topics often overlooked by ecological psychologists. Other issues covered include ecological approaches to animal behavior, neural mechanisms, perception, action, and interaction. Provocative and controversial, Encountering the World makes a significant contribution to the debate over the nature of psychology.},
  address    = {{New York}},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/books/reed1996enc.pdf},
  month      = aug,
  shorttitle = {Encountering the {{World}}},
  year       = {1996},
}
% == BibTeX quality report for vinckMoreGammaMore2016:
% ? Title looks like it was stored in title-case in Zotero

@Article{vinckPairwisePhaseConsistency2010,
  author   = {Vinck, M. and {van Wingerden}, M. and Womelsdorf, T. and Fries, P. and Pennartz, C. M.},
  title    = {The Pairwise Phase Consistency: A Bias-Free Measure of Rhythmic Neuronal Synchronization},
  doi      = {10.1016/j.neuroimage.2010.01.073},
  issn     = {1095-9572 (Electronic) 1053-8119 (Linking)},
  pages    = {112--22},
  volume   = {51},
  abstract = {Oscillatory activity is a widespread phenomenon in nervous systems and has been implicated in numerous functions. Signals that are generated by two separate neuronal sources often demonstrate a consistent phase-relationship in a particular frequency-band, i.e., they demonstrate rhythmic neuronal synchronization. This consistency is conventionally measured by the PLV (phase-locking value) or the spectral coherence measure. Both statistical measures suffer from significant bias, in that their sample estimates overestimate the population statistics for finite sample sizes. This is a significant problem in the neurosciences where statistical comparisons are often made between conditions with a different number of trials or between neurons with a different number of spikes. We introduce a new circular statistic, the PPC (pairwise phase consistency). We demonstrate that the sample estimate of the PPC is a bias-free and consistent estimator of its corresponding population parameter. We show, both analytically and by means of numerical simulations, that the population statistic of the PPC is equivalent to the population statistic of the squared PLV. The variance and mean squared error of the PPC and PLV are compared. Finally, we demonstrate the practical relevance of the method in actual neuronal data recorded from the orbitofrontal cortex of rats that engage in a two-odour discrimination task. We find a strong increase in rhythmic synchronization of spikes relative to the local field potential (as measured by the PPC) for a wide range of low frequencies (including the theta-band) during the anticipation of sucrose delivery in comparison to the anticipation of quinine delivery.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/dataAnalysis/nerualDataAnalysis_nda/vinck2010the.pdf},
  journal  = {Neuroimage},
  keywords = {*Periodicity,*Signal Processing; Computer-Assisted,Action Potentials,Algorithms,Animals,Computer Simulation,Discrimination (Psychology)/physiology,Frontal Lobe/physiology,Male,Mental Processes/physiology,Neurons/*physiology,Olfactory Perception/physiology,Rats,Rats; Wistar,Reward},
  month    = may,
  year     = {2010},
}

@Article{shewFunctionalBenefitsCriticality2013,
  author   = {Shew, W. L. and Plenz, D.},
  title    = {The Functional Benefits of Criticality in the Cortex},
  doi      = {10.1177/1073858412445487},
  issn     = {1089-4098 (Electronic) 1073-8584 (Linking)},
  pages    = {88--100},
  volume   = {19},
  abstract = {Rapidly growing empirical evidence supports the hypothesis that the cortex operates near criticality. Although the confirmation of this hypothesis would mark a significant advance in fundamental understanding of cortical physiology, a natural question arises: What functional benefits are endowed to cortical circuits that operate at criticality? In this review, we first describe an introductory-level thought experiment to provide the reader with an intuitive understanding of criticality. Second, we discuss some practical approaches for investigating criticality. Finally, we review quantitative evidence that three functional properties of the cortex are optimized at criticality: 1) dynamic range, 2) information transmission, and 3) information capacity. We focus on recently reported experimental evidence and briefly discuss the theory and history of these ideas.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/criticality/shew2013the.pdf},
  journal  = {Neuroscientist},
  keywords = {*Information Theory,Animals,Cerebral Cortex/cytology/*physiology,Humans,Mental Processes/*physiology,Models; Neurological,Neurons/physiology,Nonlinear Dynamics},
  month    = feb,
  year     = {2013},
}

@Article{ruffiniRealisticModelingMesoscopic2020,
  author     = {Ruffini, Giulio and Salvador, Ricardo and Tadayon, Ehsan and {Sanchez-Todo}, Roser and {Pascual-Leone}, Alvaro and Santarnecchi, Emiliano},
  title      = {Realistic Modeling of Mesoscopic Ephaptic Coupling in the Human Brain},
  doi        = {10.1371/journal.pcbi.1007923},
  issn       = {1553-7358},
  language   = {en},
  number     = {6},
  pages      = {e1007923},
  volume     = {16},
  abstract   = {Several decades of research suggest that weak electric fields may influence neural processing, including those induced by neuronal activity and proposed as a substrate for a potential new cellular communication system, i.e., ephaptic transmission. Here we aim to model mesoscopic ephaptic activity in the human brain and explore its trajectory during aging by characterizing the electric field generated by cortical dipoles using realistic finite element modeling. Extrapolating from electrophysiological measurements, we first observe that modeled endogenous field magnitudes are comparable to those in measurements of weak but functionally relevant self-generated fields and to those produced by noninvasive transcranial brain stimulation, and therefore possibly able to modulate neuronal activity. Then, to evaluate the role of these fields in the human cortex in large MRI databases, we adapt an interaction approximation that considers the relative orientation of neuron and field to estimate the membrane potential perturbation in pyramidal cells. We use this approximation to define a simplified metric (EMOD1) that weights dipole coupling as a function of distance and relative orientation between emitter and receiver and evaluate it in a sample of 401 realistic human brain models from healthy subjects aged 16\textendash 83. Results reveal that ephaptic coupling, in the simplified mesoscopic modeling approach used here, significantly decreases with age, with higher involvement of sensorimotor regions and medial brain structures. This study suggests that by providing the means for fast and direct interaction between neurons, ephaptic modulation may contribute to the complexity of human function for cognition and behavior, and its modification across the lifespan and in response to pathology.},
  journal    = {PLOS Computational Biology},
  keywords   = {Cognitive science,Electric field,Electroencephalography,Finite element analysis,Magnetic resonance imaging,Mesoscopic physics,Neurons,read,Scalp},
  month      = jun,
  publisher  = {{Public Library of Science}},
  readstatus = {read},
  year       = {2020},
}

@Article{karFastRecurrentProcessing2020,
  author     = {Kar, Kohitij and DiCarlo, James J.},
  title      = {Fast Recurrent Processing via Ventral Prefrontal Cortex Is Needed by the Primate Ventral Stream for Robust Core Visual Object Recognition},
  doi        = {10.1101/2020.05.10.086959},
  language   = {en},
  pages      = {2020.05.10.086959},
  abstract   = {{$<$}p{$>$}Distributed neural population spiking patterns in macaque inferior temporal (IT) cortex that support core visual object recognition require additional time to develop for specific ("late-solved") images suggesting the necessity of recurrent processing in these computations. Which brain circuit motifs are most responsible for computing and transmitting these putative recurrent signals to IT? To test whether the ventral prefrontal cortex (vPFC) is a critical recurrent circuit node in this system, here we pharmacologically inactivated parts of the vPFC and simultaneously measured IT population activity, while monkeys performed object discrimination tasks. Our results show that vPFC inactivation deteriorated the quality of the late-phase (\&gt;150 ms from image onset) IT population code, along with commensurate, specific behavioral deficits for "late-solved" images. Finally, silencing vPFC caused the monkeys9 IT activity patterns and behavior to become more like those produced by feedforward artificial neural network models of the ventral stream. Together with prior work, these results argue that fast recurrent processing through the vPFC is critical to the production of behaviorally-sufficient object representations in IT.{$<$}/p{$>$}},
  chapter    = {New Results},
  copyright  = {\textcopyright{} 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
  journal    = {bioRxiv},
  keywords   = {read},
  month      = may,
  publisher  = {{Cold Spring Harbor Laboratory}},
  readstatus = {read},
  year       = {2020},
}

@Article{rabinovichDynamicalPrinciplesNeuroscience2006,
  author     = {Rabinovich, Mikhail I. and Varona, Pablo and Selverston, Allen I. and Abarbanel, Henry D. I.},
  title      = {Dynamical Principles in Neuroscience},
  doi        = {10.1103/RevModPhys.78.1213},
  number     = {4},
  pages      = {1213--1265},
  volume     = {78},
  abstract   = {Dynamical modeling of neural systems and brain functions has a history of success over the last half century. This includes, for example, the explanation and prediction of some features of neural rhythmic behaviors. Many interesting dynamical models of learning and memory based on physiological experiments have been suggested over the last two decades. Dynamical models even of consciousness now exist. Usually these models and results are based on traditional approaches and paradigms of nonlinear dynamics including dynamical chaos. Neural systems are, however, an unusual subject for nonlinear dynamics for several reasons: (i) Even the simplest neural network, with only a few neurons and synaptic connections, has an enormous number of variables and control parameters. These make neural systems adaptive and flexible, and are critical to their biological function. (ii) In contrast to traditional physical systems described by well-known basic principles, first principles governing the dynamics of neural systems are unknown. (iii) Many different neural systems exhibit similar dynamics despite having different architectures and different levels of complexity. (iv) The network architecture and connection strengths are usually not known in detail and therefore the dynamical analysis must, in some sense, be probabilistic. (v) Since nervous systems are able to organize behavior based on sensory inputs, the dynamical modeling of these systems has to explain the transformation of temporal information into combinatorial or combinatorial-temporal codes, and vice versa, for memory and recognition. In this review these problems are discussed in the context of addressing the stimulating questions: What can neuroscience learn from nonlinear dynamics, and what can nonlinear dynamics learn from neuroscience?},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/dynamics/neural/rabinovich2006dyn.pdf;/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neuroprinciples/rabinovich2006dyn.pdf},
  journal    = {Reviews of Modern Physics},
  keywords   = {read,review},
  month      = nov,
  readstatus = {read},
  year       = {2006},
}
% == BibTeX quality report for ramirez-villegasDissectingSynapseFrequencyDependent2018:
% ? Title looks like it was stored in title-case in Zotero

@Article{ramirez-villegasDiversitySharpwaverippleLFP2015,
  author   = {{Ramirez-Villegas}, J. F. and Logothetis, N. K. and Besserve, M.},
  title    = {Diversity of Sharp-Wave-Ripple {{LFP}} Signatures Reveals Differentiated Brain-Wide Dynamical Events},
  doi      = {10.1073/pnas.1518257112},
  issn     = {1091-6490 (Electronic) 0027-8424 (Linking)},
  pages    = {E6379-87},
  volume   = {112},
  abstract = {Sharp-wave-ripple (SPW-R) complexes are believed to mediate memory reactivation, transfer, and consolidation. However, their underlying neuronal dynamics at multiple scales remains poorly understood. Using concurrent hippocampal local field potential (LFP) recordings and functional MRI (fMRI), we study local changes in neuronal activity during SPW-R episodes and their brain-wide correlates. Analysis of the temporal alignment between SPW and ripple components reveals well-differentiated SPW-R subtypes in the CA1 LFP. SPW-R-triggered fMRI maps show that ripples aligned to the positive peak of their SPWs have enhanced neocortical metabolic up-regulation. In contrast, ripples occurring at the trough of their SPWs relate to weaker neocortical up-regulation and absent subcortical down-regulation, indicating differentiated involvement of neuromodulatory pathways in the ripple phenomenon mediated by long-range interactions. To our knowledge, this study provides the first evidence for the existence of SPW-R subtypes with differentiated CA1 activity and metabolic correlates in related brain areas, possibly serving different memory functions.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/unfiled/ramirez-villegas2015div.pdf;/home/ssafavi/Zotero/storage/XT7JBHER/Ramirez-Villegas-20151.pdf},
  journal  = {Proc Natl Acad Sci U S A},
  keywords = {*CA1 Region; Hippocampal/physiology/radiography,*Magnetic Resonance Imaging,*Neocortex/physiology/radiography,Animals,Brain Waves/*physiology,fMRI,hippocampus,in vivo electrophysiology,local field potential,Macaca mulatta,memory,Memory/*physiology},
  month    = nov,
  pmcid    = {PMC4655565},
  year     = {2015},
}

@Article{shrikiOptimalInformationRepresentation2016,
  author   = {Shriki, Oren and Yellin, Dovi},
  title    = {Optimal {{Information Representation}} and {{Criticality}} in an {{Adaptive Sensory Recurrent Neuronal Network}}},
  doi      = {10.1371/journal.pcbi.1004698},
  issn     = {1553-7358},
  language = {en},
  number   = {2},
  pages    = {e1004698},
  volume   = {12},
  abstract = {Recurrent connections play an important role in cortical function, yet their exact contribution to the network computation remains unknown. The principles guiding the long-term evolution of these connections are poorly understood as well. Therefore, gaining insight into their computational role and into the mechanism shaping their pattern would be of great importance. To that end, we studied the learning dynamics and emergent recurrent connectivity in a sensory network model based on a first-principle information theoretic approach. As a test case, we applied this framework to a model of a hypercolumn in the visual cortex and found that the evolved connections between orientation columns have a "Mexican hat" profile, consistent with empirical data and previous modeling work. Furthermore, we found that optimal information representation is achieved when the network operates near a critical point in its dynamics. Neuronal networks working near such a phase transition are most sensitive to their inputs and are thus optimal in terms of information representation. Nevertheless, a mild change in the pattern of interactions may cause such networks to undergo a transition into a different regime of behavior in which the network activity is dominated by its internal recurrent dynamics and does not reflect the objective input. We discuss several mechanisms by which the pattern of interactions can be driven into this supercritical regime and relate them to various neurological and neuropsychiatric phenomena.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/criticality/shriki2016opt.pdf},
  journal  = {PLOS Computational Biology},
  keywords = {Hallucinations,Learning,Network analysis,Neural networks,Neuronal tuning,Neurons,Vision,Visual cortex},
  month    = feb,
  year     = {2016},
}

@Article{liUnbiasedRobustQuantification2016,
  author   = {Li, Z. and Cui, D. and Li, X.},
  title    = {Unbiased and Robust Quantification of Synchronization between Spikes and Local Field Potential},
  doi      = {10.1016/j.jneumeth.2016.05.004},
  issn     = {1872-678X (Electronic) 0165-0270 (Linking)},
  language = {English},
  pages    = {33--8},
  volume   = {269},
  abstract = {BACKGROUND: In neuroscience, relating the spiking activity of individual neurons to the local field potential (LFP) of neural ensembles is an increasingly useful approach for studying rhythmic neuronal synchronization. Many methods have been proposed to measure the strength of the association between spikes and rhythms in the LFP recordings, and most existing measures are dependent upon the total number of spikes. NEW METHOD: In the present work, we introduce a robust approach for quantifying spike-LFP synchronization which performs reliably for limited samples of data. The measure is termed as spike-triggered correlation matrix synchronization (SCMS), which takes LFP segments centered on each spike as multi-channel signals and calculates the index of spike-LFP synchronization by constructing a correlation matrix. RESULTS: The simulation based on artificial data shows that the SCMS output almost does not change with the sample size. This property is of crucial importance when making comparisons between different experimental conditions. When applied to actual neuronal data recorded from the monkey primary visual cortex, it is found that the spike-LFP synchronization strength shows orientation selectivity to drifting gratings. COMPARISON WITH EXISTING METHODS: In comparison to another unbiased method, pairwise phase consistency (PPC), the proposed SCMS behaves better for noisy spike trains by means of numerical simulations. CONCLUSIONS: This study demonstrates the basic idea and calculating process of the SCMS method. Considering its unbiasedness and robustness, the measure is of great advantage to characterize the synchronization between spike trains and rhythms present in LFP.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/multiModal/neuroNetworkRelationship_nnr/methods/li2016unb.pdf},
  journal  = {J Neurosci Methods},
  keywords = {Correlation matrix,Local field potential,Spike train,Synchronization},
  month    = aug,
  year     = {2016},
}
% == BibTeX quality report for buendiaJensenForceStatistical2019:
% ? Possibly abbreviated journal title arXiv:1901.08355 [cond-mat, physics:nlin, q-bio]

@Article{buesingNeuralDynamicsSampling2011,
  author   = {Buesing, L. and Bill, J. and Nessler, B. and Maass, W.},
  title    = {Neural Dynamics as Sampling: A Model for Stochastic Computation in Recurrent Networks of Spiking Neurons},
  doi      = {10.1371/journal.pcbi.1002211},
  issn     = {1553-7358 (Electronic) 1553-734X (Linking)},
  pages    = {e1002211},
  volume   = {7},
  abstract = {The organization of computations in networks of spiking neurons in the brain is still largely unknown, in particular in view of the inherently stochastic features of their firing activity and the experimentally observed trial-to-trial variability of neural systems in the brain. In principle there exists a powerful computational framework for stochastic computations, probabilistic inference by sampling, which can explain a large number of macroscopic experimental data in neuroscience and cognitive science. But it has turned out to be surprisingly difficult to create a link between these abstract models for stochastic computations and more detailed models of the dynamics of networks of spiking neurons. Here we create such a link and show that under some conditions the stochastic firing activity of networks of spiking neurons can be interpreted as probabilistic inference via Markov chain Monte Carlo (MCMC) sampling. Since common methods for MCMC sampling in distributed systems, such as Gibbs sampling, are inconsistent with the dynamics of spiking neurons, we introduce a different approach based on non-reversible Markov chains that is able to reflect inherent temporal processes of spiking neuronal activity through a suitable choice of random variables. We propose a neural network model and show by a rigorous theoretical analysis that its neural activity implements MCMC sampling of a given distribution, both for the case of discrete and continuous time. This provides a step towards closing the gap between abstract functional models of cortical computation and more detailed models of networks of spiking neurons.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/unfiled/buesing2011neu.pdf},
  journal  = {PLoS Comput Biol},
  keywords = {*Models; Neurological,Action Potentials/*physiology,Algorithms,Animals,Computer Simulation,Humans,Markov Chains,Monte Carlo Method,Neurons/*physiology,Primates,Stochastic Processes},
  month    = nov,
  year     = {2011},
}
% == BibTeX quality report for haddadComputationalStudySpatiotemporal2018:
% ? Title looks like it was stored in title-case in Zotero

@Article{haddadMaternalImmuneActivation2020,
  author     = {Haddad, Faraj and Patel, Salonee and Schmid, Susanne},
  title      = {Maternal {{Immune Activation}} by {{Poly I}}:{{C}} as a Preclinical {{Model}} for {{Neurodevelopmental Disorders}}: {{A}} Focus on {{Autism}} and {{Schizophrenia}}},
  doi        = {10.1016/j.neubiorev.2020.04.012},
  issn       = {0149-7634},
  language   = {en},
  abstract   = {Maternal immune activation (MIA) in response to a viral infection during early and mid-gestation has been epidemically linked to a higher risk for the child to develop autism or schizophrenia-related symptoms. This has led to the establishment of the pathogen-free poly I:C induced MIA animal model for neurodevelopmental disorders with relatively high construct and face validity. Depending on the experimental variables, particularly the timing of poly I:C administration, different behavioural and molecular phenotypes have been described that relate to specific symptoms of neurodevelopmental disorders such as autism spectrum disorder and/or schizophrenia. We here review and summarize epidemiological evidence for the effects of maternal infection and immune activation, as well as major findings in different poly I:C MIA models with a focus on poly I:C exposure timing, behavioural and molecular changes in the offspring, and characteristics of the model that relate it to autism spectrum disorder and schizophrenia.},
  journal    = {Neuroscience \& Biobehavioral Reviews},
  keywords   = {animal model,autism spectrum disorder,environmental impact on brain development,Maternal immune activation,prenatal brain development,read,schizophrenia,viral infection during pregnancy},
  month      = apr,
  readstatus = {read},
  shorttitle = {Maternal {{Immune Activation}} by {{Poly I}}},
  year       = {2020},
}

@Article{tkacikInformationProcessingLiving2016,
  author     = {Tkacik, G. and Bialek, W.},
  title      = {Information {{Processing}} in {{Living Systems}}},
  doi        = {10.1146/annurev-conmatphys-031214-014803},
  issn       = {1947-5454},
  language   = {English},
  pages      = {89--117},
  volume     = {7},
  abstract   = {Life depends as much on the flow of information as on the flow of energy. Here we review the many efforts to make this intuition precise. Starting with the building blocks of information theory, we explore examples where it has been possible to measure, directly, the flow of information in biological networks, or more generally where information-theoretic ideas have been used to guide the analysis of experiments. Systems of interest range from single molecules (the sequence diversity in families of proteins) to groups of organisms (the distribution of velocities in flocks of birds), and all scales in between. Many of these analyses are motivated by the idea that biological systems may have evolved to optimize the gathering and representation of information, and we review the experimental evidence for this optimization, again across a wide range of scales.},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/brain/tkacik2016inf.pdf},
  journal    = {Annual Review of Condensed Matter Physics, Vol 2},
  keywords   = {biochemical signaling networks,biological networks,cortical networks,gene regulation,gene-expression,information theory,mutual information,neural population,neuroscience,optimality,positional information,read,receptive-fields,review,social interactions,statistical-mechanics,visual-perception},
  month      = mar,
  readstatus = {read},
  year       = {2016},
}

@Article{michielsvankessenichPatternRecognitionNeuronal2019,
  author   = {{Michiels van Kessenich}, L. and Berger, D. and {de Arcangelis}, L. and Herrmann, H. J.},
  title    = {Pattern Recognition with Neuronal Avalanche Dynamics},
  doi      = {10.1103/PhysRevE.99.010302},
  number   = {1},
  pages    = {010302},
  volume   = {99},
  abstract = {Pattern recognition is a fundamental neuronal process which enables a cortical system to interpret visual stimuli. How the brain learns to recognize patterns is, however, an unsolved problem. The frequently employed method of back propagation excels at this task but has been found to be unbiological in many aspects. In this Rapid Communication we achieve pattern recognition tasks in a biologically, fully consistent framework. We consider a neuronal network exhibiting avalanche dynamics, as observed experimentally, and implement negative feedback signals. These are chemical signals, such as dopamine, which mediate synaptic plasticity and sculpt the network to achieve certain tasks. The system is able to distinguish horizontal and vertical lines with high accuracy, as well as to perform well at the more complicated task of handwritten digit recognition. Resulting from the learning mechanism, spatially separate activity regions emerge, as observed in the primary visual cortex using functional magnetic resonance imaging techniques. The results therefore suggest that negative feedback signals offer an explanation for the emergence of distinct activity areas in the visual cortex.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/criticality/applications/michiels_van_kessenich2019pat.pdf},
  journal  = {Physical Review E},
  month    = jan,
  year     = {2019},
}

@Article{doesburgRhythmsConsciousnessBinocular2009b,
  author   = {Doesburg, S. M. and Green, J. J. and McDonald, J. J. and Ward, L. M.},
  title    = {Rhythms of Consciousness: Binocular Rivalry Reveals Large-Scale Oscillatory Network Dynamics Mediating Visual Perception},
  doi      = {10.1371/journal.pone.0006142},
  issn     = {1932-6203 (Electronic) 1932-6203 (Linking)},
  number   = {7},
  pages    = {e6142},
  volume   = {4},
  abstract = {Consciousness has been proposed to emerge from functionally integrated large-scale ensembles of gamma-synchronous neural populations that form and dissolve at a frequency in the theta band. We propose that discrete moments of perceptual experience are implemented by transient gamma-band synchronization of relevant cortical regions, and that disintegration and reintegration of these assemblies is time-locked to ongoing theta oscillations. In support of this hypothesis we provide evidence that (1) perceptual switching during binocular rivalry is time-locked to gamma-band synchronizations which recur at a theta rate, indicating that the onset of new conscious percepts coincides with the emergence of a new gamma-synchronous assembly that is locked to an ongoing theta rhythm; (2) localization of the generators of these gamma rhythms reveals recurrent prefrontal and parietal sources; (3) theta modulation of gamma-band synchronization is observed between and within the activated brain regions. These results suggest that ongoing theta-modulated-gamma mechanisms periodically reintegrate a large-scale prefrontal-parietal network critical for perceptual experience. Moreover, activation and network inclusion of inferior temporal cortex and motor cortex uniquely occurs on the cycle immediately preceding responses signaling perceptual switching. This suggests that the essential prefrontal-parietal oscillatory network is expanded to include additional cortical regions relevant to tasks and perceptions furnishing consciousness at that moment, in this case image processing and response initiation, and that these activations occur within a time frame consistent with the notion that conscious processes directly affect behaviour.},
  file     = {/Users/ssafavi/Documents/libraries/EndnoteLib_fromWin407/EndnoteLib_MPIPClocal_20170723.Data/PDF/0359230459/Doesburg-2009.pdf},
  journal  = {PLoS One},
  keywords = {*Consciousness,*Vision; Binocular,*Visual Perception,Humans},
  month    = jul,
  year     = {2009},
}

@Article{srinivasanIncreasedSynchronizationNeuromagnetic1999b,
  author   = {Srinivasan, R. and Russell, D. P. and Edelman, G. M. and Tononi, G.},
  title    = {Increased Synchronization of Neuromagnetic Responses during Conscious Perception},
  issn     = {0270-6474 (Print) 0270-6474 (Linking)},
  language = {en},
  number   = {13},
  pages    = {5435--48},
  volume   = {19},
  abstract = {In binocular rivalry, the observer views two incongruent images, one through each eye, but is conscious of only one image at a time. The image that is perceptually dominant alternates every few seconds. We used this phenomenon to investigate neural correlates of conscious perception. We presented a red vertical grating to one eye and a blue horizontal grating to the other eye, with each grating continuously flickering at a distinct frequency (the frequency tag for that stimulus). Steady-state magnetic fields were recorded with a 148 sensor whole-head magnetometer while the subjects reported which grating was perceived. The power of the steady-state magnetic field at the frequency associated with a grating typically increased at multiple sensors when the grating was perceived. Changes in power related to perceptual dominance, presumably reflecting local neural synchronization, reached statistical significance at several sensors, including some positioned over occipital, temporal, and frontal cortices. To identify changes in synchronization between distinct brain areas that were related to perceptual dominance, we analyzed coherence between pairs of widely separated sensors. The results showed that when the stimulus was perceived there was a marked increase in both interhemispheric and intrahemispheric coherence at the stimulus frequency. This study demonstrates a direct correlation between the conscious perception of a visual stimulus and the synchronous activity of large populations of neocortical neurons as reflected by stimulus-evoked steady-state neuromagnetic fields.},
  file     = {/Users/ssafavi/Documents/libraries/EndnoteLib_fromWin407/EndnoteLib_MPIPClocal_20170723.Data/PDF/4193492092/Srinivasan-1999.pdf},
  journal  = {J Neurosci},
  keywords = {*Magnetoencephalography,Adult,Brain/cytology/physiology,Color Perception,Consciousness,Cortical Synchronization,Electromagnetic Fields,Female,Functional Laterality,Head,Humans,Male,Middle Aged,Neurons/physiology,Photic Stimulation,Statistics as Topic,Time Factors,Vision Disparity/*physiology,Vision; Binocular/*physiology,Visual Perception/*physiology},
  month    = jul,
  year     = {1999},
}

@Article{kochSystemsBiologyModular2012,
  author   = {Koch, C.},
  title    = {Systems Biology. {{Modular}} Biological Complexity},
  doi      = {10.1126/science.1218616},
  issn     = {1095-9203 (Electronic) 0036-8075 (Linking)},
  language = {en},
  pages    = {531--2},
  volume   = {337},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/integratedInformationTheory_iit/koch2012sys.pdf},
  journal  = {Science},
  keywords = {*Proteomics,*Systems Biology,Animals,Brain/*metabolism,Humans,Mice,Nerve Tissue Proteins/*metabolism,Neurons/*metabolism,Synapses/metabolism},
  month    = aug,
  year     = {2012},
}

@Article{liBurstSpikingSingle2009a,
  author   = {Li, C. Y. and Poo, M. M. and Dan, Y.},
  title    = {Burst Spiking of a Single Cortical Neuron Modifies Global Brain State},
  doi      = {10.1126/science.1169957},
  issn     = {1095-9203 (Electronic) 0036-8075 (Linking)},
  number   = {5927},
  pages    = {643--6},
  volume   = {324},
  abstract = {Different global patterns of brain activity are associated with distinct arousal and behavioral states of an animal, but how the brain rapidly switches between different states remains unclear. We here report that repetitive high-frequency burst spiking of a single rat cortical neuron could trigger a switch between the cortical states resembling slow-wave and rapid-eye-movement sleep. This is reflected in the switching of the membrane potential of the stimulated neuron from slow UP/DOWN oscillations to a persistent-UP state or vice versa, with concurrent changes in the temporal pattern of cortical local field potential (LFP) recorded several millimeters away. These results point to the power of single cortical neurons in modulating the behavioral state of an animal.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/multiModal/neuroNetworkRelationship_nnr/observations/li2009bur.pdf},
  journal  = {Science},
  keywords = {Animals,Behavior; Animal,Electroencephalography,Membrane Potentials,Neurons/*physiology,Patch-Clamp Techniques,Rats,Rats; Long-Evans,Sleep Stages,Sleep; REM,Somatosensory Cortex/cytology/*physiology,Visual Cortex/cytology/*physiology},
  month    = may,
  pmcid    = {PMC2913066},
  year     = {2009},
}
% == BibTeX quality report for sethnaCracklingNoise2001a:
% ? Title looks like it was stored in title-case in Zotero

@Article{sethnaCracklingNoise2001b,
  author     = {Sethna, J. P. and Dahmen, K. A. and Myers, C. R.},
  title      = {Crackling Noise},
  doi        = {10.1038/35065675},
  issn       = {0028-0836 (Print) 0028-0836 (Linking)},
  number     = {6825},
  pages      = {242--50},
  volume     = {410},
  abstract   = {Crackling noise arises when a system responds to changing external conditions through discrete, impulsive events spanning a broad range of sizes. A wide variety of physical systems exhibiting crackling noise have been studied, from earthquakes on faults to paper crumpling. Because these systems exhibit regular behaviour over a huge range of sizes, their behaviour is likely to be independent of microscopic and macroscopic details, and progress can be made by the use of simple models. The fact that these models and real systems can share the same behaviour on many scales is called universality. We illustrate these ideas by using results for our model of crackling noise in magnets, explaining the use of the renormalization group and scaling collapses, and we highlight some continuing challenges in this still-evolving field.},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/sethna2001cra.pdf},
  journal    = {Nature},
  keywords   = {read},
  month      = mar,
  readstatus = {read},
  year       = {2001},
}

@Article{juavinettChronicallyImplantedNeuropixels2019,
  author    = {Juavinett, Ashley L and Bekheet, George and Churchland, Anne K},
  title     = {Chronically Implanted {{Neuropixels}} Probes Enable High-Yield Recordings in Freely Moving Mice},
  doi       = {10.7554/eLife.47188},
  editor    = {Colgin, Laura L and Steinmetz, Nick},
  issn      = {2050-084X},
  pages     = {e47188},
  volume    = {8},
  abstract  = {The advent of high-yield electrophysiology using Neuropixels probes is now enabling researchers to simultaneously record hundreds of neurons with remarkably high signal to noise. However, these probes have not been well-suited to use in freely moving mice. It is critical to study neural activity in unrestricted animals for many reasons, such as leveraging ethological approaches to study neural circuits. We designed and implemented a novel device that allows Neuropixels probes to be customized for chronically implanted experiments in freely moving mice. We demonstrate the ease and utility of this approach in recording hundreds of neurons during an ethological behavior across weeks of experiments. We provide the technical drawings and procedures for other researchers to do the same. Importantly, our approach enables researchers to explant and reuse these valuable probes, a transformative step which has not been established for recordings with any type of chronically-implanted probe.},
  journal   = {eLife},
  keywords  = {behavior,electrophysiology,extracellular,Neuropixels},
  month     = aug,
  publisher = {{eLife Sciences Publications, Ltd}},
  year      = {2019},
}

@Article{johnsonPointProcessModels1996,
  author   = {Johnson, Don H.},
  title    = {Point Process Models of Single-Neuron Discharges},
  doi      = {10.1007/BF00161089},
  issn     = {1573-6873},
  language = {en},
  number   = {4},
  pages    = {275--299},
  volume   = {3},
  abstract = {In most neural systems, neurons communicate via sequences of action potentials. Contemporary models assume that the action potentials' times of occurrence rather than their waveforms convey information. The mathematical tool for describing sequences of events occurring in time and/or space is the theory of point processes. Using this theory, we show that neural discharge patterns convey time-varying information intermingled with the neuron's response characteristics. We review the basic techniques for analyzing single-neuron discharge patterns and describe what they reveal about the underlying point process model. By applying information theory and estimation theory to point processes, we describe the fundamental limits on how well information can be represented by and extracted from neural discharges. We illustrate applying these results by considering recordings from the lower auditory pathway.},
  journal  = {Journal of Computational Neuroscience},
  month    = dec,
  year     = {1996},
}

@Article{buzsakiNeuralSyntaxCell2010b,
  author   = {Buzsaki, G.},
  title    = {Neural Syntax: Cell Assemblies, Synapsembles, and Readers},
  doi      = {10.1016/j.neuron.2010.09.023},
  issn     = {1097-4199 (Electronic) 0896-6273 (Linking)},
  number   = {3},
  pages    = {362--85},
  volume   = {68},
  abstract = {A widely discussed hypothesis in neuroscience is that transiently active ensembles of neurons, known as "cell assemblies," underlie numerous operations of the brain, from encoding memories to reasoning. However, the mechanisms responsible for the formation and disbanding of cell assemblies and temporal evolution of cell assembly sequences are not well understood. I introduce and review three interconnected topics, which could facilitate progress in defining cell assemblies, identifying their neuronal organization, and revealing causal relationships between assembly organization and behavior. First, I hypothesize that cell assemblies are best understood in light of their output product, as detected by "reader-actuator" mechanisms. Second, I suggest that the hierarchical organization of cell assemblies may be regarded as a neural syntax. Third, constituents of the neural syntax are linked together by dynamically changing constellations of synaptic weights ("synapsembles"). The existing support for this tripartite framework is reviewed and strategies for experimental testing of its predictions are discussed.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/projects/nnr/MT/buzsaki2010neu.pdf;/home/ssafavi/Zotero/storage/UCPUWDDL/Buzsaki-2010.pdf},
  journal  = {Neuron},
  keywords = {Animals,Brain/physiology,Electrophysiology,Humans,Models; Neurological,Neural Pathways/*physiology,Neurons/*physiology,Synapses/*physiology princNeuro},
  month    = nov,
  year     = {2010},
}

@Article{leongPromiseTwopersonNeuroscience2019,
  author     = {Leong, Victoria and Schilbach, Leonhard},
  title      = {The Promise of Two-Person Neuroscience for Developmental Psychiatry: Using Interaction-Based Sociometrics to Identify Disorders of Social Interaction},
  doi        = {10.1192/bjp.2019.73},
  issn       = {0007-1250, 1472-1465},
  language   = {en},
  number     = {5},
  pages      = {636--638},
  volume     = {215},
  abstract   = {Social interactions are fundamental for human development, and disordered social interactions are pervasive in many psychiatric disorders. Recent advances in `two-person neuroscience' have provided new tools for characterising social interactions. Accordingly, interaction-based `sociometrics' hold great promise for developmental psychology and psychiatry, particularly in the early identification of social disorders.Declaration of interestNone.},
  journal    = {The British Journal of Psychiatry},
  keywords   = {developmental disorders,Social interaction,two-person neuroscience},
  month      = nov,
  publisher  = {{Cambridge University Press}},
  shorttitle = {The Promise of Two-Person Neuroscience for Developmental Psychiatry},
  year       = {2019},
}

@Article{lehkyNoBinocularRivalry1996,
  author   = {Lehky, S. R. and Maunsell, J. H. R.},
  title    = {No Binocular Rivalry in the {{LGN}} of Alert Macaque Monkeys},
  doi      = {Doi 10.1016/0042-6989(95)00232-4},
  issn     = {0042-6989},
  language = {English},
  number   = {9},
  pages    = {1225--1234},
  volume   = {36},
  abstract = {Orthogonal drifting gratings were presented binocularly to alert macaque monkeys in an attempt to find neural correlates of binocular rivalry. Gratings were centered over lateral geniculate nucleus (LGN) receptive fields and the corresponding points for the opposite eye. The only task of the monkey was to fixate. We found no difference between the responses of LGN neurons under rivalrous and nonrivalrous conditions, as determined by examining the ratios of their respective power spectra. There was, however, a curious ''temporal afterimage'' effect in which cell responses continued to be modulated at the drift frequency of the grating for several seconds after the grating disappeared.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/perception/multiStablePerception_msp/lehky1996no.pdf},
  journal  = {Vision Res},
  keywords = {binocular vision,cat,corticofugal feedback influences,lateral geniculate nucleus,lateral geniculate-nucleus,macaque monkey,neurons,pathway,rivalry,spatial-frequency,system,visual-cortex,x-cell,y-cell},
  month    = may,
  year     = {1996},
}

@Article{vattikutiCanonicalCorticalCircuit2016,
  author     = {Vattikuti, Shashaank and Thangaraj, Phyllis and Xie, Hua W. and Gotts, Stephen J. and Martin, Alex and Chow, Carson C.},
  title      = {Canonical {{Cortical Circuit Model Explains Rivalry}}, {{Intermittent Rivalry}}, and {{Rivalry Memory}}},
  doi        = {10.1371/journal.pcbi.1004903},
  issn       = {1553-7358},
  language   = {en},
  number     = {5},
  pages      = {e1004903},
  volume     = {12},
  abstract   = {It has been shown that the same canonical cortical circuit model with mutual inhibition and a fatigue process can explain perceptual rivalry and other neurophysiological responses to a range of static stimuli. However, it has been proposed that this model cannot explain responses to dynamic inputs such as found in intermittent rivalry and rivalry memory, where maintenance of a percept when the stimulus is absent is required. This challenges the universality of the basic canonical cortical circuit. Here, we show that by including an overlooked realistic small nonspecific background neural activity, the same basic model can reproduce intermittent rivalry and rivalry memory without compromising static rivalry and other cortical phenomena. The background activity induces a mutual-inhibition mechanism for short-term memory, which is robust to noise and where fine-tuning of recurrent excitation or inclusion of sub-threshold currents or synaptic facilitation is unnecessary. We prove existence conditions for the mechanism and show that it can explain experimental results from the quartet apparent motion illusion, which is a prototypical intermittent rivalry stimulus.},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/perception/multiStablePerception_msp/models/vattikuti2016can.pdf},
  journal    = {PLOS Computational Biology},
  keywords   = {Behavior,Fatigue,Material fatigue,Memory,Motion,Neurons,Perception,read,Vision},
  month      = may,
  readstatus = {read},
  year       = {2016},
}

@Article{scholtensMultimodalConnectomicsPsychiatry2018,
  author     = {Scholtens, Lianne H. and {van den Heuvel}, Martijn P.},
  title      = {Multimodal {{Connectomics}} in {{Psychiatry}}: {{Bridging Scales From Micro}} to {{Macro}}},
  doi        = {10.1016/j.bpsc.2018.03.017},
  issn       = {2451-9022},
  number     = {9},
  pages      = {767--776},
  series     = {Computational {{Methods}} and {{Modeling}} in {{Psychiatry}}},
  volume     = {3},
  abstract   = {The human brain is a highly complex system, with a large variety of microscale cellular morphologies and macroscale global properties. Working at multiple scales, it forms an efficient system for processing and integration of multimodal information. Studies have repeatedly demonstrated strong associations between modalities of both microscales and macroscales of brain organization. These consistent observations point toward potential common organization principles where regions with a microscale architecture supportive of a larger computational load have more and stronger connections in the brain network on the macroscale. Conversely, disruptions observed on one organizational scale could modulate the other. First neuropsychiatric micro-macro comparisons in, among other conditions, Alzheimer's disease and schizophrenia, have, for example, shown overlapping alterations across both scales. We give an overview of recent findings on associations between microscale and macroscale organization observed in the healthy brain, followed by a summary of microscale and macroscale findings reported in the context of brain disorders. We conclude with suggestions for future multiscale connectome comparisons linking multiple scales and modalities of organization and suggest how such comparisons could contribute to a more complete fundamental understanding of brain organization and associated disease-related alterations.},
  journal    = {Biological Psychiatry: Cognitive Neuroscience and Neuroimaging},
  keywords   = {Connectivity,Connectomics,Multimodal,Multiscale,Neuroimaging,Psychiatry,read,review},
  month      = sep,
  readstatus = {read},
  shorttitle = {Multimodal {{Connectomics}} in {{Psychiatry}}},
  year       = {2018},
}
% == BibTeX quality report for zeraatiSelforganizationCriticalitySynaptic2020:
% ? Possibly abbreviated journal title arXiv:2010.07888 [cond-mat, physics:physics, q-bio]

@TechReport{zeraatiStudyingCriticalityIts2017,
  author      = {Zeraati, Roxana},
  institution = {{Max Planck Institute for Biological Cybernetics}},
  title       = {Studying Criticality and Its Different Measures in Neuroscience},
  language    = {English},
  address     = {{Tuebingen, Germany}},
  file        = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/criticality/zeraati2017cri.pdf},
  keywords    = {review},
  year        = {2017},
}

@Article{tkacikThermodynamicsSignaturesCriticality2015,
  author   = {Tkacik, G. and Mora, T. and Marre, O. and Amodei, D. and Palmer, S. E. and Berry, M. J. and Bialek, W.},
  title    = {Thermodynamics and Signatures of Criticality in a Network of Neurons},
  doi      = {10.1073/pnas.1514188112},
  issn     = {1091-6490 (Electronic) 0027-8424 (Linking)},
  abstract = {The activity of a neural network is defined by patterns of spiking and silence from the individual neurons. Because spikes are (relatively) sparse, patterns of activity with increasing numbers of spikes are less probable, but, with more spikes, the number of possible patterns increases. This tradeoff between probability and numerosity is mathematically equivalent to the relationship between entropy and energy in statistical physics. We construct this relationship for populations of up to N = 160 neurons in a small patch of the vertebrate retina, using a combination of direct and model-based analyses of experiments on the response of this network to naturalistic movies. We see signs of a thermodynamic limit, where the entropy per neuron approaches a smooth function of the energy per neuron as N increases. The form of this function corresponds to the distribution of activity being poised near an unusual kind of critical point. We suggest further tests of criticality, and give a brief discussion of its functional significance.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/criticality/tkacik2015the.pdf;/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/criticality/tkacik2015the2.pdf},
  journal  = {Proc Natl Acad Sci U S A},
  keywords = {correlation,entropy,information,Monte Carlo,neural networks},
  month    = sep,
  year     = {2015},
}

@Article{freemanScalefreeNeocorticalDynamics2007a,
  author   = {Freeman, Walter J. and Breakspear, Michael},
  title    = {Scale-Free Neocortical Dynamics},
  doi      = {10.4249/scholarpedia.1357},
  issn     = {1941-6016},
  language = {en},
  number   = {2},
  pages    = {1357},
  volume   = {2},
  journal  = {Scholarpedia},
  month    = feb,
  year     = {2007},
}

@Article{decoDynamicBrainSpiking2008,
  author   = {Deco, G. and Jirsa, V. K. and Robinson, P. A. and Breakspear, M. and Friston, K.},
  title    = {The Dynamic Brain: From Spiking Neurons to Neural Masses and Cortical Fields},
  doi      = {10.1371/journal.pcbi.1000092},
  issn     = {1553-7358 (Electronic) 1553-734X (Linking)},
  number   = {8},
  pages    = {e1000092},
  volume   = {4},
  abstract = {The cortex is a complex system, characterized by its dynamics and architecture, which underlie many functions such as action, perception, learning, language, and cognition. Its structural architecture has been studied for more than a hundred years; however, its dynamics have been addressed much less thoroughly. In this paper, we review and integrate, in a unifying framework, a variety of computational approaches that have been used to characterize the dynamics of the cortex, as evidenced at different levels of measurement. Computational models at different space-time scales help us understand the fundamental mechanisms that underpin neural processes and relate these processes to neuroscience data. Modeling at the single neuron level is necessary because this is the level at which information is exchanged between the computing elements of the brain; the neurons. Mesoscopic models tell us how neural elements interact to yield emergent behavior at the level of microcolumns and cortical columns. Macroscopic models can inform us about whole brain dynamics and interactions between large-scale neural systems such as cortical regions, the thalamus, and brain stem. Each level of description relates uniquely to neuroscience data, from single-unit recordings, through local field potentials to functional magnetic resonance imaging (fMRI), electroencephalogram (EEG), and magnetoencephalogram (MEG). Models of the cortex can establish which types of large-scale neuronal networks can perform computations and characterize their emergent properties. Mean-field and related formulations of dynamics also play an essential and complementary role as forward models that can be inverted given empirical data. This makes dynamic models critical in integrating theory and experiments. We argue that elaborating principled and informed models is a prerequisite for grounding empirical neuroscience in a cogent theoretical framework, commensurate with the achievements in the physical sciences.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/c_onTabelPrince/deco2008the2.pdf},
  journal  = {PLoS Comput Biol},
  keywords = {*Computational Biology,*Models; Neurological,*Nerve Net/chemistry/physiology,Animals,Biomedical Research/methods/standards,Cerebral Cortex/physiology,Electrophysiology,Empirical Research,Humans,Neurons/physiology,Nonlinear Dynamics,Terminology as Topic,Thermodynamics},
  year     = {2008},
}
% == BibTeX quality report for finleyMachineAdaptiveSystems1963:
% Missing required field 'publisher'

@Article{finlinsonOptimalControlExcitable2020,
  author     = {Finlinson, Kathleen and Shew, Woodrow L. and Larremore, Daniel B. and Restrepo, Juan G.},
  title      = {Optimal Control of Excitable Systems near Criticality},
  doi        = {10.1103/PhysRevResearch.2.033450},
  number     = {3},
  pages      = {033450},
  volume     = {2},
  abstract   = {Experiments suggest that the cerebral cortex gains several functional advantages by operating in a dynamical regime near the critical point of a phase transition. However, a long-standing criticism of this hypothesis is that critical dynamics are rather noisy, which might be detrimental to aspects of brain function that require precision. If the cortex does operate near criticality, how might it mitigate the noisy fluctuations? One possibility is that other parts of the brain may act to control the fluctuations and reduce cortical noise. To better understand basic aspects of controlling neural activity fluctuations, here we numerically and analytically study a network of binary neurons. We determine how the efficacy of controlling the population firing rate depends on proximity to criticality as well as different structural properties of the network. We find that control is most effective\textemdash errors are minimal for the widest range of target firing rates\textemdash near criticality. Optimal control is slightly away from criticality for networks with heterogeneous degree distributions. Thus, while criticality is the noisiest dynamical regime, it is also the regime that is easiest to control, which may offer a way to mitigate the noise.},
  journal    = {Physical Review Research},
  keywords   = {read},
  month      = sep,
  publisher  = {{American Physical Society}},
  readstatus = {read},
  year       = {2020},
}

@Article{vanniCriticalityTransmissionInformation2011,
  author   = {Vanni, F. and Lukovic, M. and Grigolini, P.},
  title    = {Criticality and Transmission of Information in a Swarm of Cooperative Units},
  doi      = {ARTN 078103 DOI 10.1103/PhysRevLett.107.078103},
  issn     = {1079-7114 (Electronic) 0031-9007 (Linking)},
  language = {English},
  pages    = {078103},
  volume   = {107},
  abstract = {We show that the intelligence of a swarm of cooperative units (birds) emerges at criticality, as an effect of the joint action of frequent organizational collapses and of spatial correlation as extended as the flock size. The organizational collapses make the birds become independent of one another, thereby allowing the flock to follow the direction of the lookout birds. Long-range correlation violates the principle of locality, making the lookout birds transmit information on either danger or resources with a time delay determined by the time distance between two consecutive collapses.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/criticality/vanni2011cri.pdf},
  journal  = {Phys Rev Lett},
  keywords = {flocks},
  month    = aug,
  year     = {2011},
}
% == BibTeX quality report for kollingNeuralMechanismsForaging2012:
% ? Title looks like it was stored in title-case in Zotero

@Article{kolMemoryOrchestraRole2021,
  author     = {Kol, Adi and Goshen, Inbal},
  title      = {The Memory Orchestra: The Role of Astrocytes and Oligodendrocytes in Parallel to Neurons},
  doi        = {10.1016/j.conb.2020.10.022},
  issn       = {0959-4388},
  language   = {en},
  pages      = {131--137},
  volume     = {67},
  abstract   = {For decades, the study of memory has been neuron-centric, yet neurons do not function in isolation. Today we know that neuronal activity is modulated by the environment within which it occurs, and is subject to modulation by different types of glial cells. In this review we summarize recent findings on the functional roles of astrocytes and oligodendrocytes, two major types of glia cells in the adult brain, in memory formation and its cellular underpinnings across multiple time points. We will discuss the different methods that are being used to investigate the astrocytic and oligodendroglial involvement in memory. We shall focus on chemogenetics and optogenetics, which support genetically specificity and high spatiotemporal resolution, attributes that are particularly well suited to the investigation of the contribution of unique cell types at the different stages of memory formation.},
  journal    = {Current Opinion in Neurobiology},
  month      = apr,
  shorttitle = {The Memory Orchestra},
  year       = {2021},
}
% == BibTeX quality report for oizumiMeasuringIntegratedInformation2016:
% ? Title looks like it was stored in title-case in Zotero

@Article{oizumiPhenomenologyMechanismsConsciousness2014,
  author   = {Oizumi, M. and Albantakis, L. and Tononi, G.},
  title    = {From the Phenomenology to the Mechanisms of Consciousness: Integrated Information Theory 3.0},
  doi      = {10.1371/journal.pcbi.1003588},
  issn     = {1553-7358 (Electronic) 1553-734X (Linking)},
  pages    = {e1003588},
  volume   = {10},
  abstract = {This paper presents Integrated Information Theory (IIT) of consciousness 3.0, which incorporates several advances over previous formulations. IIT starts from phenomenological axioms: information says that each experience is specific - it is what it is by how it differs from alternative experiences; integration says that it is unified - irreducible to non-interdependent components; exclusion says that it has unique borders and a particular spatio-temporal grain. These axioms are formalized into postulates that prescribe how physical mechanisms, such as neurons or logic gates, must be configured to generate experience (phenomenology). The postulates are used to define intrinsic information as "differences that make a difference" within a system, and integrated information as information specified by a whole that cannot be reduced to that specified by its parts. By applying the postulates both at the level of individual mechanisms and at the level of systems of mechanisms, IIT arrives at an identity: an experience is a maximally irreducible conceptual structure (MICS, a constellation of concepts in qualia space), and the set of elements that generates it constitutes a complex. According to IIT, a MICS specifies the quality of an experience and integrated information PhiMax its quantity. From the theory follow several results, including: a system of mechanisms may condense into a major complex and non-overlapping minor complexes; the concepts that specify the quality of an experience are always about the complex itself and relate only indirectly to the external environment; anatomical connectivity influences complexes and associated MICS; a complex can generate a MICS even if its elements are inactive; simple systems can be minimally conscious; complicated systems can be unconscious; there can be true "zombies" - unconscious feed-forward systems that are functionally equivalent to conscious complexes.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/integratedInformationTheory_iit/oizumi2014fro.pdf;/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/integratedInformationTheory_iit/oizumi2014fro.pdf;/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/integratedInformationTheory_iit/oizumi2014fro2.pdf;/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/integratedInformationTheory_iit/oizumi2014fro3.pdf;/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/integratedInformationTheory_iit/oizumi2014fro4.pdf},
  journal  = {PLoS Comput Biol},
  month    = may,
  year     = {2014},
}
% == BibTeX quality report for deneveBrainEfficientRobust2017a:
% ? Title looks like it was stored in title-case in Zotero

@Article{deneveCircularInferenceMistaken2016,
  author     = {Deneve, Sophie and Jardri, Renaud},
  title      = {Circular Inference: Mistaken Belief, Misplaced Trust},
  doi        = {10.1016/j.cobeha.2016.04.001},
  issn       = {2352-1546},
  pages      = {40--48},
  series     = {Computational Modeling},
  volume     = {11},
  abstract   = {At the clinical level, psychosis can be formalized as the formation of aberrant beliefs or percepts and has been proposed to result from disruptions in the excitation/inhibition (E/I) balance in cortical microcircuitry. However, these two conceptual approaches toward psychosis have yet to be correlated. Here, we review recent empirical and computational studies that enable an integrated understanding of how the brain may generate beliefs along a spectrum ranging from normal to pathology. We mainly focus on hierarchical predictive coding and circular inference. We will expose how these two frameworks may account for hallucinations, delusions, and reduced susceptibility to illusions, and we will additionally critically discuss their respective strengths and weaknesses as well as potential future research directions.},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/psychiatry/cmpsy/objectives/denve2016cir.pdf},
  journal    = {Current Opinion in Behavioral Sciences},
  keywords   = {read,review},
  month      = oct,
  readstatus = {read},
  shorttitle = {Circular Inference},
  year       = {2016},
}

@Article{chenGenomicAnalysesVisual2018,
  author     = {Chen, Biqing and Zhu, Zijian and Na, Ren and Fang, Wan and Zhang, Wenxia and Zhou, Qin and Zhou, Shanbi and Lei, Han and Huang, Ailong and Chen, Tingmei and Ni, Dongsheng and Gu, Yuping and Liu, Jianing and Fang, Fang and Rao, Yi},
  title      = {Genomic {{Analyses}} of {{Visual Cognition}}: {{Perceptual Rivalry}} and {{Top}}-{{Down Control}}},
  doi        = {10.1523/JNEUROSCI.1970-17.2018},
  issn       = {0270-6474, 1529-2401},
  language   = {en},
  number     = {45},
  pages      = {9668--9678},
  volume     = {38},
  journal    = {The Journal of Neuroscience},
  keywords   = {keypap,read},
  month      = nov,
  readstatus = {read},
  shorttitle = {Genomic {{Analyses}} of {{Visual Cognition}}},
  year       = {2018},
}

@Article{millerIntegrativeTheoryPrefrontal2001,
  author   = {Miller, E. K. and Cohen, J. D.},
  title    = {An Integrative Theory of Prefrontal Cortex Function},
  doi      = {10.1146/annurev.neuro.24.1.167},
  issn     = {0147-006X (Print) 0147-006X (Linking)},
  language = {English},
  pages    = {167--202},
  volume   = {24},
  abstract = {The prefrontal cortex has long been suspected to play an important role in cognitive control, in the ability to orchestrate thought and action in accordance with internal goals. Its neural basis, however, has remained a mystery. Here, we propose that cognitive control stems from the active maintenance of patterns of activity in the prefrontal cortex that represent goals and the means to achieve them. They provide bias signals to other brain structures whose net effect is to guide the flow of activity along neural pathways that establish the proper mappings between inputs, internal states, and outputs needed to perform a given task. We review neurophysiological, neurobiological, neuroimaging, and computational studies that support this theory and discuss its implications as well as further issues to be addressed},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/unfiled/miller2001an.pdf},
  journal  = {Annu Rev Neurosci},
  keywords = {*Models; Neurological,Animals,Attention/physiology,Cognition/physiology,Humans,Memory/physiology,Neural Pathways/physiology,Neurons/physiology,Prefrontal Cortex/*physiology},
  year     = {2001},
}

@Article{gutenbergEarthquakeMagnitudeIntensity1956,
  author    = {Gutenberg, B. and Richter, C. F.},
  title     = {Earthquake Magnitude, Intensity, Energy, and Acceleration({{Second}} Paper)},
  issn      = {0037-1106},
  language  = {en},
  number    = {2},
  pages     = {105--145},
  volume    = {46},
  journal   = {Bulletin of the Seismological Society of America},
  month     = apr,
  publisher = {{GeoScienceWorld}},
  year      = {1956},
}

@Article{echevesteCorticallikeDynamicsRecurrent2020,
  author     = {Echeveste, Rodrigo and Aitchison, Laurence and Hennequin, Guillaume and Lengyel, M{\'a}t{\'e}},
  title      = {Cortical-like Dynamics in Recurrent Circuits Optimized for Sampling-Based Probabilistic Inference},
  doi        = {10.1038/s41593-020-0671-1},
  issn       = {1546-1726},
  language   = {en},
  number     = {9},
  pages      = {1138--1149},
  volume     = {23},
  abstract   = {Sensory cortices display a suite of ubiquitous dynamical features, such as ongoing noise variability, transient overshoots and oscillations, that have so far escaped a common, principled theoretical account. We developed a unifying model for these phenomena by training a recurrent excitatory\textendash inhibitory neural circuit model of a visual cortical hypercolumn to perform sampling-based probabilistic inference. The optimized network displayed several key biological properties, including divisive normalization and stimulus-modulated noise variability, inhibition-dominated transients at stimulus onset and strong gamma oscillations. These dynamical features had distinct functional roles in speeding up inferences and made predictions that we confirmed in novel analyses of recordings from awake monkeys. Our results suggest that the basic motifs of cortical dynamics emerge as a consequence of the efficient implementation of the same computational function\textemdash fast sampling-based inference\textemdash and predict further properties of these motifs that can be tested in future experiments.},
  copyright  = {2020 The Author(s), under exclusive licence to Springer Nature America, Inc.},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neuroprinciples/computation/echeveste2020cor.pdf},
  journal    = {Nature Neuroscience},
  keywords   = {read},
  month      = sep,
  publisher  = {{Nature Publishing Group}},
  readstatus = {read},
  year       = {2020},
}

@Article{friesMechanismCognitiveDynamics2005,
  author   = {Fries, P.},
  title    = {A Mechanism for Cognitive Dynamics: Neuronal Communication through Neuronal Coherence},
  doi      = {DOI 10.1016/j.tics.2005.08.011},
  issn     = {1364-6613},
  language = {English},
  pages    = {474--480},
  volume   = {9},
  abstract = {At any one moment, many neuronal groups in our brain are active. Microelectrode recordings have characterized the activation of single neurons and fMRI has unveiled brain-wide activation patterns. Now it is time to understand how the many active neuronal groups interact with each other and how their communication is flexibly modulated to bring about our cognitive dynamics. I hypothesize that neuronal communication is mechanistically subserved by neuronal coherence. Activated neuronal groups oscillate and thereby undergo rhythmic excitability fluctuations that produce temporal windows for communication. Only coherently oscillating neuronal groups can interact effectively, because their communication windows for input and for output are open at the same times. Thus, a flexible pattern of coherence defines a flexible communication structure, which subserves our cognitive flexibility.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/oscillations/neural/fries2005a.pdf},
  journal  = {Trends Cogn Sci},
  keywords = {alert macaque,areas,attention,cat visual-cortex,coincidence detection,in-vivo,monkey,oscillatory responses,striate cortical activity,synchronization},
  month    = oct,
  year     = {2005},
}

@Article{moreno-boteNoiseinducedAlternationsAttractor2007a,
  author   = {{Moreno-Bote}, R. and Rinzel, J. and Rubin, N.},
  title    = {Noise-Induced Alternations in an Attractor Network Model of Perceptual Bistability},
  doi      = {10.1152/jn.00116.2007},
  issn     = {0022-3077 (Print) 0022-3077 (Linking)},
  number   = {3},
  pages    = {1125--39},
  volume   = {98},
  abstract = {When a stimulus supports two distinct interpretations, perception alternates in an irregular manner between them. What causes the bistable perceptual switches remains an open question. Most existing models assume that switches arise from a slow fatiguing process, such as adaptation or synaptic depression. We develop a new, attractor-based framework in which alternations are induced by noise and are absent without it. Our model goes beyond previous energy-based conceptualizations of perceptual bistability by constructing a neurally plausible attractor model that is implemented in both firing rate mean-field and spiking cell-based networks. The model accounts for known properties of bistable perceptual phenomena, most notably the increase in alternation rate with stimulation strength observed in binocular rivalry. Furthermore, it makes a novel prediction about the effect of changing stimulus strength on the activity levels of the dominant and suppressed neural populations, a prediction that could be tested with functional MRI or electrophysiological recordings. The neural architecture derived from the energy-based model readily generalizes to several competing populations, providing a natural extension for multistability phenomena.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/perception/multiStablePerception_msp/models/moreno-bote2007noi.pdf},
  journal  = {J Neurophysiol},
  keywords = {*Noise,Acclimatization,Animals,Auditory Perception/*physiology,Humans,Models; Neurological,Nerve Net/*physiology,Neurons/*physiology,Synapses/*physiology,Time Factors,Vision; Binocular},
  month    = sep,
  year     = {2007},
}

@Article{buzsakiWhatDoesGamma2015,
  author   = {Buzsaki, G. and Schomburg, E. W.},
  title    = {What Does Gamma Coherence Tell Us about Inter-Regional Neural Communication?},
  doi      = {10.1038/nn.3952},
  issn     = {1546-1726 (Electronic) 1097-6256 (Linking)},
  language = {en},
  pages    = {484--9},
  volume   = {18},
  abstract = {Neural oscillations have been measured and interpreted in multitudinous ways, with a variety of hypothesized functions in physiology, information processing and cognition. Much attention has been paid in recent years to gamma-band (30-100 Hz) oscillations and synchrony, with an increasing interest in 'high gamma' ({$>$}100 Hz) signals as mesoscopic measures of inter-regional communication. The biophysical origins of the measured variables are often difficult to precisely identify, however, making their interpretation fraught with pitfalls. Here we discuss how measurements of inter-regional gamma coherence can be prone to misinterpretation and suggest strategies for deciphering the roles that synchronized oscillations across brain networks may play in neural function.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/oscillations/neural/gamma/buzsaki2015wha.pdf},
  journal  = {Nat Neurosci},
  keywords = {Animals,Cortical Synchronization/*physiology,Electrophysiology/*methods/standards,Gamma Rhythm/*physiology,Humans,Membrane Potentials/*physiology,Nerve Net/cytology/*physiology},
  month    = apr,
  year     = {2015},
}

@InProceedings{deLearningForecastingOpinion2016,
  author    = {De, Abir and Valera, Isabel and Ganguly, Niloy and Bhattacharya, Sourangshu and {Gomez-Rodriguez}, Manuel},
  booktitle = {Proceedings of the 30th {{International Conference}} on {{Neural Information Processing Systems}}},
  title     = {Learning and Forecasting Opinion Dynamics in Social Networks},
  isbn      = {978-1-5108-3881-9},
  pages     = {397--405},
  publisher = {{Curran Associates Inc.}},
  series    = {{{NIPS}}'16},
  abstract  = {Social media and social networking sites have become a global pinboard for exposition and discussion of news, topics, and ideas, where social media users often update their opinions about a particular topic by learning from the opinions shared by their friends. In this context, can we learn a data-driven model of opinion dynamics that is able to accurately forecast users' opinions? In this paper, we introduce SLANT, a probabilistic modeling framework of opinion dynamics, which represents users' opinions over time by means of marked jump diffusion stochastic differential equations, and allows for efficient model simulation and parameter estimation from historical fine grained event data. We then leverage our framework to derive a set of efficient predictive formulas for opinion forecasting and identify conditions under which opinions converge to a steady state. Experiments on data gathered from Twitter show that our model provides a good fit to the data and our formulas achieve more accurate forecasting than alternatives.},
  address   = {{Red Hook, NY, USA}},
  month     = dec,
  year      = {2016},
}

@Article{lauEmpiricalSupportHigherorder2011,
  author   = {Lau, H. and Rosenthal, D.},
  title    = {Empirical Support for Higher-Order Theories of Conscious Awareness},
  doi      = {10.1016/j.tics.2011.05.009},
  issn     = {1879-307X (Electronic) 1364-6613 (Linking)},
  pages    = {365--73},
  volume   = {15},
  abstract = {Higher-order theories of consciousness argue that conscious awareness crucially depends on higher-order mental representations that represent oneself as being in particular mental states. These theories have featured prominently in recent debates on conscious awareness. We provide new leverage on these debates by reviewing the empirical evidence in support of the higher-order view. We focus on evidence that distinguishes the higher-order view from its alternatives, such as the first-order, global workspace and recurrent visual processing theories. We defend the higher-order view against several major criticisms, such as prefrontal activity reflects attention but not awareness, and prefrontal lesion does not abolish awareness. Although the higher-order approach originated in philosophical discussions, we show that it is testable and has received substantial empirical support.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/lau2011emp.pdf},
  journal  = {Trends Cogn Sci},
  keywords = {*Awareness,*Models; Neurological,Animals,Cerebral Cortex/*physiology,Consciousness/*physiology,Humans,Mental Disorders/pathology/physiopathology/psychology,Neural Pathways/physiology,Perception/physiology},
  month    = aug,
  year     = {2011},
}

@Article{olshausenEmergenceSimplecellReceptive1996,
  author   = {Olshausen, B. A. and Field, D. J.},
  title    = {Emergence of Simple-Cell Receptive Field Properties by Learning a Sparse Code for Natural Images},
  doi      = {10.1038/381607a0},
  issn     = {0028-0836 (Print) 0028-0836 (Linking)},
  pages    = {607--9},
  volume   = {381},
  abstract = {The receptive fields of simple cells in mammalian primary visual cortex can be characterized as being spatially localized, oriented and bandpass (selective to structure at different spatial scales), comparable to the basis functions of wavelet transforms. One approach to understanding such response properties of visual neurons has been to consider their relationship to the statistical structure of natural images in terms of efficient coding. Along these lines, a number of studies have attempted to train unsupervised learning algorithms on natural images in the hope of developing receptive fields with similar properties, but none has succeeded in producing a full set that spans the image space and contains all three of the above properties. Here we investigate the proposal that a coding strategy that maximizes sparseness is sufficient to account for these properties. We show that a learning algorithm that attempts to find sparse linear codes for natural scenes will develop a complete family of localized, oriented, bandpass receptive fields, similar to those found in the primary visual cortex. The resulting sparse image code provides a more efficient representation for later stages of processing because it possesses a higher degree of statistical independence among its outputs.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neuroprinciples/olshausen1996eme.pdf},
  journal  = {Nature},
  keywords = {Algorithms,Learning,Models; Neurological,Neurons/*physiology,Vision; Ocular/*physiology,Visual Cortex/cytology/*physiology princNeuro},
  month    = jun,
  year     = {1996},
}
% == BibTeX quality report for jiangImpairedFunctionalCriticality2018:
% ? Title looks like it was stored in title-case in Zotero

@Article{jiangMeasuringDirectionalityNeuronal2015,
  author   = {Jiang, Haiteng and Bahramisharif, Ali and {van Gerven}, Marcel A. J. and Jensen, Ole},
  title    = {Measuring Directionality between Neuronal Oscillations of Different Frequencies},
  doi      = {10.1016/j.neuroimage.2015.05.044},
  issn     = {1053-8119},
  pages    = {359--367},
  volume   = {118},
  abstract = {It is well established that neuronal oscillations at different frequencies interact with each other in terms of cross-frequency coupling (CFC). In particular, the phase of slower oscillations modulates the power of faster oscillations. This is referred to as phase\textendash amplitude coupling (PAC). Examples are alpha phase to gamma power coupling as observed in humans and theta phase to gamma power coupling as observed in the rat hippocampus. We here ask if the interaction between alpha and gamma oscillations is in the direction of the phase of slower oscillations driving the power of faster oscillations or conversely from the power of faster oscillations driving the phase of slower oscillations. To answer this question, we introduce a new measure to estimate the cross-frequency directionality (CFD). This measure is based on the phase-slope index (PSI) between the phase of slower oscillations and the power envelope of faster oscillations. Further, we propose a randomization framework for statistically evaluating the coupling measures when controlling for multiple comparisons over the investigated frequency ranges. The method was firstly validated on simulated data and next applied to resting state electrocorticography (ECoG) data. These results demonstrate that the method works reliably. In particular, we found that the power envelope of gamma oscillations drives the phase of slower oscillations in the alpha band. This surprising finding is not easily reconcilable with theories suggesting that feedback controlled alpha oscillations modulate feedforward processing reflected in the gamma band.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/multiModal/neuroNetworkRelationship_nnr/methods/jiang2015mea.pdf},
  journal  = {NeuroImage},
  keywords = {Cross-frequency coupling,Cross-frequency directionality,Neuronal oscillations},
  month    = sep,
  year     = {2015},
}

@InProceedings{mailheShiftinvariantDictionaryLearning2008a,
  author     = {Mailh{\'e}, B. and Lesage, S. and Gribonval, R. and Bimbot, F. and Vandergheynst, P.},
  booktitle  = {2008 16th {{European Signal Processing Conference}}},
  title      = {Shift-Invariant Dictionary Learning for Sparse Representations: {{Extending K}}-{{SVD}}},
  pages      = {1--5},
  abstract   = {Shift-invariant dictionaries are generated by taking all the possible shifts of a few short patterns. They are helpful to represent long signals where the same pattern can appear several times at different positions. We present an algorithm that learns shift invariant dictionaries from long training signals. This algorithm is an extension of K-SVD. It alternates a sparse decomposition step and a dictionary update step. The update is more difficult in the shift-invariant case because of occurrences of the same pattern that overlap. We propose and evaluate an unbiased extension of the method used in K-SVD, i.e. a method able to exactly retrieve the original dictionary in a noiseless case.},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/dataAnalysis/clustering/mailh2008shi.pdf},
  issn       = {2219-5491},
  keywords   = {Approximation methods,Bayes methods,Dictionaries,dictionary update,K-SVD extension,Linear programming,Matching pursuit algorithms,shift invariant dictionary learning,Signal processing algorithms,signal representation,Signal to noise ratio,singular value decomposition,sparse decomposition,sparse matrices,sparse signal representation},
  month      = aug,
  shorttitle = {Shift-Invariant Dictionary Learning for Sparse Representations},
  year       = {2008},
}

@Article{zaldivarDopamineinducedDissociationBOLD2014,
  author   = {Zaldivar, D. and Rauch, A. and Whittingstall, K. and Logothetis, N. K. and Goense, J.},
  title    = {Dopamine-Induced Dissociation of {{BOLD}} and Neural Activity in Macaque Visual Cortex},
  doi      = {10.1016/j.cub.2014.10.006},
  issn     = {1879-0445 (Electronic) 0960-9822 (Linking)},
  pages    = {2805--11},
  volume   = {24},
  abstract = {Neuromodulators determine how neural circuits process information during cognitive states such as wakefulness, attention, learning, and memory. fMRI can provide insight into their function and dynamics, but their exact effect on BOLD responses remains unclear, limiting our ability to interpret the effects of changes in behavioral state using fMRI. Here, we investigated the effects of dopamine (DA) injections on neural responses and haemodynamic signals in macaque primary visual cortex (V1) using fMRI (7T) and intracortical electrophysiology. Aside from DA's involvement in diseases such as Parkinson's and schizophrenia, it also plays a role in visual perception. We mimicked DAergic neuromodulation by systemic injection of L-DOPA and Carbidopa (LDC) or by local application of DA in V1 and found that systemic application of LDC increased the signal-to-noise ratio (SNR) and amplitude of the visually evoked neural responses in V1. However, visually induced BOLD responses decreased, whereas cerebral blood flow (CBF) responses increased. This dissociation of BOLD and CBF suggests that dopamine increases energy metabolism by a disproportionate amount relative to the CBF response, causing the reduced BOLD response. Local application of DA in V1 had no effect on neural activity, suggesting that the dopaminergic effects are mediated by long-range interactions. The combination of BOLD-based and CBF-based fMRI can provide a signature of dopaminergic neuromodulation, indicating that the application of multimodal methods can improve our ability to distinguish sensory processing from neuromodulatory effects.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/multiModal/zaldivar2014dop.pdf},
  journal  = {Curr Biol},
  keywords = {Animals,Carbidopa/pharmacology,Cerebrovascular Circulation/*drug effects,Dopamine/*metabolism/pharmacology,Energy Metabolism,Female,Injections; Intraventricular,Macaca mulatta,Magnetic Resonance Imaging,Male,Signal-To-Noise Ratio,Visual Cortex/blood supply/drug effects/*physiology},
  month    = dec,
  year     = {2014},
}

@Article{eliasmithUnifiedApproachBuilding2005,
  author     = {Eliasmith, Chris},
  title      = {A {{Unified Approach}} to {{Building}} and {{Controlling Spiking Attractor Networks}}},
  doi        = {10.1162/0899766053630332},
  issn       = {0899-7667},
  number     = {6},
  pages      = {1276--1314},
  volume     = {17},
  abstract   = {Extending work in Eliasmith and Anderson (2003), we employ a general framework to construct biologically plausible simulations of the three classes of attractor networks relevant for biological systems: static (point, line, ring, and plane) attractors, cyclic attractors, and chaotic attractors. We discuss these attractors in the context of the neural systems that they have been posited to help explain: eye control, working memory, and head direction; locomotion (specifically swimming); and olfaction, respectively. We then demonstrate how to introduce control into these models. The addition of control shows how attractor networks can be used as subsystems in larger neural systems, demonstrates how a much larger class of networks can be related to attractor networks, and makes it clear how attractor networks can be exploited for various information processing tasks in neurobiological systems.},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neuroprinciples/computation/eliasmith2005a.pdf},
  journal    = {Neural Computation},
  keywords   = {read},
  month      = jun,
  readstatus = {read},
  year       = {2005},
}

@Article{hasenstaubInhibitoryPostsynapticPotentials2005,
  author   = {Hasenstaub, A. and Shu, Y. and Haider, B. and Kraushaar, U. and Duque, A. and McCormick, D. A.},
  title    = {Inhibitory Postsynaptic Potentials Carry Synchronized Frequency Information in Active Cortical Networks},
  doi      = {10.1016/j.neuron.2005.06.016},
  issn     = {0896-6273 (Print) 0896-6273 (Linking)},
  number   = {3},
  pages    = {423--35},
  volume   = {47},
  abstract = {Temporal precision in spike timing is important in cortical function, interactions, and plasticity. We found that, during periods of recurrent network activity (UP states), cortical pyramidal cells in vivo and in vitro receive strong barrages of both excitatory and inhibitory postsynaptic potentials, with the inhibitory potentials showing much higher power at all frequencies above approximately 10 Hz and more synchrony between nearby neurons. Fast-spiking inhibitory interneurons discharged strongly in relation to higher-frequency oscillations in the field potential in vivo and possess membrane, synaptic, and action potential properties that are advantageous for transmission of higher-frequency activity. Intracellular injection of synaptic conductances having the characteristics of the recorded EPSPs and IPSPs reveal that IPSPs are important in controlling the timing and probability of action potential generation in pyramidal cells. Our results support the hypothesis that inhibitory networks are largely responsible for the dissemination of higher-frequency activity in cortex.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/multiModal/neuroNetworkRelationship_nnr/observations/hasenstaub2005inh.pdf},
  journal  = {Neuron},
  keywords = {*Cortical Synchronization,Action Potentials/physiology,Animals,Cerebral Cortex/*physiology,Excitatory Postsynaptic Potentials,Ferrets,In Vitro Techniques,Interneurons/physiology,Male,Membrane Potentials,Nerve Net/*physiology,Neural Inhibition/*physiology,Neurons/physiology,Oscillometry,Pyramidal Cells/physiology,Reaction Time,Refractory Period; Electrophysiological,Synapses/physiology,Synaptic Transmission/*physiology},
  month    = aug,
  year     = {2005},
}

@Article{bellLevelsLoopsFuture1999,
  author    = {Bell, Anthony J},
  title     = {Levels and Loops: The Future of Artificial Intelligence and Neuroscience},
  language  = {en},
  pages     = {8},
  file      = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neuroprinciples/multiScale/bell1999lev.pdf},
  ids       = {zekiLevelsLoopsFuture1999},
  journal   = {Phil.Trans. R. Soc. Lond.B},
  publisher = {{Royal Society}},
  year      = {1999},
}
% == BibTeX quality report for ditzingerOscillationsPerceptionAmbiguous1989a:
% ? Title looks like it was stored in title-case in Zotero

@Article{ditzingerOscillationsPerceptionAmbiguous1989b,
  author   = {Ditzinger, T. and Haken, H.},
  title    = {Oscillations in the {{Perception}} of {{Ambiguous Patterns}} - a {{Model Based}} on {{Synergetics}}},
  doi      = {Doi 10.1007/Bf00203175},
  issn     = {0340-1200},
  language = {English},
  number   = {4},
  pages    = {279--287},
  volume   = {61},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/perception/multiStablePerception_msp/ditzinger1989osc.pdf},
  journal  = {Biol Cybern},
  year     = {1989},
}
% == BibTeX quality report for karFastRecurrentProcessing2020a:
% ? Title looks like it was stored in title-case in Zotero

@Article{karimiabadchiSpatiotemporalPatternsNeocortical2020,
  author    = {Karimi Abadchi, J and {Nazari-Ahangarkolaee}, Mojtaba and Gattas, Sandra and {Bermudez-Contreras}, Edgar and Luczak, Artur and McNaughton, Bruce L and Mohajerani, Majid H},
  title     = {Spatiotemporal Patterns of Neocortical Activity around Hippocampal Sharp-Wave Ripples},
  doi       = {10.7554/eLife.51972},
  editor    = {Deshmukh, Sachin and Colgin, Laura L and Deshmukh, Sachin},
  issn      = {2050-084X},
  pages     = {e51972},
  volume    = {9},
  abstract  = {A prevalent model is that sharp-wave ripples (SWR) arise `spontaneously' in CA3 and propagate recent memory traces outward to the neocortex to facilitate memory consolidation there. Using voltage and extracellular glutamate transient recording over widespread regions of mice dorsal neocortex in relation to CA1 multiunit activity (MUA) and SWR, we find that the largest SWR-related modulation occurs in retrosplenial cortex; however, contrary to the unidirectional hypothesis, neocortical activation exhibited a continuum of activation timings relative to SWRs, varying from leading to lagging. Thus, contrary to the model in which SWRs arise `spontaneously' in the hippocampus, neocortical activation often precedes SWRs and may thus constitute a trigger event in which neocortical information seeds associative reactivation of hippocampal `indices'. This timing continuum is consistent with a dynamics in which older, more consolidated memories may in fact initiate the hippocampal-neocortical dialog, whereas reactivation of newer memories may be initiated predominantly in the hippocampus.},
  journal   = {eLife},
  keywords  = {hippocampal-neocortical interaction,hippocampus,memory consolidation,neocortex,sharp-wave ripple,wide-field mesoscale optical imaging},
  month     = mar,
  publisher = {{eLife Sciences Publications, Ltd}},
  year      = {2020},
}
% == BibTeX quality report for kalisvaartInfluenceRetinalImage2013a:
% ? Title looks like it was stored in title-case in Zotero

@Article{kalloniatisFisherInformationCriticality2018,
  author     = {Kalloniatis, Alexander C. and Zuparic, Mathew L. and Prokopenko, Mikhail},
  title      = {Fisher Information and Criticality in the {{Kuramoto}} Model of Nonidentical Oscillators},
  doi        = {10.1103/PhysRevE.98.022302},
  number     = {2},
  pages      = {022302},
  volume     = {98},
  abstract   = {We use the Fisher information to provide a lens on the transition to synchronization of the Kuramoto model of nonidentical frequencies on a variety of undirected graphs. We numerically solve the equations of motion for a N=400 complete graph and N=1000 small-world, scale-free, uniform random, and random regular graphs. For large but finite graphs of small average diameter the Fisher information F as a function of coupling shows a peak closely coinciding with the critical point as determined by Kuramoto's order parameter or synchronization measure r. However, for graphs of larger average diameter the position of the peak in F differs from the critical point determined by estimates of r. On the one hand, this is a finite-size effect even at N=1000; however, we show across a range of topologies that the Fisher information peak points to a transition for smaller graphs that indicates structural changes in the numbers of locally phase-synchronized clusters, often directly from metastable to stable frequency synchronization. Solving explicitly for a two-cluster ansatz subject to Gaussian noise shows that the Fisher infomation peaks at such a transition. We discuss the implications for Fisher information as an indicator for edge-of-chaos phenomena in finite-coupled oscillator systems.},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/criticality/kalloniatis2018fis.pdf},
  journal    = {Physical Review E},
  keywords   = {read},
  month      = aug,
  publisher  = {{American Physical Society}},
  readstatus = {read},
  year       = {2018},
}

@Article{logothetisHippocampalCorticalInteraction2012,
  author    = {Logothetis, N. K. and Eschenko, O. and Murayama, Y. and Augath, M. and Steudel, T. and Evrard, H. C. and Besserve, M. and Oeltermann, A.},
  title     = {Hippocampal\textendash Cortical Interaction during Periods of Subcortical Silence},
  doi       = {10.1038/nature11618},
  issn      = {1476-4687},
  language  = {en},
  number    = {7425},
  pages     = {547--553},
  volume    = {491},
  abstract  = {Hippocampal ripples, episodic high-frequency field-potential oscillations primarily occurring during sleep and calmness, have been described in mice, rats, rabbits, monkeys and humans, and so far they have been associated with retention of previously acquired awake experience. Although hippocampal ripples have been studied in detail using neurophysiological methods, the global effects of ripples on the entire brain remain elusive, primarily owing to a lack of methodologies permitting concurrent hippocampal recordings and whole-brain activity mapping. By combining electrophysiological recordings in hippocampus with ripple-triggered functional magnetic resonance imaging, here we show that most of the cerebral cortex is selectively activated during the ripples, whereas most diencephalic, midbrain and brainstem regions are strongly and consistently inhibited. Analysis of regional temporal response patterns indicates that thalamic activity suppression precedes the hippocampal population burst, which itself is temporally bounded by massive activations of association and primary cortical areas. These findings suggest that during off-line memory consolidation, synergistic thalamocortical activity may be orchestrating a privileged interaction state between hippocampus and cortex by silencing the output of subcortical centres involved in sensory processing or potentially mediating procedural learning. Such a mechanism would cause minimal interference, enabling consolidation of hippocampus-dependent memory.},
  copyright = {2012 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  journal   = {Nature},
  month     = nov,
  publisher = {{Nature Publishing Group}},
  year      = {2012},
}

@Article{vinckImprovedMeasuresPhasecoupling2012,
  author   = {Vinck, M. and Battaglia, F. P. and Womelsdorf, T. and Pennartz, C.},
  title    = {Improved Measures of Phase-Coupling between Spikes and the {{Local Field Potential}}},
  doi      = {10.1007/s10827-011-0374-4},
  issn     = {1573-6873 (Electronic) 0929-5313 (Linking)},
  language = {en},
  pages    = {53--75},
  volume   = {33},
  abstract = {An important tool to study rhythmic neuronal synchronization is provided by relating spiking activity to the Local Field Potential (LFP). Two types of interdependent spike-LFP measures exist. The first approach is to directly quantify the consistency of single spike-LFP phases across spikes, referred to here as point-field phase synchronization measures. We show that conventional point-field phase synchronization measures are sensitive not only to the consistency of spike-LFP phases, but are also affected by statistical dependencies between spike-LFP phases, caused by e.g. non-Poissonian history-effects within spike trains such as bursting and refractoriness. To solve this problem, we develop a new pairwise measure that is not biased by the number of spikes and not affected by statistical dependencies between spike-LFP phases. The second approach is to quantify, similar to EEG-EEG coherence, the consistency of the relative phase between spike train and LFP signals across trials instead of across spikes, referred to here as spike train to field phase synchronization measures. We demonstrate an analytical relationship between point-field and spike train to field phase synchronization measures. Based on this relationship, we prove that the spike train to field pairwise phase consistency (PPC), a quantity closely related to the squared spike-field coherence, is a monotonically increasing function of the number of spikes per trial. This derived relationship is exact and analytic, and takes a linear form for weak phase-coupling. To solve this problem, we introduce a corrected version of the spike train to field PPC that is independent of the number of spikes per trial. Finally, we address the problem that dependencies between spike-LFP phase and the number of spikes per trial can cause spike-LFP phase synchronization measures to be biased by the number of trials. We show how to modify the developed point-field and spike train to field phase synchronization measures in order to make them unbiased by the number of trials.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/multiModal/neuroNetworkRelationship_nnr/methods/vinck2012imp.pdf},
  journal  = {J Comput Neurosci},
  keywords = {*Models; Neurological,*Neural Networks (Computer),Action Potentials/*physiology,Animals,Electroencephalography,Electroencephalography Phase Synchronization/*physiology,Humans,Nerve Net/physiology,Neurons/*physiology},
  month    = aug,
  year     = {2012},
}

@Article{decoEmergingConceptsDynamical2011,
  author   = {Deco, G. and Jirsa, V. K. and McIntosh, A. R.},
  title    = {Emerging Concepts for the Dynamical Organization of Resting-State Activity in the Brain},
  doi      = {10.1038/nrn2961},
  issn     = {1471-0048 (Electronic) 1471-003X (Linking)},
  language = {en},
  pages    = {43--56},
  volume   = {12},
  abstract = {A broad body of experimental work has demonstrated that apparently spontaneous brain activity is not random. At the level of large-scale neural systems, as measured with functional MRI (fMRI), this ongoing activity reflects the organization of a series of highly coherent functional networks. These so-called resting-state networks (RSNs) closely relate to the underlying anatomical connectivity but cannot be understood in those terms alone. Here we review three large-scale neural system models of primate neocortex that emphasize the key contributions of local dynamics, signal transmission delays and noise to the emerging RSNs. We propose that the formation and dissolution of resting-state patterns reflects the exploration of possible functional network configurations around a stable anatomical skeleton.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/deco2011eme.pdf},
  journal  = {Nat Rev Neurosci},
  keywords = {*Magnetic Resonance Imaging/methods,Animals,Brain/*physiology,Humans,Nerve Net/*physiology,Neural Pathways/physiology,Rest/*physiology,review},
  month    = jan,
  year     = {2011},
}
% == BibTeX quality report for hoffmannOptimizationSelfOrganizedCriticality2018:
% ? Title looks like it was stored in title-case in Zotero

@Article{hoffmannOptimizationSelfOrganizedCriticality2018a,
  author     = {Hoffmann, Heiko and Payton, David W.},
  title      = {Optimization by {{Self}}-{{Organized Criticality}}},
  doi        = {10.1038/s41598-018-20275-7},
  issn       = {2045-2322},
  language   = {en},
  number     = {1},
  pages      = {2358},
  volume     = {8},
  abstract   = {Self-organized criticality (SOC) is a phenomenon observed in certain complex systems of multiple interacting components, e.g., neural networks, forest fires, and power grids, that produce power-law distributed avalanche sizes. Here, we report the surprising result that the avalanches from an SOC process can be used to solve non-convex optimization problems. To generate avalanches, we use the Abelian sandpile model on a graph that mirrors the graph of the optimization problem. For optimization, we map the avalanche areas onto search patterns for optimization, while the SOC process receives no feedback from the optimization itself. The resulting method can be applied without parameter tuning to a wide range of optimization problems, as demonstrated on three problems: finding the ground-state of an Ising spin glass, graph coloring, and image segmentation. We find that SOC search is more efficient compared to other random search methods, including simulated annealing, and unlike annealing, it is parameter free, thereby eliminating the time-consuming requirement to tune an annealing temperature schedule.},
  copyright  = {2018 The Author(s)},
  journal    = {Scientific Reports},
  keywords   = {read},
  month      = feb,
  publisher  = {{Nature Publishing Group}},
  readstatus = {read},
  year       = {2018},
}
% == BibTeX quality report for wolpertFreeEnergyRequirements2016:
% ? Title looks like it was stored in title-case in Zotero

@Article{womelsdorfBurstFiringSynchronizes2014,
  author   = {Womelsdorf, T. and Ardid, S. and Everling, S. and Valiante, T. A.},
  title    = {Burst Firing Synchronizes Prefrontal and Anterior Cingulate Cortex during Attentional Control},
  doi      = {10.1016/j.cub.2014.09.046},
  issn     = {1879-0445 (Electronic) 0960-9822 (Linking)},
  pages    = {2613--21},
  volume   = {24},
  abstract = {BACKGROUND: It is widely held that single cells in anterior cingulate and lateral prefrontal cortex (ACC/PFC) coordinate their activity during attentional processes, although cellular activity that may underlie such coordination across ACC/PFC has not been identified. We thus recorded cells in five ACC/PFC subfields of macaques engaged in a selective attention task, characterized those spiking events that indexed attention, and identified how spiking of distinct cell populations synchronized between brain areas. RESULTS: We found that cells in ACC/PFC increased the firing of brief 200 Hz spike bursts when subjects shifted attention and engaged in selective visual processing. In contrast to nonburst spikes, burst spikes synchronized over large distances to local field potentials at narrow beta (12-20 Hz) and at gamma (50-75 Hz) frequencies. Long-range burst synchronization was anatomically specific, functionally connecting those subfields in area 24 (ACC) and area 46 (PFC) that are key players of attentional control. By splitting cells into putative excitatory (pE) and inhibitory (pI) cells by their broad and narrow spikes, we identified that bursts of pI cells preceded and that bursts of pE cells followed in time periods of maximal beta coherent network activity. In contrast, gamma bursts were transient impulses with equal timing across cell classes. CONCLUSIONS: These findings suggest that processes underlying burst firing and burst synchronization are candidate mechanisms to coordinate attention information across brain areas. We speculate that distinct burst-firing motifs realize beta and gamma synchrony to trigger versus maintain functional network states during goal-directed behavior.},
  journal  = {Curr Biol},
  keywords = {*Action Potentials,*Attention,Animals,Brain Mapping,Gyrus Cinguli/*physiology,Macaca/*physiology,Photic Stimulation,Prefrontal Cortex/physiology},
  month    = nov,
  year     = {2014},
}
% == BibTeX quality report for LukensLaboratory:
% ? Title looks like it was stored in title-case in Zotero

@Article{lukovicTransmissionInformationCriticality2014,
  author     = {Lukovic, M. and Vanni, F. and Svenkeson, A. and Grigolini, P.},
  title      = {Transmission of Information at Criticality},
  doi        = {DOI 10.1016/j.physa.2014.08.066},
  issn       = {0378-4371},
  language   = {English},
  pages      = {430--438},
  volume     = {416},
  abstract   = {We study the problem of information transmission in complex cooperative systems to prove that adaptivity rather than diffusion is the main source of information transport at criticality. We adopt two different cooperative models, the two-dimensional Decision Making Model (DMM), and the one-dimensional Flock Model (FM) inspired by the cooperation between birds. The criticality-induced consensus is intermittently broken by the occurrence of moments of high susceptibility, which we call free-will states. We construct a network A based on the DMM and FM that is perturbed by a similar network B. Some units of A, called lookout birds, follow the directions of the mean field generated by B, while the rest are blind to B. When both networks are at criticality a small percentage of lookout birds establish the synchronization between B and A as a result of the nonergodic nature of the free-will state dynamics. (C) 2014 Elsevier B.V. All rights reserved.},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/criticality/lukovic2014tra.pdf},
  journal    = {Physica a-Statistical Mechanics and Its Applications},
  keywords   = {criticality,diffusion,ergodicity breakdown,flocks,information transfer,intermittency,particles,phase-transition,read,systems},
  month      = dec,
  readstatus = {read},
  year       = {2014},
}

@Article{harrisCorticalConnectivitySensory2013,
  author   = {Harris, K. D. and {Mrsic-Flogel}, T. D.},
  title    = {Cortical Connectivity and Sensory Coding},
  doi      = {10.1038/nature12654},
  issn     = {1476-4687 (Electronic) 0028-0836 (Linking)},
  language = {English},
  number   = {7474},
  pages    = {51--8},
  volume   = {503},
  abstract = {The sensory cortex contains a wide array of neuronal types, which are connected together into complex but partially stereotyped circuits. Sensory stimuli trigger cascades of electrical activity through these circuits, causing specific features of sensory scenes to be encoded in the firing patterns of cortical populations. Recent research is beginning to reveal how the connectivity of individual neurons relates to the sensory features they encode, how differences in the connectivity patterns of different cortical cell classes enable them to encode information using different strategies, and how feedback connections from higher-order cortex allow sensory information to be integrated with behavioural context.},
  file     = {/Users/ssafavi/Documents/libraries/EndnoteLib_fromWin407/EndnoteLib_MPIPClocal_20170723.Data/PDF/1278746397/Harris-2013.pdf},
  journal  = {Nature},
  keywords = {Animals,Auditory Cortex/cytology/physiology,Cerebral Cortex/*cytology/*physiology,Interneurons/cytology/physiology,keypap,Models; Neurological,Neural Pathways/*cytology/physiology,Sensory Receptor Cells/*cytology/*physiology,Somatosensory Cortex/cytology/physiology,Visual Cortex/cytology/physiology},
  month    = nov,
  year     = {2013},
}
% == BibTeX quality report for larremoreInhibitionCausesCeaseless2014:
% ? Title looks like it was stored in title-case in Zotero

@Article{larremorePredictingCriticalityDynamic2011,
  author     = {Larremore, Daniel B. and Shew, Woodrow L. and Restrepo, Juan G.},
  title      = {Predicting {{Criticality}} and {{Dynamic Range}} in {{Complex Networks}}: {{Effects}} of {{Topology}}},
  doi        = {10.1103/PhysRevLett.106.058101},
  number     = {5},
  pages      = {058101},
  volume     = {106},
  abstract   = {The collective dynamics of a network of coupled excitable systems in response to an external stimulus depends on the topology of the connections in the network. Here we develop a general theoretical approach to study the effects of network topology on dynamic range, which quantifies the range of stimulus intensities resulting in distinguishable network responses. We find that the largest eigenvalue of the weighted network adjacency matrix governs the network dynamic range. When the largest eigenvalue is exactly one, the system is in a critical state and its dynamic range is maximized. Further, we examine higher order behavior of the steady state system, which predicts that networks with more homogeneous degree distributions should have higher dynamic range. Our analysis, confirmed by numerical simulations, generalizes previous studies in terms of the largest eigenvalue of the adjacency matrix.},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/criticality/larremore2011pre.pdf},
  journal    = {Physical Review Letters},
  month      = jan,
  publisher  = {{American Physical Society}},
  shorttitle = {Predicting {{Criticality}} and {{Dynamic Range}} in {{Complex Networks}}},
  year       = {2011},
}

@Article{maierDivergenceFMRINeural2008a,
  author   = {Maier, A. and Wilke, M. and Aura, C. and Zhu, C. and Ye, F. Q. and Leopold, D. A.},
  title    = {Divergence of {{fMRI}} and Neural Signals in {{V1}} during Perceptual Suppression in the Awake Monkey},
  doi      = {10.1038/nn.2173},
  issn     = {1546-1726 (Electronic) 1097-6256 (Linking)},
  language = {en},
  number   = {10},
  pages    = {1193--200},
  volume   = {11},
  abstract = {The role of primary visual cortex (V1) in determining the contents of perception is controversial. Human functional magnetic resonance imaging (fMRI) studies of perceptual suppression have revealed a robust drop in V1 activity when a stimulus is subjectively invisible. In contrast, monkey single-unit recordings have failed to demonstrate such perception-locked changes in V1. To investigate the basis of this discrepancy, we measured both the blood oxygen level-dependent (BOLD) response and several electrophysiological signals in two behaving monkeys. We found that all signals were in good agreement during conventional stimulus presentation, showing strong visual modulation to presentation and removal of a stimulus. During perceptual suppression, however, only the BOLD response and the low-frequency local field potential (LFP) power showed decreases, whereas the spiking and high-frequency LFP power were unaffected. These results demonstrate that the coupling between the BOLD and electrophysiological signals in V1 is context dependent, with a marked dissociation occurring during perceptual suppression.},
  file     = {/Users/ssafavi/Documents/libraries/EndnoteLib_fromWin407/EndnoteLib_MPIPClocal_20170723.Data/PDF/0681362706/Maier-20081.pdf;/Users/ssafavi/Documents/libraries/EndnoteLib_fromWin407/EndnoteLib_MPIPClocal_20170723.Data/PDF/4118925727/Maier-2008.pdf},
  journal  = {Nat Neurosci},
  keywords = {*Brain Mapping,*Inhibition (Psychology),*Magnetic Resonance Imaging,Action Potentials/physiology,Animals,Image Processing; Computer-Assisted/methods,keypap,Macaca mulatta,Male,Neurons/*physiology,Oxygen/blood,Photic Stimulation/methods,Psychomotor Performance/physiology,Psychophysics/methods,Time Factors,Visual Cortex/*blood supply/cytology,Visual Perception/*physiology,Wakefulness},
  month    = oct,
  year     = {2008},
}
% == BibTeX quality report for simeoneLearningAlgorithmsSignal2019:
% ? Title looks like it was stored in title-case in Zotero

@Article{simoncelliNaturalImageStatistics2001,
  author   = {Simoncelli, Eero P and Olshausen, Bruno A},
  title    = {Natural {{Image Statistics}} and {{Neural Representation}}},
  doi      = {10.1146/annurev.neuro.24.1.1193},
  number   = {1},
  pages    = {1193--1216},
  volume   = {24},
  abstract = {It has long been assumed that sensory neurons are adapted, through both evolutionary and developmental processes, to the statistical properties of the signals to which they are exposed. Attneave (1954), Barlow (1961) proposed that information theory could provide a link between environmental statistics and neural responses through the concept of coding efficiency. Recent developments in statistical modeling, along with powerful computational tools, have enabled researchers to study more sophisticated statistical models for visual images, to validate these models empirically against large sets of data, and to begin experimentally testing the efficient coding hypothesis for both individual neurons and populations of neurons.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/coding/Efficient_Optimal/simoncelli2001nat.pdf},
  journal  = {Annual Review of Neuroscience},
  pmid     = {11520932},
  year     = {2001},
}
% == BibTeX quality report for mathisEmergenceLifeFirstOrder2017:
% ? Title looks like it was stored in title-case in Zotero

@Article{mathisEmergenceLifeFirstOrder2017a,
  author     = {Mathis, Cole and Bhattacharya, Tanmoy and Walker, Sara Imari},
  title      = {The {{Emergence}} of {{Life}} as a {{First}}-{{Order Phase Transition}}},
  doi        = {10.1089/ast.2016.1481},
  issn       = {1531-1074},
  number     = {3},
  pages      = {266--276},
  volume     = {17},
  abstract   = {It is well known that life on Earth alters its environment over evolutionary and geological timescales. An important open question is whether this is a result of evolutionary optimization or a universal feature of life. In the latter case, the origin of life would be coincident with a shift in environmental conditions. Here we present a model for the emergence of life in which replicators are explicitly coupled to their environment through the recycling of a finite supply of resources. The model exhibits a dynamic, first-order phase transition from nonlife to life, where the life phase is distinguished by selection on replicators. We show that environmental coupling plays an important role in the dynamics of the transition. The transition corresponds to a redistribution of matter in replicators and their environment, driven by selection on replicators, exhibiting an explosive growth in diversity as replicators are selected. The transition is accurately tracked by the mutual information shared between replicators and their environment. In the absence of successfully repartitioning system resources, the transition fails to complete, leading to the possibility of many frustrated trials before life first emerges. Often, the replicators that initiate the transition are not those that are ultimately selected. The results are consistent with the view that life's propensity to shape its environment is indeed a universal feature of replicators, characteristic of the transition from nonlife to life. We discuss the implications of these results for understanding life's emergence and evolutionary transitions more broadly. Key Words: Origin of life\textemdash Prebiotic evolution\textemdash Astrobiology\textemdash Biopolymers\textemdash Life. Astrobiology 17, 266\textendash 276.},
  journal    = {Astrobiology},
  keywords   = {r18,read},
  month      = mar,
  publisher  = {{Mary Ann Liebert, Inc., publishers}},
  readstatus = {read},
  year       = {2017},
}

@Article{atwalStatisticalMechanicsMultistable2014,
  author     = {Atwal, G. S.},
  title      = {Statistical Mechanics of Multistable Perception},
  doi        = {10.1101/008177},
  language   = {en},
  abstract   = {The stochastic dynamics of multistable perception poses an enduring challenge to our understanding of neural signal processing in the brain. We show that the emergence of perception switching and stability can be understood using principles of probabilistic Bayesian inference where the prior temporal expectations are matched to a scale-free power spectrum, characteristic of fluctuations in the natural environment. The optimal percept dynamics are inferred by an exact mapping of the statistical estimation problem to the motion of a dissipative quantum particle in a multi-well potential. In the bistable case the problem is further mapped to a long-ranged Ising model. Optimal inference in the presence of a 1/f noise prior leads to critical dynamics, exhibiting a dynamical phase transition from unstable perception to stable perception, as demonstrated in recent experiments. The effect of stimulus fluctuations and perception bias is also discussed.},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/collectiveBehaviors/cognition/atwal2014sta.pdf;/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/perception/multiStablePerception_msp/models/atwal2014sta.pdf;/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/perception/multiStablePerception_msp/models/atwal2014sta.pdf;/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neuroprinciples/atwal2014sta.pdf},
  journal    = {bioRxiv},
  keywords   = {princNeuro,r10,read},
  month      = aug,
  readstatus = {read},
  year       = {2014},
}

@Article{sheinbergRoleTemporalCortical1997,
  author   = {Sheinberg, D. L. and Logothetis, N. K.},
  title    = {The Role of Temporal Cortical Areas in Perceptual Organization},
  issn     = {0027-8424 (Print) 0027-8424 (Linking)},
  number   = {7},
  pages    = {3408--13},
  volume   = {94},
  abstract = {The visual areas of the temporal lobe of the primate are thought to be essential for the representation of visual objects. To examine the role of these areas in the visual awareness of a stimulus, we recorded the activity of single neurons in monkeys trained to report their percepts when viewing ambiguous stimuli. Visual ambiguity was induced by presenting incongruent images to the two eyes, a stimulation condition known to instigate binocular rivalry, during which one image is seen at a given time while the other is perceptually suppressed. Previous recordings in areas V1, V2, V4, and MT of monkeys experiencing binocular rivalry showed that only a small proportion of striate and early extrastriate neurons discharge exclusively when the driving stimulus is seen. In contrast, the activity of almost all neurons in the inferior temporal cortex and the visual areas of the cortex of superior temporal sulcus was found to be contingent upon the perceptual dominance of an effective visual stimulus. These areas thus appear to represent a stage of processing beyond the resolution of ambiguities--and thus beyond the processes of perceptual grouping and image segmentation--where neural activity reflects the brain's internal view of objects, rather than the effects of the retinal stimulus on cells encoding simple visual features or shape primitives.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/perception/multiStablePerception_msp/sheinberg1997the.pdf},
  journal  = {Proc Natl Acad Sci U S A},
  keywords = {Animals,Macaca mulatta,Photic Stimulation,Temporal Lobe/*physiology,Visual Perception/*physiology},
  month    = apr,
  year     = {1997},
}
% == BibTeX quality report for weilnhammerPsychoticExperiencesSchizophrenia2020a:
% ? Title looks like it was stored in title-case in Zotero

@Article{weiMutualInformationFisher2015,
  author     = {Wei, Xue-Xin and Stocker, Alan A.},
  title      = {Mutual {{Information}}, {{Fisher Information}}, and {{Efficient Coding}}},
  doi        = {10.1162/NECO_a_00804},
  issn       = {0899-7667},
  number     = {2},
  pages      = {305--326},
  volume     = {28},
  abstract   = {Fisher information is generally believed to represent a lower bound on mutual information~(Brunel \& Nadal, 1998), a result that is frequently used in the assessment of neural coding efficiency. However, we demonstrate that the relation between these two quantities is more nuanced than previously thought. For example, we find that in the small noise regime, Fisher information actually provides an upper bound on mutual information. Generally our results show that it is more appropriate to consider Fisher information as an approximation rather than a bound on mutual information. We analytically derive the correspondence between the two quantities and the conditions under which the approximation is good. Our results have implications for neural coding theories and the link between neural population coding and psychophysically measurable behavior. Specifically, they allow us to formulate the efficient coding problem of maximizing mutual information between a stimulus variable and the response of a neural population in terms of Fisher information. We derive a signature of efficient coding expressed as the correspondence between the population Fisher information and the distribution of the stimulus variable. The signature is more general than previously proposed solutions that rely on specific assumptions about the neural tuning characteristics. We demonstrate that it can explain measured tuning characteristics of cortical neural populations that do not agree with previous models of efficient coding.},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/computation/bayesian/bayesianNeuralSystems/theories/wei2015mut.pdf},
  journal    = {Neural Computation},
  keywords   = {r9.5,read},
  month      = dec,
  readstatus = {read},
  year       = {2015},
}
% == BibTeX quality report for bielczykEffectiveSelfManagementEarly2020:
% ? Title looks like it was stored in title-case in Zotero

@Article{biessmannAnalysisMultimodalNeuroimaging2011,
  author   = {Biessmann, F. and Plis, S. and Meinecke, F. C. and Eichele, T. and Muller, K. R.},
  title    = {Analysis of Multimodal Neuroimaging Data},
  doi      = {10.1109/RBME.2011.2170675},
  issn     = {1941-1189 (Electronic) 1937-3333 (Linking)},
  pages    = {26--58},
  volume   = {4},
  abstract = {Each method for imaging brain activity has technical or physiological limits. Thus, combinations of neuroimaging modalities that can alleviate these limitations such as simultaneous recordings of neurophysiological and hemodynamic activity have become increasingly popular. Multimodal imaging setups can take advantage of complementary views on neural activity and enhance our understanding about how neural information processing is reflected in each modality. However, dedicated analysis methods are needed to exploit the potential of multimodal methods. Many solutions to this data integration problem have been proposed, which often renders both comparisons of results and the choice of the right method for the data at hand difficult. In this review we will discuss different multimodal neuroimaging setups, the advances achieved in basic research and clinical application and the methods used. We will provide a comprehensive overview of mathematical tools reoccurring in multimodal neuroimaging studies for artifact removal, data-driven and model-driven analyses, enabling the practitioner to try established or new combinations from these algorithmic building blocks.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/unfiled/biessmann2011ana.pdf},
  journal  = {IEEE Rev Biomed Eng},
  keywords = {Brain/*physiology,Diffusion Tensor Imaging,Electroencephalography/*methods,Humans,Image Processing; Computer-Assisted,Magnetic Resonance Imaging/*methods,Magnetoencephalography/*methods,Optics and Photonics,Positron-Emission Tomography/methods,Spectroscopy; Near-Infrared/methods},
  year     = {2011},
}
% == BibTeX quality report for knightNewFrontiersAnxiety2019:
% ? Title looks like it was stored in title-case in Zotero

@Article{knillBayesianBrainRole2004,
  author   = {Knill, D. C. and Pouget, A.},
  title    = {The {{Bayesian}} Brain: The Role of Uncertainty in Neural Coding and Computation},
  doi      = {10.1016/j.tins.2004.10.007},
  issn     = {0166-2236 (Print) 0166-2236 (Linking)},
  pages    = {712--9},
  volume   = {27},
  abstract = {To use sensory information efficiently to make judgments and guide action in the world, the brain must represent and use information about uncertainty in its computations for perception and action. Bayesian methods have proven successful in building computational theories for perception and sensorimotor control, and psychophysics is providing a growing body of evidence that human perceptual computations are "Bayes' optimal". This leads to the "Bayesian coding hypothesis": that the brain represents sensory information probabilistically, in the form of probability distributions. Several computational schemes have recently been proposed for how this might be achieved in populations of neurons. Neurophysiological data on the hypothesis, however, is almost non-existent. A major challenge for neuroscientists is to test these ideas experimentally, and so determine whether and how neurons code information about sensory uncertainty.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/computation/bayesian/bayesianNeuralSystems/knill2004the.pdf},
  journal  = {Trends Neurosci},
  keywords = {*Bayes Theorem,*Perception,Animals,Brain/*physiology,Humans,Models; Biological,Nerve Net,Neurons/metabolism},
  month    = dec,
  year     = {2004},
}

@Article{petersonHealthyOscillatoryCoordination2018,
  author    = {Peterson, Erik J. and Voytek, Bradley},
  title     = {Healthy Oscillatory Coordination Is Bounded by Single-Unit Computation.},
  doi       = {10.1101/309427},
  language  = {en},
  pages     = {309427},
  abstract  = {Oscillations can improve neural coding by grouping action potentials into synchronous windows of activity, but this same effect can harm coding when action potentials become over-synchronized. Diseases ranging from Parkinson's to epilepsy suggest that over-synchronization leads to pathology, but the precise boundary separating healthy from pathological synchrony remains an open theoretical problem. Here we study a simple model that shows how error in individual cells' computations is traded for population-level synchronization. To put the in biological terms accessible to the cell we conceive of a ''voltage budget'' where instantaneous moments of membrane voltage can be partitioned into oscillatory and computational terms. By comparing these budget terms we derive a new set of biologically measurable inequalities that separate healthy from pathological synchrony. Finally, we derive an optimal non-biological algorithm for exchanging computational error with population synchrony.},
  copyright = {\textcopyright{} 2018, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
  file      = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/DynamicCoding/peterson2018hea.pdf},
  journal   = {bioRxiv},
  month     = jun,
  year      = {2018},
}
% == BibTeX quality report for bellaySelectiveParticipationSingle2021:
% ? Title looks like it was stored in title-case in Zotero

@Article{bellCrossLevelTheory2007,
  author     = {Bell, Anthony J.},
  title      = {Towards a {{Cross}}-{{Level Theory}} of {{Neural Learning}}},
  doi        = {10.1063/1.2821301},
  issn       = {0094-243X},
  number     = {1},
  pages      = {56--73},
  volume     = {954},
  file       = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neuroprinciples/multiScale/bell2007tow.pdf},
  journal    = {AIP Conference Proceedings},
  keywords   = {read},
  month      = nov,
  publisher  = {{American Institute of Physics}},
  readstatus = {read},
  year       = {2007},
}

@Article{kadmonPredictiveCodingBalanced2020,
  author        = {Kadmon, Jonathan and Timcheck, Jonathan and Ganguli, Surya},
  title         = {Predictive Coding in Balanced Neural Networks with Noise, Chaos and Delays},
  eprint        = {2006.14178},
  eprinttype    = {arxiv},
  abstract      = {Biological neural networks face a formidable task: performing reliable computations in the face of intrinsic stochasticity in individual neurons, imprecisely specified synaptic connectivity, and nonnegligible delays in synaptic transmission. A common approach to combatting such biological heterogeneity involves averaging over large redundant networks of \$N\$ neurons resulting in coding errors that decrease classically as \$1/\textbackslash sqrt\{N\}\$. Recent work demonstrated a novel mechanism whereby recurrent spiking networks could efficiently encode dynamic stimuli, achieving a superclassical scaling in which coding errors decrease as \$1/N\$. This specific mechanism involved two key ideas: predictive coding, and a tight balance, or cancellation between strong feedforward inputs and strong recurrent feedback. However, the theoretical principles governing the efficacy of balanced predictive coding and its robustness to noise, synaptic weight heterogeneity and communication delays remain poorly understood. To discover such principles, we introduce an analytically tractable model of balanced predictive coding, in which the degree of balance and the degree of weight disorder can be dissociated unlike in previous balanced network models, and we develop a mean field theory of coding accuracy. Overall, our work provides and solves a general theoretical framework for dissecting the differential contributions neural noise, synaptic disorder, chaos, synaptic delays, and balance to the fidelity of predictive neural codes, reveals the fundamental role that balance plays in achieving superclassical scaling, and unifies previously disparate models in theoretical neuroscience.},
  archiveprefix = {arXiv},
  file          = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/coding/Efficient_Optimal/kadmon2020pre.pdf},
  journal       = {arXiv:2006.14178 [cond-mat, q-bio, stat]},
  keywords      = {Condensed Matter - Disordered Systems and Neural Networks,Quantitative Biology - Neurons and Cognition,r17,read,Statistics - Machine Learning},
  month         = jun,
  primaryclass  = {cond-mat, q-bio, stat},
  readstatus    = {read},
  year          = {2020},
}
% == BibTeX quality report for cohenIsofluraneImpairsLow2018:
% ? Title looks like it was stored in title-case in Zotero

@Article{cohenMeasuringInterpretingNeuronal2011,
  author   = {Cohen, M. R. and Kohn, A.},
  title    = {Measuring and Interpreting Neuronal Correlations},
  doi      = {10.1038/nn.2842},
  issn     = {1546-1726 (Electronic) 1097-6256 (Linking)},
  number   = {7},
  pages    = {811--9},
  volume   = {14},
  abstract = {Mounting evidence suggests that understanding how the brain encodes information and performs computations will require studying the correlations between neurons. The recent advent of recording techniques such as multielectrode arrays and two-photon imaging has made it easier to measure correlations, opening the door for detailed exploration of their properties and contributions to cortical processing. However, studies have reported discrepant findings, providing a confusing picture. Here we briefly review these studies and conduct simulations to explore the influence of several experimental and physiological factors on correlation measurements. Differences in response strength, the time window over which spikes are counted, spike sorting conventions and internal states can all markedly affect measured correlations and systematically bias estimates. Given these complicating factors, we offer guidelines for interpreting correlation data and a discussion of how best to evaluate the effect of correlations on cortical processing.},
  file     = {/home/ssafavi/Nextcloud/libraries/zoteroLib/neuroscience/neuralInteractions/PWcorrelations/cohen2011mea.pdf},
  journal  = {Nat Neurosci},
  keywords = {*Models; Neurological,Action Potentials/*physiology,Animals,Cell Communication/physiology,Cerebral Cortex/*cytology,Humans,Models; Statistical,Neurons/classification/*physiology},
  month    = jul,
  year     = {2011},
}

@InCollection{gell-mannComplexAdaptiveSystems1994,
  author    = {{Gell-Mann}, Murray},
  booktitle = {Complexity: {{Metaphors}}, {{Models}}, and {{Reality}}},
  title     = {Complex {{Adaptive Systems}}},
  editor    = {Cowan, G. and Pines, D. and Meltzer, D.},
  isbn      = {978-0-201-62605-6},
  number    = {19},
  pages     = {17--45},
  publisher = {{Addison-Wesley}},
  abstract  = {The various groups at the Santa Fe Institute studying complex adaptive systems (CAS) have somewhat different points of view and have adopted different vocabularies. Some of us speak of "artificial life" or "artificial social life" or "artificial worlds," while others, of whom I am one, prefer to consider natural CAS and computer-based systems together. The latter include methods for adaptive computation as well as models and simulations of natural CAS.},
  address   = {{Reading, MA}},
  file      = {/home/ssafavi/Nextcloud/libraries/zoteroLib/complexSystems/cas_ComplexAdaptiveSystems/gell-mann1994com.pdf},
  year      = {1994},
}
% == BibTeX quality report for medianoInformationIntegrationPlants2021:
% ? Title looks like it was stored in title-case in Zotero

@Article{medianoIntegratedInformationMetastability2016,
  author        = {Mediano, Pedro A. M. and Farah, Juan Carlos and Shanahan, Murray},
  title         = {Integrated {{Information}} and {{Metastability}} in {{Systems}} of {{Coupled Oscillators}}},
  eprint        = {1606.08313},
  eprinttype    = {arxiv},
  abstract      = {It has been shown that sets of oscillators in a modular network can exhibit a rich variety of metastable chimera states, in which synchronisation and desynchronisation coexist. Independently, under the guise of integrated information theory, researchers have attempted to quantify the extent to which a complex dynamical system presents a balance of integrated and segregated activity. In this paper we bring these two areas of research together by showing that the system of oscillators in question exhibits a critical peak of integrated information that coincides with peaks in other measures such as metastability and coalition entropy.},
  archiveprefix = {arXiv},
  file          = {/home/ssafavi/Nextcloud/libraries/zoteroLib/consciousness/integratedInformationTheory_iit/related/mediano2016int.pdf},
  journal       = {arXiv:1606.08313 [q-bio]},
  keywords      = {Quantitative Biology - Neurons and Cognition,r8,read},
  month         = jun,
  primaryclass  = {q-bio},
  readstatus    = {read},
  year          = {2016},
}

@Article{levittTopographyPyramidalNeuron1993,
  author     = {Levitt, Jonathan B. and Lewis, David A. and Yoshioka, Takashi and Lund, Jennifer S.},
  title      = {Topography of Pyramidal Neuron Intrinsic Connections in Macaque Monkey Prefrontal Cortex (Areas 9 and 46)},
  doi        = {10.1002/cne.903380304},
  issn       = {1096-9861},
  language   = {en},
  number     = {3},
  pages      = {360--376},
  volume     = {338},
  abstract   = {An understanding of the normal organization of prefrontal cortex is essential to the recognition of pathology underlying human behavioral disorders believed to depend on this region. We have therefore studied the pattern of intrinsic intra- and interlaminar pyramidal neuron connectivity in prefrontal areas 9 and 46 (of Walker) in macaque monkey cerebral cortex (anterior to the arcuate sulcus between the principal sulcus and midline). We made focal (200\textendash 400 {$\mu$}m) injections of biocytin and mapped the pattern of orthogradely transported label. Injections made into the superficial layers label wide-ranging lateral projections within the same areas of prefrontal cortex. Projections local to such small injections form a narrow band of terminals in layers 1\textendash 3 (200\textendash 400 {$\mu$}m wide, 2\textendash 4 mm long) centered on the injection site. Collateral fibers spread orthogonal to this terminal band, making frequent bifurcations, to establish a series of parallel bands of terminals with uninnervated bands between, spaced regularly across the cortex (center to center 500\textendash 600 {$\mu$}m). The entire pattern of terminal label is stripelike, with occasional narrower interbands and crosslinks between the bands, and can extend over 7\textendash 8 mm across the cortex. These projections arise from pyramidal neurons in layers 2, 3, and 5 and terminate in layers 1\textendash 3. The stripelike pattern contrasts with patchlike patterns in other cortical regions (V1, V2, V4, motor, somatosensory) and is smaller in scale than stripelike zones of corticocortical afferent terminals to this region, reported to be 300\textendash 750 {$\mu$}m wide and spaced 1.0\textendash 1.5 mm center to center. \textcopyright{} 1993 Wiley-Liss, Inc.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/cne.903380304},
  copyright  = {Copyright \textcopyright{} 1993 Wiley-Liss, Inc.},
  journal    = {Journal of Comparative Neurology},
  keywords   = {biocytin,cerebral cortex,circuitry,neuroanatomy,primates},
  year       = {1993},
}

@Article{fujitaIntrinsicConnectionsMacaque1996,
  author     = {Fujita, Ichiro and Fujita, Taeko},
  title      = {Intrinsic Connections in the Macaque Inferior Temporal Cortex},
  doi        = {10.1002/(SICI)1096-9861(19960513)368:4<467::AID-CNE1>3.0.CO;2-2},
  issn       = {1096-9861},
  language   = {en},
  number     = {4},
  pages      = {467--486},
  volume     = {368},
  abstract   = {Intrinsic connections in the inferior temporal cortex were analyzed by making extracellular injections of biocytin in Japanese macaques. Analysis was focused mainly on the dorsal part of area TE, in which a functional columnar organization has been shown. Interlaminar connections were analyzed in coronal section after laminar-specific microinjections, and intralaminar connections were examined from tangential sections. After injections at various depths in the dorsal TE, both axons and cell bodies were strongly labeled above or below the injection site in a columnar appearance. Axons from layer 3 ran in bundles towards the white matter and gave off prominent collaterals in layer 5. Ascending axons from lower to upper layers were also present (e.g., layers 4, 5, and 6 to layer 3). In tangential sections, there were abundant axons running parallel to the pia mater. These horizontal axons, particularly those in layers 2 and 3, produced patches of terminals 0.5 {$\pm$} 0.1 mm (mean {$\pm$} s.d.) in size and cylindrical in shape, spanning layers 1\textendash 3 or even to layers 4 and 5. In the tangential plane, they were distributed in an anisotropic manner around the injection. The farthest patch appeared at 4 mm from the injection site. The center-to-center distance between nearest-neighbor patches was 0.7 {$\pm$} 0.3 mm. These patches were found only within the dorsal TE and did not extend into the lower bank of the superior temporal sulcus or into the ventral part of area TE. Area TEO, which is a major afferent source to area TE, had axonal patches with spacing similar to those in area TE but with smaller sizes (0.4 {$\pm$} 0.1 mm). The results show that intrinsic horizontal axons both in area TE and in area TEO arborize in a patchy manner, as has been reported for several other cortical areas. In area TE, the size and spacing of the terminal patches match those of columns with similar stimulus selectivity. Thus, these patches may be related to the functional modularity in area TE. Vertical connections across layers and cylindrical patches of horizontal axons most likely contribute to the shared stimulus selectivity among cells within a column. \textcopyright{} 1996 Wiley-Liss, Inc.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/\%28SICI\%291096-9861\%2819960513\%29368\%3A4\%3C467\%3A\%3AAID-CNE1\%3E3.0.CO\%3B2-2},
  copyright  = {Copyright \textcopyright{} 1996 Wiley-Liss, Inc.},
  journal    = {Journal of Comparative Neurology},
  keywords   = {biocytin,columnar organization,horizontal axon,object recognition,visual association cortex},
  year       = {1996},
}
